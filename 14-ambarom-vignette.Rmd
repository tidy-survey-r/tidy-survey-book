# AmericasBarometer Vignette {#c14-ambarom-vignette}

```{r}
#| label: ambarom-styler
#| include: false
knitr::opts_chunk$set(tidy = 'styler')
```

::: {.prereqbox-header}
`r if (knitr:::is_html_output()) '### Prerequisites {- #prereq10}'`
:::

::: {.prereqbox data-latex="{Prerequisites}"}
For this chapter, load the following packages:
```{r}
#| label: ambarom-setup
#| error: FALSE
#| warning: FALSE
#| message: FALSE
library(tidyverse)
library(survey)
library(srvyr)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
library(gt)
library(ggpattern)
```

In this vignette, we will be using data from the 2021 AmericasBarometer survey. Download the raw files yourself from the [LAPOP website](http://datasets.americasbarometer.org/database/index.php).  This book uses version 1.2 of the data and each country has its own file for a total of 22 files. To read all files into R and ignore the Stata labels, we recommend running code like this:

```r
stata_files <- list.files(here("RawData", "LAPOP_2021"), "*.dta")

read_stata_unlabeled <- function(file) {
  read_stata(file) %>%
    zap_labels() %>%
    zap_label()
}

ambarom_in <- here("RawData", "LAPOP_2021", stata_files) %>%
  map_df(read_stata_unlabeled) %>%
  select(pais, strata, upm, weight1500, strata, core_a_core_b,
         q2, q1tb, covid2at, a4, idio2, idio2cov, it1, jc13,
         m1, mil10a, mil10e, ccch1, ccch3, ccus1, ccus3,
         edr, ocup4a, q14, q11n, q12c, q12bn,
         starts_with("covidedu1"), gi0n,
         r15, r18n, r18) 
```

The code above will read all files of type `.dta` in and stack them into one tibble. We then selected a subset of variables for this vignette. 
:::

## Introduction

The AmericasBarometer surveys are conducted by the LAPOP Lab [@lapop]. These surveys are public opinion surveys of the Americas focused on democracy. The study was launched in 2004/2005 with 11 countries, with the countries growing and fluctuating over time, and creates a study with consistent methodology across many countries. In 2021, the study included 22 countries ranging from the north in Canada to the South in Chile and Argentina [@lapop-about].

Historically, surveys were administered with face-to-face household interviews, but the COVID-19 pandemic changed the study significantly to the use of random-digit dialing (RDD) of mobile phones in all countries except the United States and Canada [@lapop-tech]. In Canada, LAPOP collaborated with the Environics Institute to collect data from a panel of Canadians using a web survey [@lapop-can]. While in the United States, YouGov conducted the survey on behalf of LAPOP by conducting a web survey among their panelists [@lapop-usa].

The survey has a core set of questions across the countries, but not all questions are asked everywhere. Additionally, some questions are only asked to half of the respondents within a country, presumably to reduce the burden as different sections are randomized to different respondents [@lapop-svy]. 

## Data Structure

Each country and year has its own file available in Stata format (`.dta`). In this vignette, we downloaded and stacked all the data from all 22 participating countries in 2021. We subset the data to a smaller set of columns as noted in the prerequisites box for usage in the vignette. To understand variables that are used across the several countries, the core questionnaire is useful [@lapop-svy]. 

## Preparing files

Many of the variables are coded as numeric and do not have intuitive variable names, so the next step is to create derived variables and analysis-ready data. Using the core questionnaire as a codebook, derived variables are created below with relevant factors with informative names.


```{r}
#| label: ambarom-read-secret
#| include: FALSE
#| cache: TRUE
#| message: FALSE
library(osfr)
osf_auth(Sys.getenv("OSF_PAT"))

lapop_rds_files <- osf_retrieve_node("https://osf.io/z5c3m/") %>%
  osf_ls_files(path = "LAPOP_2021",
               n_max = 40,
               pattern = ".rds")

filedet <- lapop_rds_files %>%
  osf_download(conflicts = "overwrite", path = here::here("osf_dl"))

ambarom_in <- filedet %>%
  pull(local_path) %>%
  read_rds()

unlink(pull(filedet, "local_path"))
```


```{r}
#| label: ambarom-derive
ambarom <- ambarom_in %>%
  mutate(
    Country = factor(
      case_match(pais,
                 1 ~ "Mexico",
                 2 ~ "Guatemala",
                 3 ~ "El Salvador",
                 4 ~ "Honduras",
                 5 ~ "Nicaragua",
                 6 ~ "Costa Rica",
                 7 ~ "Panama",
                 8 ~ "Colombia",
                 9 ~ "Ecuador",
                 10 ~ "Bolivia",
                 11 ~ "Peru",
                 12 ~ "Paraguay",
                 13 ~ "Chile",
                 14 ~ "Uruguay",
                 15 ~ "Brazil",
                 17 ~ "Argentina",
                 21 ~ "Dominican Republic",
                 22 ~ "Haiti",
                 23 ~ "Jamaica",
                 24 ~ "Guyana",
                 40 ~ "United States",
                 41 ~ "Canada")),
    CovidWorry = fct_reorder(
      case_match(covid2at,
                 1 ~ "Very worried",
                 2 ~ "Somewhat worried",
                 3 ~ "A little worried",
                 4 ~ "Not worried at all"),
      covid2at,
      .na_rm = FALSE)
  ) %>%
  rename(Educ_NotInSchool = covidedu1_1,
         Educ_NormalSchool = covidedu1_2,
         Educ_VirtualSchool = covidedu1_3,
         Educ_Hybrid = covidedu1_4,
         Educ_NoSchool = covidedu1_5,
         BroadbandInternet = r18n,
         Internet = r18)
```

At this point, it is helpful to check the cross-tabs between the original variables and the newly derived variables. By outputting these tables, we can check to make sure that we have correctly aligned the numeric data from the original data to the factored data with informative labels in the new data.

```{r}
#| label: ambarom-derive-check
ambarom %>% 
  count(Country, pais) %>% 
  print(n = 22)

ambarom %>% 
  count(CovidWorry, covid2at)
```

## Survey design objects

The technical report is the best source to understand how to specify the sampling design in R [@lapop-tech]. The data includes two weights: `wt` and `weight1500`. The first weight variable is country-specific and sums to the sample size but is calibrated to reflect each country's demographics, while the second weight variable sums to 1500 for each country. The second weight is indicated as the weight to use for multi-country analyses. While the documentation does not directly state this, the example Stata syntax (`svyset upm [pw=weight1500], strata(strata)`) indicates the variable `upm` is a clustering variable, and `strata` is the strata variable. Therefore, the design object is setup in R as follows:

```{r}
#| label: ambarom-design
ambarom_des <- ambarom %>%
  as_survey_design(ids = upm,
                   strata = strata,
                   weight = weight1500)
```

One interesting thing to note is that these can only give us estimates to compare countries but not multi-country estimates since the weights do not account for different sizes of countries. For example, Canada has about 10% of the population of the United States, but an estimate that uses records from both countries would weigh them equally. 

## Calculating estimates {#ambarom-estimates}

When calculating estimates from the data, we use the survey design object `ambarom_des` and can then use the `survey_mean()` function.  The next sections walk through a few examples.

### Example: Worried about COVID

This survey was administered in 2021 between March and August, varying by country^[See Table 2 in @lapop-tech for dates by country]. Given the state of the pandemic at that time, several questions about COVID were included. The first question about COVID asked:

> How worried are you about the possibility that you or someone in your household will get sick from coronavirus in the next 3 months? 
>
> - Very worried
> - Somewhat worried
> - A little worried
> - Not worried at all

If we are interested in those that are very worried or somewhat worried, we can create a new variable (`CovidWorry_bin`) that collapses levels of the original question using the `fct_collapse()` function from the {forcats} package. We then use the `survey_count()` function to understand the distribution of responses for each category of the original variable (`CovidWorry`) and the new variable (`CovidWorry_bin`).

```{r}
#| label: ambarom-worry-est1
covid_worry_collapse <- ambarom_des %>%
  mutate(CovidWorry_bin = fct_collapse(
    CovidWorry,
    WorriedHi = c("Very worried", "Somewhat worried"),
    WorriedLo = c("A little worried", "Not worried at all")
  )) 

covid_worry_collapse %>% 
  survey_count(CovidWorry_bin,CovidWorry)

```

With this new variable created, we can then use `survey_mean()` to calculate the percentage of people in each country that are very or somewhat worried of COVID.  As we see in the `survey_count()` output above, there are missing data, so we need to use `na.rm = TRUE` in the `survey_mean()` function.

```{r}
#| label: ambarom-worry-est2
covid_worry_country_ests <- covid_worry_collapse %>%
  group_by(Country) %>%
  summarize(p = survey_mean(CovidWorry_bin == "WorriedHi",
                            na.rm = TRUE) * 100) 

covid_worry_country_ests

```

To view the results for all countries, we can use the {gt} package to create Table \@ref(tab:ambarom-worry-tab).

```{r}
#| label: ambarom-worry-gt
covid_worry_country_ests_gt <- covid_worry_country_ests %>%
  gt(rowname_col = "Country") %>%
  cols_label(p = "Percent",
             p_se = "SE") %>%
  fmt_number(decimals = 1) %>%
  tab_source_note("AmericasBarometer Surveys, 2021")
```

```{r}
#| label: ambarom-worry-noeval
#| eval: false
covid_worry_country_ests_gt
```

(ref:ambarom-worry-tab) Percentage worried about the possibility that they or someone in their household will get sick from coronavirus in the next 3 months

```{r}
#| label: ambarom-worry-tab
#| echo: FALSE
#| warning: FALSE

covid_worry_country_ests_gt %>%
    print_gt_book(knitr::opts_current$get()[["label"]])
```

### Example: Education affected by COVID

Respondents were also asked a question about how education was affected by the pandemic. This question was asked among households with children under the age of 13, and respondents could select more than one option as follows:

> Did any of these children have their school education affected due to the pandemic?
> 
> |   - No, because they are not yet school age or because they do not attend school for another reason
> |   - No, their classes continued normally
> |   - Yes, they went to virtual or remote classes
> |   - Yes, they switched to a combination of virtual and in-person classes
> |   - Yes, they cut all ties with the school

Multiple-choice questions can be challenging and interesting to work with. Let's walk through how to analyze this question. If we are interested in how education was impacted, then we should filter the data to those who are in school.  This means we need to filter to anyone that responded with the first response option "No, because they are not yet school age or because they do not attend school for another reason". To do this, we will use the variable `Educ_NotInSchool` in the dataset, which has values of 0 and 1. A value of 1 means that the respondent selected the first response option in the question (none of the children are in school) and a value of 0 means that at least one of their children are in school. Using this variable, we can filter the data to only those with a value of 0 (they have at least one child in school).  

We next want to review the data for those that selected one of the next three response options: 

- No, their classes continued normally: `Educ_NormalSchool`
- Yes, they went to virutal or remote classes: `Educ_VirtualSchool`
- Yes, they switched to a combination of virtual and in-person classes: `Educ_Hybrid`
 
An unweighted cross-tab for the responses is included below, and we can see there is a wide-range of impacts and that many combinations of effects on education are possible.

```{r}
#| label: ambarom-covid-ed-skip
ambarom %>% 
  filter(Educ_NotInSchool == 0) %>% 
  count(Educ_NormalSchool,
        Educ_VirtualSchool,
        Educ_Hybrid)
```

In reviewing the survey question, we could be interested in knowing the answers to the following:

- What percentage of households indicated that school continued as normal with no virtual or hybrid option?
- What percentage of households indicated that the education medium was changed to either virtual or hybrid?
- What percentage of households indicated that they cut ties with their school?

To answer these questions, we need to create indicators for the first two questions, make national estimates for all three questions, and then create a summary table for easy viewing. First, we create the indicators and output `survey_count()` results to check the new indicators and the distributions of the data.

```{r}
#| label: ambarom-covid-ed-inds
ambarom_des_educ <- ambarom_des %>%
  filter(Educ_NotInSchool == 0) %>%
  mutate(Educ_OnlyNormal = (Educ_NormalSchool == 1 &
                              Educ_VirtualSchool == 0 & 
                              Educ_Hybrid == 0),
         Educ_MediumChange = (Educ_VirtualSchool == 1 | 
                                Educ_Hybrid == 1))

ambarom_des_educ %>% 
  survey_count(Educ_OnlyNormal, 
               Educ_NormalSchool,
               Educ_VirtualSchool,
               Educ_Hybrid)

ambarom_des_educ %>% 
  survey_count(Educ_MediumChange, 
               Educ_VirtualSchool,
               Educ_Hybrid)
```

Next, we group by country and calculate the population estimates for our three questions.

```{r}
#| label: ambarom-covid-ed-ests
covid_educ_ests <-
  ambarom_des_educ %>%
  group_by(Country) %>%
  summarize(
    p_onlynormal = survey_mean(Educ_OnlyNormal, na.rm = TRUE) * 100,
    p_mediumchange = survey_mean(Educ_MediumChange, na.rm = TRUE) * 100,
    p_noschool = survey_mean(Educ_NoSchool, na.rm = TRUE) * 100,
  ) 

covid_educ_ests
```

Finally, to view the results for all countries, we can use the {gt} package to create Table \@ref(tab:ambarom-covid-ed-der-tab).

```{r}
#| label ambarom-covid-ed-gt
covid_educ_ests_gt<-covid_educ_ests %>%
  gt(rowname_col = "Country") %>%
  cols_label(p_onlynormal = "%",
             p_onlynormal_se = "SE",
             p_mediumchange = "%",
             p_mediumchange_se = "SE",
             p_noschool = "%",
             p_noschool_se = "SE") %>%
  tab_spanner(label = "Normal school only",
              columns = c("p_onlynormal", "p_onlynormal_se")) %>%
  tab_spanner(label = "Medium change",
              columns = c("p_mediumchange", "p_mediumchange_se")) %>%
  tab_spanner(label = "Cut ties with school",
              columns = c("p_noschool", "p_noschool_se")) %>%
  fmt_number(decimals = 1) %>%
  tab_source_note("AmericasBarometer Surveys, 2021")
```

```{r}
#| label: ambarom-covid-ed-der-noeval
#| eval: false
covid_educ_ests_gt
```

(ref:ambarom-covid-ed-der-tab) Impact on education in households with children under the age of 13 who had children that would generally attend school

```{r}
#| label: ambarom-covid-ed-der-tab
#| echo: FALSE
#| warning: FALSE

covid_educ_ests_gt %>%
  print_gt_book(knitr::opts_current$get()[["label"]])
```

Of the countries that used this question, many had households where their children had an education medium change, except Haiti, where only `r covid_educ_ests %>% filter(Country=="Haiti") %>% pull(p_mediumchange) %>% signif(.,2)`% of households with students changed to virtual or hybrid learning. 


## Mapping survey data {#ambarom-maps}

While the table presents the data well, a map could also be used. To obtain maps of the countries, the package {rnaturalearth} is used, subsetting North and South America using the function `ne_countries()`. This returns an sf (simple features) object with many columns but, most importantly `soverignt` (sovereignty), `geounit` (country or territory), and `geometry` (the shape). As an example of the difference between sovereignty and country/territory, the United States, Puerto Rico, and the US Virgin Islands are all separate units with the same sovereignty. This map (without data) is plotted in Figure \@ref(fig:ambarom-americas-map).

```{r}
#| label: ambarom-americas-map
#| fig.cap: "Map of North and South America"
#| error: true
country_shape <-
  ne_countries(
    scale = "medium",
    returnclass = "sf",
    continent = c("North America", "South America")
  )

country_shape %>%
  ggplot() + 
  geom_sf()
```

The map in Figure \@ref(fig:ambarom-americas-map) is very wide as the Aleutian islands in Alaska extend into the Eastern Hemisphere. We can crop the shape file to only the Western Hemisphere to remove some of the trailing islands of Alaska.

```{r}
#| label: ambarom-update-map
#| warning: false
country_shape_crop <- country_shape %>%
  st_crop(c(xmin = -180,
            xmax = 0,
            ymin = -90,
            ymax = 90)) 
```

Now that we have the shape files we need, our next step is to match our survey data to the map. Countries can be called by different names (e.g., "U.S", "U.S.A", "United States"). To make sure we can plot our survey data on the map, we will need to make sure the country in both the survey data and the map data match.  To do this, we can use the `anti_join()` function and check to see what countries are in the survey data but not in the map data. For example, as shown below, the United States is referred to as "United States" in the survey data but "United States of America" in the map data. Table \@ref(tab:ambarom-map-merge-check-1-tab) shows the countries in the survey data but not the map data, and Table \@ref(tab:ambarom-map-merge-check-2-tab) shows the countries in the map data but not the survey data.

```{r}
#| label: ambarom-map-merge-check-1-gt
survey_country_list <- ambarom %>% distinct(Country) 

survey_country_list_gt <- survey_country_list %>% 
  anti_join(country_shape_crop, by = c("Country" = "geounit")) %>% 
  gt()
```

```{r}
#| label: ambarom-map-merge-check-1-noeval
#| eval: false
survey_country_list_gt
```

(ref:ambarom-map-merge-check-1-tab) Countries in the survey data but not the map data

```{r}
#| label: ambarom-map-merge-check-1-tab
#| echo: FALSE
#| warning: FALSE

survey_country_list_gt %>%
  print_gt_book(knitr::opts_current$get()[["label"]])
```

```{r}
#| label: ambarom-map-merge-check-2-gt
map_country_list_gt<-country_shape_crop %>% as_tibble() %>% 
  select(geounit, sovereignt) %>%
  anti_join(survey_country_list, by = c("geounit" = "Country")) %>%
  arrange(geounit) %>%
  gt()
```


```{r}
#| label: ambarom-map-merge-check-2-noeval
#| eval: false
map_country_list_gt
```

(ref:ambarom-map-merge-check-2-tab) Countries in the map data but not the survey data

```{r}
#| label: ambarom-map-merge-check-2-tab
#| echo: FALSE
#| warning: FALSE

map_country_list_gt %>%
  print_gt_book(knitr::opts_current$get()[["label"]])
```

With the mismatched names, there are several ways to remedy the data to join later. The most straightforward fix is to rename the shape object's data before merging. We then can plot the survey estimates after merging the data. As there is only one country in the survey data that is not in the map data, we will rename the map data to match.

```{r}
#| label: ambarom-update-map-usa
country_shape_upd <- country_shape_crop %>%
  mutate(geounit = if_else(geounit == "United States of America", 
                           "United States", geounit))
```

Once the country names match, we merge the survey and map data together then plot the data. We begin with the map file and merge on the survey estimates we created in section \@ref(ambarom-estimates) (`covid_worry_country_ests` and `covid_educ_ests`).  We do this using the tidyverse function of `full_join()`, which takes all data in both the map data and the survey estimates we calculated, and creates one large dataset.

```{r}
#| label: ambarom-join-maps-ests
covid_sf <- country_shape_upd %>%
  full_join(covid_worry_country_ests, 
            by = c("geounit" = "Country")) %>%
  full_join(covid_educ_ests,
            by = c("geounit" = "Country"))
```

Next, we create two figures that graphically display the population estimates for the percentage of people who are worried about COVID (Figure \@ref(fig:ambarom-make-maps-covid)) and the percentage of households who had at least one child partcipate in virtual or hybrid learning (Figure \@ref(fig:ambarom-make-maps-covid-ed)).

```{r}
#| label: ambarom-make-maps-covid
#| fig.cap: "Percent of households worried someone in their household will get COVID-19 in the next 3 months by country"
#| error: true

ggplot() +
  geom_sf(data = covid_sf, 
          aes(fill = p, geometry = geometry),
          color = "darkgray") +
  scale_fill_gradientn(
    guide = "colorbar",
    name = "Percent",
    labels = scales::comma,
    colors = c("#BFD7EA","#087e8b","#0B3954"),
    na.value = NA
  ) +
  geom_sf_pattern(
    data = filter(covid_sf, is.na(p)),
    pattern = "crosshatch",
    pattern_fill = "lightgray",
    pattern_color = "lightgray",
    fill = NA,
    color = "darkgray"
  ) +
  theme_minimal()
```

```{r}
#| label: ambarom-make-maps-covid-ed
#| fig.cap: "Percent of households who had at least one child participate in virtual or hybrid learning"
#| error: true
ggplot() +
  geom_sf(data = covid_sf,  
          aes(fill = p_mediumchange, geometry = geometry),
          color = "darkgray") +
  scale_fill_gradientn(
    guide = "colorbar",
    name = "Percent",
    labels = scales::comma,
    colors = c("#BFD7EA","#087e8b","#0B3954"),
    na.value = NA
  ) +
  geom_sf_pattern(
    data = filter(covid_sf, is.na(p_mediumchange)),
    pattern = "crosshatch",
    pattern_fill = "lightgray",
    pattern_color = "lightgray",
    fill = NA,
    color = "darkgray"
  ) +
  theme_minimal()
```

In Figure \@ref(fig:ambarom-make-maps-covid-ed) we can see that Canada, Mexico, and the United States have missing data (the crosshatch pattern).  Reviewing the questionnaires indicate that these three countries did not include the education question in the survey. To better see the differences in the data, it may make sense to remove North America from the map and focus on Central and South America. This is done below by restricting the shape files to Latin America and the Caribbean as seen in Figure \@ref(fig:ambarom-make-maps-covid-ed-c-s).

```{r}
#| label: ambarom-make-maps-covid-ed-c-s
#| fig.cap: "Percent of  households who had at least one child participate in virtual or hybrid learning, Central and South America"
#| error: true

covid_c_s <- covid_sf %>%
  filter(region_wb == "Latin America & Caribbean")

ggplot() +
  geom_sf(data = covid_c_s, 
          aes(fill = p_mediumchange, geometry = geometry),
          color = "darkgray") +
  scale_fill_gradientn(
    guide = "colorbar",
    name = "Percent",
    labels = scales::comma,
    colors = c("#BFD7EA","#087e8b","#0B3954"),
    na.value = NA
  ) +
  geom_sf_pattern(
    data = filter(covid_c_s, is.na(p_mediumchange)),
    pattern = "crosshatch",
    pattern_fill = "lightgray",
    pattern_color = "lightgray",
    fill = NA,
    color = "darkgray"
  ) + 
  theme_minimal()
```

In Figure \@ref(fig:ambarom-make-maps-covid-ed-c-s), we can see that most countries that do have data are similar in percentage (due to their similar color).  However, we can see the ligher color present for Haiti indicating a much lower percentage of households who had at least one child participate in virtual or hybrid learning. 

## Exercises

1. Calculate the percentage of households with broadband internet and those with any internet at home, including from phone or tablet. Hint: if you see countries with 0% Internet usage, you may want to filter by something first.

```{r}
#| label: ambarom-int-prev
int_ests <-
  ambarom_des %>%
  filter(!is.na(Internet) | !is.na(BroadbandInternet)) %>%
  group_by(Country) %>%
  summarize(
    p_broadband = survey_mean(BroadbandInternet, na.rm = TRUE) * 100,
    p_internet = survey_mean(Internet, na.rm = TRUE) * 100
  ) 

int_ests %>%
  print(n = 30)
```

2. Make a faceted map showing both broadband internet and any internet usage.

```{r}
#| label: ambarom-facet-map
#| error: true
#| fig.cap: "Percent of broadband internet and any internet usage, Central and South America"
internet_sf <- country_shape_upd %>%
  full_join(select(int_ests, p = p_internet, geounit = Country), by = "geounit") %>%
  mutate(Type = "Internet")
broadband_sf <- country_shape_upd %>%
  full_join(select(int_ests, p = p_broadband, geounit = Country), by = "geounit") %>%
  mutate(Type = "Broadband")
b_int_sf <- internet_sf %>%
  bind_rows(broadband_sf) %>%
  filter(region_wb == "Latin America & Caribbean")

b_int_sf %>%
  ggplot(aes(fill = p),
         color="darkgray") +
  geom_sf() +
  facet_wrap( ~ Type) +
  scale_fill_gradientn(
    guide = "colorbar",
    name = "Percent",
    labels = scales::comma,
    colors = c("#BFD7EA", "#087E8B", "#0B3954"),
    na.value = NA
  ) +
  geom_sf_pattern(
    data = filter(b_int_sf, is.na(p)),
    pattern = "crosshatch",
    pattern_fill = "lightgray",
    pattern_color = "lightgray",
    fill = NA,
    color = "darkgray"
  ) +
  theme_minimal()
```