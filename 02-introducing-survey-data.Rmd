# Overview of Surveys {#c02}

Creating and fielding surveys to provide estimates of a population are much more complex than simply adding a few questions to an online platform. Survey researchers can spend months or even years developing the study design, questions, and other methods for a single survey to ensure high quality data is collected. While this book focuses on the analysis methods of surveys, understanding the entire survey process can provide a better understanding of what types of analyses should be conducted on the data. There are many pieces of existing literature that cover designing and implementing surveys that we recommend reviewing in detail (e.g., {cite: Dillman book, Groves book, education book?, others?}). The information provided in this chapter is a brief introduction into the survey process aiming to provide a foundation of the complexities of survey data.

## Survey Process

The survey life cycle starts with a research topic or question of interest. For example, a researcher may be interested in the impact childhood trauma has on political affiliation later in life. Before choosing to conduct a survey, researchers typically review existing data sources to determine if data are already available that can answer this question. If existing data cannot answer the nuances of the research question, a survey can be used to capture the exact data that the researcher needs.

Figure \@ref(fig:svylifecycle) shows a high level view of the steps that researchers must conduct to go from a research question to final results.

<!-- Note: need to adjust the size of the text in this figure. -->

```{r svylifecycle, echo=FALSE, fig.cap = "Overview of the survey process"}
library(DiagrammeR)
mermaid("
graph TD
  A[Survey Concept]-->B[Study Design]
  B-->C[Questionnaire Design]
  B-->D[Data Collection Materials]
  C-->E[Collect Data]
  D-->E
  E-->F[Create Weights]
  F-->G[Analysis]
  G-->H[Reporting]
  
  style A fill: #bfd7ea, stroke: #0b3954
  style B fill: #bfd7ea, stroke: #0b3954
  style C fill: #bfd7ea, stroke: #0b3954
  style D fill: #bfd7ea, stroke: #0b3954
  style E fill: #bfd7ea, stroke: #0b3954
  style F fill: #bfd7ea, stroke: #0b3954
  style G fill: #bfd7ea, stroke: #0b3954
  style H fill: #bfd7ea, stroke: #0b3954
")
```

### Study Design

Having a robust study design is crucial for success of the survey both implementation and analysis. Knowing who and how to survey individuals depends on both the goals of the study and the feasibility of implementation. Who we want to survey is known as the *population* of interest in the study. This could be broad, such as, "all adults age 18+ living in the U.S.", or it could be a very specific population of interest based on a specific characteristic or location. For example, we may want to know about "adults age 18-24 who live in North Carolina" or "eligible voters living in Illinois".

While it would be great to survey every person that meet these requirements (i.e., conduct a census), the ability to implement a questionnaire at that scale is something few can do. Instead, researchers choose to *sample* individuals and use weights to estimate numbers in the population. There are a variety of different sampling methods that can be used, and more information on these can be found in Chapter \@ref(c05).

Once a population of interest is identified, researchers need to consider how to survey these individuals. There are four main modes that researchers can consider when conducting a survey:

-   Computer Assisted Personal Interview (CAPI; also known as face-to-face or in-person interviewing)
-   Computer Assisted Telephone Interview (CATI; also known as phone or telephone interviewing)
-   Web
-   Paper and Pencil

Researchers can use a single mode to collect data, or multiple modes (also called mixed modes). Using mixed modes can allow for broader reach and can increase response rates depending on the population of interest ({CITE DeLeeuw mixed mode article}). However, mode effects (where responses differ based on the mode of response) can be present in the data and may need to be considered during analysis.

When selecting which mode, or modes, to use, understanding the unique aspects of the chosen population will provide insight into how they can best be reached and engaged. For example, if we plan to survey adults age 18-24 who live in North Carolina, asking them to complete a survey using CATI (i.e., over the phone) would most likely not be as successful as other modes like web.

### Questionnaire Design

After determining the study design to use for the survey, researchers will begin developing the questions of the survey. As with writing papers, an outline of the topics to be asked is a good place to begin. When starting out, adding in the "why" each question or topic is important to the research question(s) can help researchers better tailor their questionnaire and potentially reduce the number of questions (and thus burden on the respondent) if topics are deemed irrelevant to the research question. When making these decisions, researchers should also consider questions needed for weighting purposes. While we would love to have everyone sampled answer our survey, this is rarely the case. Thus, including questions about demographics in the survey can assist with weighting for nonresponse.

Additionally, when crafting questions for surveys, researchers should consider the mode the survey will be administered in and adjust language appropriately. In self-administered surveys (e.g., web or mail), respondents can see all of the questions and response options, so formatting of the questions and ordering of questions is important. In interviewer-administered surveys (e.g., CATI), respondents only hear the interviewer asking the questions and it becomes more of a conversation between parties. There are multiple resources out there to help researchers draft questions for different modes (e.g., {CITE Dillman, fowler, ed book?}).

How questions are worded have large impacts on what results can be obtained from the data. For example, Let's say we have the following question in our survey:

<!-- Put this in as an image instead of as a block quote -->
> What animal do you prefer to have as a pet?
>
<ul class="ro">
  <li class="ro">Dogs</li>
  <li class="ro">Cats</li>
</ul>

If we had 100 respondents who answered the question and 50 selected dogs, then the results of this question cannot be 

> 50% of the population perfers to have a dog as a pet

as only two response options were provided. If a respondent taking our survey prefers turtles, they could either be forced to choose a response between these two (i.e., interpret the question as "between dogs and cats which do you prefer?"), or they may not answer the question (i.e., nonresponse).  As researchers we cannot determine, how these respondents would have answered.  Instead, the interpretation of this question should be

> When given the choice between dogs and cats, 50% of respodents perferred to have a dog as a pet.

However, when researchers are creating questions they should consider these possibilities and adjust the question accordingly.  One simple way could be to add an "other" response option to give respondents a chance to provide a different response.  The "other" response option could then include a way for respondents to write in what their other preference is.  For example, this question could be rewritten as

<!-- Put this in as an image instead of as a block quote, or need to add in an open-ended box for write in after the last option. -->
> What animal do you prefer to have as a pet?
>
<ul class="ro">
  <li class="ro">Dogs</li>
  <li class="ro">Cats</li>
  <li class="ro">Other, please specify:</li>
</ul>

Researchers can then code the responses from the open-ended box and get a better understanding of the respondent's choice of preferred pet.  Interpreting this question becomes easier as researchers no longer need to qualify the results with the choices provided.

This is a very simple example of how the question presentation and options can impact the findings.  More complex topics and questions will need researchers to thoroughly consider how to mitigate any impacts from the presentation, formatting, wording, and other aspects.  As survey analysts, reviewing not only the data but also the wording of the questions is crucial to ensure the results are presented in a manner consistent with the question asked.

### Data Collection

Much of data collection relies on what is available on the sample frame (see \@ref(c05)).  For example, if our sampling frame includes email address, we could send email to our selected sample members to convince them to complete a web survey. The contact mode and the survey mode do not need to be the same. However, it is important to make access to the survey as easy as possible for sample members to reduce burden and increase response rates.

### Weights

### Analysis

### Reporting

## Survey Data

### Error Sources

### Weights

## When to use Survey Data
