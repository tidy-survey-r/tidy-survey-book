# Understanding survey data documentation {#understanding-survey-data-documentation}

```{r}
#| include: false

library(tidyverse)
```

Before diving into survey analysis, it's crucial to thoroughly review the survey documentation. This documentation includes technical guides, questionnaires, codebooks, errata, and other useful resources. By taking the time to review these materials, we can gain a comprehensive understanding of the survey data and effectively conduct our analysis.

Survey documentation can vary in its organization, type, and ease of use. The information may be stored in any format - PDFs, Excel spreadsheets, Word documents, etc. Some surveys save different documentation together, such as providing a single document that contains both the codebook and the questionnaire. Others keep them in separate files. Despite these differences, it's important to know what kind of information is available in each documentation type and what to focus on in each one.

## Types of survey documentation

### Technical documentation
<!-- this is adapted from chapter 05 ending -->
The technical documentation, also known as user guides or methodology/analysis guides, highlights the variables necessary to specify the survey design. We recommend focusing on these key sections:

* **Introduction:** The introduction orients us to the survey. This section provides the project's background, the study's purpose, and the main research questions.
* **Study design:** The study design section describes how researchers prepared and administered the survey.
* **Sample:** The sample section describes how researchers selected cases, any sampling error that occurred, and the limitations of the sample. This section can contain recommendations on how to use sampling weights. Look for weight information, whether the survey design is strata and/or clusters/PSUs or replicate weights, and any population sizes or finite population correction. This documentation is critical in successfully running our analysis, and more detail on sample designs is available in [Chapter 05: Specifying sample designs in srvyr](#c05).

The technical documentation may include other helpful information. Some technical documentation includes syntax for SAS, SUDAAN, Stata, and/or R, meaning we don't have to create this code from scratch.

### Questionnaires

A survey questionnaire is a series of questions asked to obtain information from survey respondents. A questionnaire gathers opinions, behaviors, or demographic data by employing different types of questions, such as multiple-choice, open-ended, Likert scales, or ranking questions. It may randomize responses or include instructions to help respondents understand the questions. A survey may have one questionnaire or multiple, depending on its scale and scope.

The questionnaire is an essential resource for understanding and interpreting the survey data and we should use it alongside any analysis. It provides details about each of the questions asked in the survey, such as question name, question wording, response options, skip logic, randomizations, display specification, mode differences, and the universe (if only a subset of respondents were asked the question). 

Below in Figure \@ref(fig:que-examp), we show a question from the ANES 2020 questionnaire. The screenshot shows a particular question's question name (`postvote_rvote`), description (Did R Vote?), full wording of the question and responses, response order, universe, question logic (if `vote_pre` = 0), and other specifications. The section also includes the variable name, which we can link to the codebook.

```{r}
#| label: que-examp
#| echo: false
#| fig.cap: ANES 2020 Questionnaire Example
#| fig.alt: Question information about the variable postvote_rvote from ANES 2020 questionnaire Survey question, Universe, Logic, Web Spec, Response Order, and Released Variable are included. 

knitr::include_graphics(path="images/questionnaire-example.jpg")
```

### Codebooks

While a questionnaire provides information about the questions asked to respondents, the codebook explains how the survey data was coded and recorded. The codebook lists details such as variable names, variable label, variable meaning, codes for missing data, values labels, and value type (whether categorical or continuous, etc.). The codebook enables us to understand and use the variables appropriately in our analysis.

Below, we show a question from the ANES 2020 codebook. This part shows a particular variable's name (`V202066`), question wording, value labels, universe, and associated survey question (`postvote_rvote`).

```{r}
#| label: codebook-examp
#| echo: false
#| fig.cap: ANES 2020 Codebook Example
#| fig.alt: Variable information about the variable V202066 from ANES 2020 questionnaire Variable meaning, Value labels, Universe, and Survey Question(s) are included. 

knitr::include_graphics(path="images/codebook-example.jpg")
```

Reviewing both questionnaires and codebooks in parallel is important, as questions and variables are not one-to-one. A single question may have multiple associated variables, or a single variable may summarize multiple questions. Reviewing the codebook clarifies how to analyze the variables.

### Errata

An erratum (singular) or errata (plural) is a document that lists errors found in a publication or dataset, such as a survey questionnaire. The purpose of an erratum is to correct or update mistakes or inaccuracies in the original document.

For example, if a survey questionnaire contains an error, such as a typo or confusing wording, the researchers would release an erratum that provides a corrected version. Be sure to review these corrections before conducting any analysis to ensure the accuracy and eliability of the survey data and analysis.

### Additional resources

Surveys may have additional resources, such as interviewer instructions or "show cards" held up to respondents to help them answer questions. Explore the survey website to find out what resources were used and in what contexts.

## Working with missing data

We consider the data missing if a respondent does not reply to a survey question. Respondents may also not have seen a question by design. Or, they may not respond to a question for various reasons, such as not wanting to answer a particular question, not understanding the question, or simply forgetting to answer. 

Missing data can be a significant problem in survey analysis, as it can introduce bias and reduce the representativeness of the data. There are several different types of missing data^[Mack C, Su Z, Westreich D. Managing Missing Data in Patient Registries: Addendum to Registries for Evaluating Patient Outcomes: A Userâ€™s Guide, Third Edition [Internet]. Rockville (MD): Agency for Healthcare Research and Quality (US); 2018 Feb. Types of Missing Data. Available from: https://www.ncbi.nlm.nih.gov/books/NBK493614/]:

1. Missing completely at random (MCAR): The missing data is unrelated to both observed and unobserved data, and the probability of being missing is the same across all cases. For example, if a respondent missed a question because they had to leave the survey early due to an emergency.

2. Missing at random (MAR): The missing data is related to observed data but not unobserved data, and the probability of being missing is the same within groups. For example, if older respondents choose not to answer specific questions than younger respondents, and we ask about age in the demographic section.

3. Missing not at random (MNAR): The missing data is related to unobserved data and the probability of being missing varies for reasons that we are not measuring. For example, if respondents with depression do not answer a question about depression severity.

The survey documentation represents the missing data with a code. For example, a survey may have "Yes" responses coded to `1`, "No" responses coded to `2`, and missing responses coded to `-9`. Survey documentation may list different codes depending on why certain data is missing, such as non-response or skipped questions. When we are running analysis in R, we want to ensure that we are treating missing responses as missing data (i.e., `NA`) and not numeric data.

As survey analysts, we must consider the implications of handling missing data. For instance, we can analyze only the respondents who answered all questions by performing listwise deletion, which drops all rows from a data frame with a missing value in any column. The function `tidyr::drop_na()` can be used for listwise deletion. In the example below, only the first row will remain:

```{r}
dat <- tibble::tribble(
  ~col1, ~col2, ~col3,
    "a",    "d",   "e",
    "b",    NA,    NA,
    "c",    NA,    "f"
  )

dat %>% 
  tidyr::drop_na()
```

However, suppose our data is not missing completely at random (MCAR). In that case, listwise deletion may produce biased estimates. There may be a pattern of respondents who do not respond to specific questions. In these circumstances, we should explore other options, such as multiple imputation or weighted estimation. See Allison (2002) for more detail.
<!-- this was referenced in the ANES user guide but maybe we should not include?-->

### Accounting for skip patterns

Questionnaires may also include skip patterns, in which specific questions are skipped based on the respondent's answers to earlier questions. For example, if a respondent answers "no" to a question on whether they voted in the last election, then they may be instructed to skip a series of questions related to that election.

We must account for skip patterns in our survey analysis to ensure unbiased and accurate population parameters. We can treat skipped questions as missing data. Or, we can run analysis that accounts for the conditional dependence between the skipped and answered questions. The appropriate method depends on the nature and extent of the skip patterns, as well as the research questions and methodology. For example, if we wanted to know what proportion of eligible voters voted for a particular candidate, the denominator would be all who are eligible, while if we wanted to know what proportion voted for a particular candidate among those who voted, the denominator would be those who voted. We include or exclude missing values depending on our question.

In summary, we need to deeply understand missing data in our survey before running any analysis. The survey documentation is an important resource for understanding how to deal with missing data. Carefully review the documentation for guidance from the researchers.

## Example: American National Election Studies (ANES) 2020 survey documentation

Let's look at the survey documentation for the American National Election Studies (ANES) 2020. The survey website is located at [https://electionstudies.org/data-center/2020-time-series-study/](https://electionstudies.org/data-center/2020-time-series-study/). 

Navigating to "User Guide and Codebook," we can download the PDF that contains the survey documentation, titled "ANES 2020 Time Series Study Full Release: User Guide and Codebook". Don't be daunted by the 796-page PDF. We can focus on the most critical information.

#### Introduction {-}

The first section in the User Guide explains that the ANES 2020 Times Series Study is a continuation of a series of election surveys conducted since 1948. These surveys contain data on public opinion and voting behavior in the U.S. presidential elections. It states that interviewers used one of three modes (web, video, or telephone). The introduction then summarizes the number of pre-election interviews (8,280) and post-election re-interviews (7,449).

#### Sample Design and Respondent Recruitment {-}

The section "Sample Design and Respondent Recruitment" describes how the survey was conducted: 

> ...a contactless, mixed-mode design.... a sequential mixed-mode design was implemented that included self-administered online surveys, live video interviews conducted online, and telephone interviews.

In addition to respondents who participated in 2016 ANES, the 2020 survey included a freshly-drawn cross-section:

> The target population for the fresh cross-section was the 231 million non-institutional U.S. citizens aged 18 or older living in the 50 U.S. states or the District of Columbia.

The document continues with more details on the sample groups.

#### Data Analysis, Weights, and Variance Estimation {-}

The section "Data Analysis, Weights, and Variance Estimation" includes information on weights and strata/cluster variables. Reading through, we can find the full sample weight variables:

> For analysis of the complete set of cases using pre-election data only, including all cases and representative of the 2020 electorate, use the full sample pre-election weight, **V200010a**. For analysis including post-election data for the complete set of participants (i.e., analysis of post-election data only or a combination of pre- and post-election data), use the full sample post-election weight, **V200010b**. Additional weights are provided for analysis of subsets of the data...

The document provides more information about the variables, summarized below:

For weight | Use variance unit/PSU/cluster | and use variance stratum
-----------|-------------------------------|-------------------------
V200010a| V200010c| V200010d
V200010b| V200010c| V200010d

As mentioned above, we want to conduct ANES data analysis with weights to accurately represent the population. The user guide references a supplemental document called "How to Analyze ANES Survey Data"^[DeBell, Matthew. 2010. How to Analyze ANES Survey Data. ANES Technical Report Series no. nes012492. Palo Alto, CA, and Ann Arbor, MI: Stanford University and the University of Michigan] as a 'how-to guide' to help us with our analysis.

Recall the "Sample Design and Respondent Recruitment" section:

> The target population for the fresh cross-section was the 231 million non-institutional U.S. citizens aged 18 or older living in the 50 US states or the District of Columbia.

We will use Current Population Survey (CPS) to find a number of the non-institutional U.S. citizens aged 18 or older living in the 50 U.S. states or D.C. The {censusapi} package allows us to run a reproducible analysis of this data.

```{r}
#| message: false
library(censusapi)
library(tidyverse)

# Note that a Census key to access the Census API
cps_state_in <- getCensus(
  name = "cps/basic/nov",
  vintage = 2020,
  region = "state",
  vars = c("HRHHID", "HRMONTH", "HRYEAR4", "PRTAGE", "PRCITSHP", "PWSSWGT"),
  key = Sys.getenv("CENSUS_API_KEY")
)

cps_state <- cps_state_in %>%
  as_tibble() %>%
  mutate(across(.cols = everything(),
                .fns = as.numeric))

# Confirm this doesn't include territories
cps_state %>%
  count(state)
```

```{r}
# Confirm this is only November 2020
cps_state %>%
  count(HRMONTH, HRYEAR4)
```

```{r}
# Voting age citizen population
targetpop <- cps_state %>%
  as_tibble() %>%
  filter(PRTAGE >= 18,
         PRCITSHP %in% (1:4)) %>%
  pull(PWSSWGT) %>%
  sum()

targetpop
```

The target population in 2020 is `r scales::comma(targetpop)`. This information gives us what we need to create the post-election survey object with {srvyr}:

```{r}
#| eval: FALSE
library(tidyverse)
library(here)
library(srvyr)

anes <- read_rds(here("AnalysisData", "anes_2020.rds")) %>%
  mutate(Weight = V200010b / sum(V200010b) * 231592693)

anes_des <- anes %>%
  as_survey_design(
    weights = Weight,
    strata = V200010d,
    ids = V200010c,
    nest = TRUE
  )

summary(anes_des)
```

The next section of the survey documentation is the codebook. As mentioned above, the codebook provides information about the variables in a survey dataset. We can use it to select the variables for our analysis later on.

## Searching for public-use survey data
<!--I feel like I put this in here after one of our meetings, don't 100% remember, let me know if it's not worth adding-->
A common question for aspiring survey analysts is, "What are some examples of public-use survey data?". When writing this book, we asked ourselves this question to find relevant, engaging, and high-quality examples for our readers.

We considered whether a survey had both continuous and discrete data, how difficult it was to analyze, and how recently the survey collection happened. We also investigated the accessibility and licensing agreements of the data. Finally, we wanted to expand our examples beyond North American surveys.

Here are a few public-use survey resources that we recommend:

* Analyze Survey Data for Free - [asdfree.com](https://asdfree.com)
* Residential Energy Consumption Survey (RECS) - [https://www.eia.gov/consumption/residential/](https://www.eia.gov/consumption/residential/)
* The National Crime Victimization Survey (NCVS) - [https://bjs.ojp.gov/data-collection/ncvs](https://bjs.ojp.gov/data-collection/ncvs)
* Afrobarometer - [https://www.afrobarometer.org/](https://www.afrobarometer.org/)
* Latin American Public Opinion Project Research institute - [https://www.vanderbilt.edu/lapop/](https://www.vanderbilt.edu/lapop/)

## Exercises
<!--TODO: add exercises-->
<!--TODO: citations-->
