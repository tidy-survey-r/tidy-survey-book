# Descriptive analyses in srvyr {#c05-descriptive-analysis}


```{r}
#| label: desc-summary-tab
#| echo: FALSE
tribble(
  ~c1, ~c2,
  "**Topic**", "Descriptive analysis of survey data",
  "**Purpose**", "purpose-blah",
  "**Learning Goals**", "learning-goals-blah"
) %>%
  knitr::kable(format="pandoc", col.names=NULL, caption="Summary of Chapter 5")
```


```{r}
#| label: desc-tidy
#| include: FALSE
knitr::opts_chunk$set(tidy = TRUE)
```

## Similarities between {dplyr} and {srvyr} functions

```{r}
#| label: desc-dstrat
#| include: false
library(srvyr)
library(survey)
data(api)

dstrata <- apistrat %>%
  as_survey_design(strata = stype, weights = pw)
```

One of the major advantages of using {srvyr} is that it applies {dplyr}-like syntax to the {survey} package. We can use pipes to specify a tbl_svy object, apply a function, and then feed that output into the next function's first argument. Functions follow the 'tidy' convention of snake_case functions names. In the example below, the mean and median are calculated for the variable `mpg` on the `mtcars` dataset.

```{r}
#| label: desc-dplyr-examp
mtcars %>%
  summarize(mpg_mean = mean(mpg),
            mpg_median = median(mpg))
```

Similarly, in the next example, the variance and standard deviation of the variable `api00` are calculated for the tbl_svy object `dstrata`. Note how similar the syntax is. When we dig into the functions later, we will show that the results output are similar in that one row is output for each group (if there are groups) but there will be more columns output. Specifically, by default, the standard error of the statistic is calculated in addition to the statistic.

```{r}
#| label: desc-srvyr-examp
dstrata %>% 
  summarize(api00_mean = survey_mean(api00),
            api00_med = survey_median(api00))
```

The functions in {srvyr} also play nicely with other tidyverse functions. If we wanted to select columns that have something in common, we can use {tidyselect} functions such as `starts_with()`, `num_range()`, etc.. In the examples below, a combination of `across()` and `starts_with()` to calculate the mean of variables starting with "Sepal" in the `iris` dataframe and then starting wtih `api` in the `dstrata` survey object.

```{r}
#| label: desc-dplyr-select
iris %>%
  summarize(
    across(starts_with("Sepal"), mean)
  )
```

```{r}
#| label: desc-srvyr-select
dstrata %>%
  summarize(
    across(starts_with("api"), survey_mean)
  )
```

We can use {dplyr} verbs such as `mutate()`, `filter()`, etc., on our survey object.

```{r}
#| label: desc-srvyr-mutate
dstrata_mod <- dstrata %>%
  mutate(api_diff = api00 - api99) %>%
  filter(stype=="E") %>%
  select(stype, api99, api00, api_diff, api_students=api.stu)
dstrata_mod
dstrata
```

Instead of data frames or tibbles, {srvyr} functions are meant for `tbl_svy` objects. Attempting to run data manipulation on non-`tbl_svy` objects will result in an error as shown in the example below while using the mtcars data frame which is not `tbl_svy` object.

```{r}
#| label: desc-nsobj-error
#| error: true
mtcars %>%
  summarize(mpg_mean = survey_mean(mpg))
```

A few functions in {srvyr} parallel functions in {dplyr}, such as `srvyr::summarize()` and `srvyr::group_by()`. Unlike {srvyr}-specific verbs, the package recognizes these parallel functions on a non-survey object. It will not error and instead give the equivalent output from {dplyr}:

```{r}
#| label: desc-nsobj-noerr
mtcars %>% 
  srvyr::summarize(mpg_mean = mean(mpg))
```

Because this book focuses on survey analysis, most of our pipes will stem from a survey object. We will not include the namespace for each function (e.g., `srvyr::summarize()`). Several functions in {srvyr} must be called within `srvyr::summarize()` with the exception of `srvyr::survey_count()` and `srvyr::survey_tally()` much like `dplyr::count()` and `dplyr::tally()` are not called within `dplyr::summarize()`.

These verbs can be used in conjunction with `group_by()` or `by/.by`, applying the functions on a group-by-group basis to create grouped summaries.

```{r}
#| label: desc-dplyr-groupby
mtcars %>%
  group_by(cyl) %>%
  dplyr::summarize(mpg_mean = mean(mpg))
```

We use a similar setup to summarize data in {srvyr}.

```{r}
#| label: desc-srvyr-groupby
dstrata %>%
  group_by(stype) %>%
  summarize(api00_mean = survey_mean(api00),
            api00_median = survey_median(api00))
```

## Deciding on descriptive analyses

We select measures based on the type of variable we are analyzing. Variables are classified as categorical/nominal, ordinal, and interval/ratio.

* Categorical/nominal data: variables with levels or descriptions that cannot be ordered, such as the region of the country (North, South, East, and West)
* Ordinal data: variables that can be ordered, such as those from a Likert scale (strongly disagree, disagree, agree, and strongly agree)
* Interval/ratio: variables that are counted or measured, such as the total cost of electricity
  * Within interval/ratio data are *discrete* variables, whose values are whole numbers, such as a count of children, and *continuous* variables, whose values can lie anywhere on an interval, such as weight.
  
If our variable is categorical, such as gender or occupation, we might use frequency counts or percentages. In contrast, if the variable is continuous, such as income or age, we might use mean, median, or standard deviation.

Choosing appropriate measures is important to reach valid conclusions. Different variable types have distinct properties and levels of measurement, and we cannot apply all measures to all variables.

Our survey data may represent categorical variables using numeric codes. For example, the North, South, East, and West regions of the United States might be coded as 1, 2, 3, and 4, respectively. Though this is a categorical variable, this variable might be automatically read as numeric values when we import our data. This can lead to the common mistake of applying `survey_mean()` to all numeric columns in the dataset, including categorical values. 

This practice can lead to incorrect inferences because categorical variables lack a natural zero point or linear ordering, making measures like mean inappropriate. Instead, it is crucial to inspect the codebook, understand the variable type, and choose appropriate measures, such as frequency counts or percentages, to describe the data across regions.

## Chapter set up

Recall from Chapter \@ref(c03-specifying-sample-designs) the general process for estimation with the {srvyr} package:  

1. Create a `tbl_svy` object using `srvyr::as_survey_design()` or `srvyr::as_survey_rep()`.
2. Subset the data for subpopulations using `dplyr::filter()`, if needed.
3. Specify domains of analysis using `dplyr::group_by()`, if needed.
4. Within `srvyr::summarize()`, specify variables to calculate means, totals, proportions, quantiles, and more.

Filtering should be done after creating the `tbl_svy` object (using `as_survey_design()` or `as_survey_rep()`) because survey objects incorporate the survey design information into the resulting object. 

<!-- TODO: edit this depending on how much we've talked about it in earlier chapters-->
The Residential Energy Consumption Survey (RECS) provides energy consumption and expenditures data. It is funded by Energy Information Administration and collects information through energy suppliers through in-person, phone, and web interviews. It has been fielded 14 times between 1950 and 2020. Topics include appliances, electronics, heating, air conditioning (A/C), temperatures, water heating, lighting, energy bills, respondent demographics, and energy assistance.

The survey targets primarily occupied housing units in the US. RECS uses Balanced Repeated Replication (BRR) to estimate the variances. The full sample information is available on the [EIA website](https://www.eia.gov/consumption/residential/index.php). 

To begin analyzing RECS, we create a `tbl_svy` object using `srvyr::as_survey_design()`:

```{r}
#| label: recs_des
#| error: FALSE
#| warning: FALSE
#| message: FALSE
#| eval: FALSE
library(survey) # for survey analysis
library(srvyr) # for tidy survey analysis
library(readr)
library(osfr)
source("helper-fun/helper-functions.R")

recs_in <-
  read_rds_tsr("recs_2015.rds")

recs_des <- recs_in %>%
  as_survey_rep(
    weights = NWEIGHT,
    repweights = starts_with("BRRWT"),
    type = "Fay",
    rho = 0.5,
    mse = TRUE
  )
```

## Types of descriptive analyses

Descriptive analysis can be categorized into univariate and multivariate analysis, depending on the number of variables we are analyzing. Below, we describe the descriptive analysis for single or multiple variables and the {srvyr} functions associated with the measures. After introducing all the functions, we will describe the syntax of each and introduce examples.

#### Measures of distribution {-}

Measures of distribution describe how often an event or response occurs. These measures include counts, proportions, and totals. 

* Examples: the proportion of students in California who did or did not receive an award based on their Academic Performance score; the estimated number of U.S. citizens who voted in the last election; the total amount of money residential households spend on electricity in a year

The {srvyr} package includes several functions for determining measures of distribution and all must be called within the `summarize()` function except `survey_count()` and `survey_tally()`. 

* The `survey_count()` and `survey_tally()` functions calculate weighted observations by group
* The `survey_total()` function calculates totals 
* The `survey_prop()` function calculates proportions 
* The `survey_quantile()` function calculates quantiles

#### Measures of dispersion {-}

Measures of dispersion describe how data spreads around the central tendency. These measures include the standard deviation, variance, and range. 

* Examples: The standard deviation of the 2000 Academic Performance Index in California, the variance of electricity expenditure in Ohio

The {srvyr} package includes functions for estimating the standard deviation and variance, and they must be called within the `summarize()` function.

* The `survey_sd()` function calculates standard deviations
* The `survey_var()` function calculates variances

#### Measures of central tendency {-}

Measures of central tendency find the central (or average) responses. These include the mean, median, and mode.

* Examples: Average 2000 Academic Performance Index in California, the median house price in Canada 

The {srvyr} package includes functions for estimating the mean and median, and they must be called within the `summarize()` function.

* The `survey_mean()` function calculates means
* The `survey_median()` function calculates medians

#### Measures of relationship {-}

Section is WIP - skeleton only for now, goal to mirror above

* The `survey_ratio()` function calculates ratio between two variables
* The `survey_corr()` function calculates the Pearson's correlation between two variables

### Counts and cross-tabulations

With `srvyr::survey_count()`, we can calculate the estimated population counts for a given variable or combination of variables. Sometimes, these are referred to as cross-tabulations or crosstabs, for short. The syntax is very similar to the `dplyr::count()` syntax; however, as noted above, it can only be called on `tbl_svy` objects. Let's explore the syntax: 

```r
survey_count(
  x,
  ...,
  wt = NULL,
  sort = FALSE,
  name = "n",
  .drop = dplyr::group_by_drop_default(x),
  vartype = c("se", "ci", "var", "cv")
  )
  
survey_tally(
  x,
  wt,
  sort = FALSE,
  name = "n",
  vartype = c("se", "ci", "var", "cv")
)
```
The arguments are:

* `x`: a `tbl_svy` object created by `as_survey`
* `...`: variables to group by, passed to `group_by`
* `wt`: a variable to weight on in addition to the survey weights, defaults to `NULL`
* `sort`: how to sort the variables, defaults to `FALSE`
* `name`: the name of the count variable, defaults to `n`
* `.drop`: whether to drop empty groups
* `vartype`: type(s) of variation estimate to calculate, defaults to `se` (standard error)

We will discuss `vartype` in Section \@ref(Variance-types) as this option occurs in all functions.

If we do not specify any variables in `survey_count()`, the function will output the estimated population count (n) and standard error (n_se).  For example, in the RECS data we can obtain the estimated number of households in the U.S. (the target population) by running the following code: 

```{r}
#| label: desc-count-overall
recs_des %>%
  survey_count() 
```

```{r}
#| label: desc-count-oa-save
#| echo: FALSE
.est_pop <- recs_des %>%
  survey_count() %>%
  pull(n) %>%
  prettyNum(big.mark=",", digits=20)
```


Thus, the estimated number of households in the U.S. is `r .est_pop`.

To calculate the estimated number of observations for subgroups, such as Region and Division, we can add the variables of interest into the function. In the example below, the estimated number of housing units by region and division is calculated. Additionally, the name of the count variable is changed to "N" from the default ("n").

```{r}
#| label: desc-count-group
recs_des %>%
  survey_count(Region, Division, name = "N") 
```

```{r}
#| label: desc-count-group-save
#| echo: FALSE

.est_pop_div <- recs_des %>%
  survey_count(Region, Division, name = "N")  %>%
  mutate(N=prettyNum(N, big.mark=",", digits=20))
```

When we run the crosstab, we see  there are an estimated `r .est_pop_div %>% filter(Division=="New England") %>% pull(N)` housing units in the New England Division.

The `survey_tally()` function is similar to the `survey_count()`, but the `survey_tally()` function lacks the following arguments `...` (used to specify the by groups) and `.drop`. To get the estimated overall population, `survey_count()` and `survey_total()` will be identical and the example below yields the same results as using `survey_count()` previously.

```{r}
#| label: desc-tally-oa
recs_des %>%
  survey_tally() 
```

However, if we wanted the estimated population total by region and division, we will get an error if we try to use the same syntax:

```{r}
#| label: desc-tally-group-bad
#| error: TRUE
recs_des %>%
  survey_tally(Region, Division, name = "N") 
```

Instead, use a the `group_by()` function prior to using `survey_tally()` as is illustrated below:

```{r}
#| label: desc-tally-group-good
recs_des %>%
  group_by(Region, Division) %>%
  survey_tally(name = "N") 
```

### Totals and sums

The `survey_total()` function is analogous to `sum`. This can be used to find the estimated aggregate sum of an outcome. All the functions introduced henceforth in this section must be called from within `summarize()`. Let's explore the syntax:

```r
survey_total(
  x,
  na.rm = FALSE,
  vartype = c("se", "ci", "var", "cv"),
  level = 0.95,
  deff = FALSE,
  df = NULL,
  ...
)
```

The arguments are:

* `x`: a variable, expression, or empty
* `na.rm`: an indicator of whether missing values should be dropped, defaults to `FALSE`
* `vartype`: type(s) of variation estimate to calculate, defaults to `se` (standard error)
* `level`: a number or a vector indicating the confidence level, defaults to 0.95
* `deff`: a logical value stating whether the design effect should be returned, defaults to FALSE
* `df`: (for `vartype = 'ci'`), a numeric value indicating degrees of freedom for the t-distribution
* `...`: Ignored and not used

To calculate a population count estimate with `survey_total()`, the argument `x` can be left empty as shown in the example below::

```{r}
#| label: desc-tot-nox
recs_des %>%
  summarize(survey_total())  
```

Note that the result from `recs_des %>% summarize(survey_total())` is equivalent to the `survey_count()` call. However, the `survey_total()` function is called within `summarize`, where as `survey_count()`, like `dplyr::count()`, is not. 

The difference between `survey_total()` and `survey_count()` is more evident when specifying continuous variables to sum. Let's compute the total cost of electricity in whole dollars from variable `DOLLAREL`^[RECS has two components: a household survey and an energy supplier survey. For each household that responds, their energy provider(s) are contacted to obtain their energy consumption and expenditure. This value reflects the dollars spent on electricity in 2015 according to the energy supplier. See https://www.eia.gov/consumption/residential/reports/2015/methodology/pdf/2015C&EMethodology.pdf for more details.]. We also calculate an unweighted estimate using `unweighted()`. The `unweighted()` function calculates unweighted summaries from `tbl_svy` object which reflects the summary among the **respondents** and does not extrapolate to a population estimate.

```{r}
#| label: desc-tot-dollarel
recs_des %>%
  summarize(
    elec_bill = survey_total(DOLLAREL),
    elec_unweight = unweighted(sum(DOLLAREL))
  )
```

```{r}
#| label: desc-tot-dollarel-save
#| echo: FALSE
.elbill <- recs_des %>%
  summarize(
    elec_bill = survey_total(DOLLAREL),
    elec_unweight = unweighted(sum(DOLLAREL))
  ) %>%
  mutate(across(starts_with("elec"), \(x) str_c("$", prettyNum(x, big.mark=",", digits=20))))
```

It is estimated that American residential households spent a total of `r .elbill %>% pull(elec_bill)` on electricity in 2015 and the estimate has a standard error of `r .elbill %>% pull(elec_bill_se)`. The unweighted function calculates unweighted counts and illustrates the total amount of money the respondents spent on electricity in 2015 which was `r .elbill %>% pull(elec_unweight)`.

Since we are using the {srvyr} package, we can use `group_by()` to calculate the cost of electricity by different groups. Let's see how much the cost of electricity in whole dollars differed between regions: 

```{r}
#| label: desc-tot-group
recs_des %>%
  group_by(Region) %>%
  summarize(elec_bill = survey_total(DOLLAREL))   
```

```{r}
#| label: desc-tot-group-save
#| echo: FALSE
.elbil_reg <- recs_des %>%
  group_by(Region) %>%
  summarize(elec_bill = survey_total(DOLLAREL)) %>%
  mutate(across(starts_with("elec"), \(x) str_c("$", prettyNum(round(x, 0), big.mark=",", digits=20))))
```

It's estimated that households in the Northeast spent `r .elbil_reg %>% filter(Region=="Northeast") %>% pull(elec_bill)` on electricity in 2015 while households in the South spent an estimated `r .elbil_reg %>% filter(Region=="South") %>% pull(elec_bill)`.

### Means and proportions

The `srvyr::survey_mean()` and `survey_prop()` functions calculate the means (of continuous variables) and proportions (of categorical variables) of survey data while accounting for complex survey design. Like `survey_total()`, they are called within `summarize()`. Let's explore the syntax:

```r
survey_mean(
  x,
  na.rm = FALSE,
  vartype = c("se", "ci", "var", "cv"),
  level = 0.95,
  proportion = FALSE,
  prop_method = c("logit", "likelihood", "asin", "beta", "mean"),
  deff = FALSE,
  df = NULL,
  ...
)

survey_prop(
  vartype = c("se", "ci", "var", "cv"),
  level = 0.95,
  proportion = FALSE,
  prop_method = c("logit", "likelihood", "asin", "beta", "mean"),
  deff = FALSE,
  df = NULL,
  ...
)
```

The arguments are:

* `x`: a variable, expression, or empty
* `na.rm`: an indicator of whether missing values should be dropped, defaults to `FALSE`
* `vartype`: type(s) of variation estimate to calculate, defaults to `se` (standard error)
* `level`: a number or a vector indicating the confidence level, defaults to 0.95
* `proportion`: an indicator of whether the estimate is a proportion. Defaults to `FALSE` in `survey_mean()` and `TRUE` in `survey_prop`. Only impacts confidence intervals
* `prop_method`: Method to calculate confidence interval for confidence intervals. More details in \@ref(Variance-types)
* `deff`: a logical value stating whether the design effect should be returned, defaults to FALSE
* `df`: (for `vartype = 'ci'`), a numeric value indicating degrees of freedom for the t-distribution
* `...`: Ignored and not used


We can calculate the estimated average cost of electricity in the U.S. and then for each region in the U.S.: 

```{r}
#| label: desc-mn-oa
recs_des %>%
  summarize(elec_bill = survey_mean(DOLLAREL))
```

```{r}
#| label: desc-mn-oa=save
#| echo: FALSE
.elbill_mn <- recs_des %>%
  summarize(elec_bill = survey_mean(DOLLAREL)) %>%
  mutate(across(starts_with("elec"), \(x) str_c("$", prettyNum(round(x, 0), big.mark=",", digits=6))))
```

```{r}
#| label: desc-mn-group
recs_des %>%
  group_by(Region) %>%
  summarize(elec_bill = survey_mean(DOLLAREL))
```

```{r}
#| label: desc-mn-group-save
#| echo: FALSE
.elbill_mn_reg <- recs_des %>%
  group_by(Region) %>%
  summarize(elec_bill = survey_mean(DOLLAREL)) %>%
  mutate(across(starts_with("elec"), \(x) str_c("$", prettyNum(round(x, 0), big.mark=",", digits=6))))
```

Nationally, the average household spent `r pull(.elbill_mn, elec_bill)` in 2015 with some variability by region. 
Households from the West spent `r .elbill_mn_reg %>% filter(Region=="West") %>% pull(elec_bill)` on electricity and in the South, they spent an average of `r .elbill_mn_reg %>% filter(Region=="South") %>% pull(elec_bill)`.

We use `srvyr::survey_prop()` to estimate a survey's proportion of categorical variables.

```{r}
#| label: desc-p-ex1
recs_des %>%
  group_by(Region) %>%
  summarize(p=survey_prop()) 
```

```{r}
#| label: desc-p-ex1-save
#| echo: FALSE
.preg <- recs_des %>%
  group_by(Region) %>%
  summarize(p=survey_prop()) %>%
  mutate(p=p*100 %>% signif(3))
```



`r .preg %>% filter(Region=="Northeast") %>% pull(p)`% of the households are in the Northeast, `r .preg %>% filter(Region=="Midwest") %>% pull(p)`% in the Midwest, and so on.

`survey_prop()` is essentially the same as using `survey_mean()` with a categorical variable and without specifying a numeric variable in the `x` argument. The following code will give us the same results as above:

```{r}
#| label: desc-p-ex2
recs_des %>%
  group_by(Region) %>%
  summarize(survey_mean())
```

It should be noted that there is a difference between using `survey_mean()` and `survey_prop()` when calculating confidence intervals and that will be discussed later when discussing variance types.

### Quantiles and medians

The `survey_median()` and `survey_quantile()` functions are analogous to `median` and `quantile`. This can be used to find the estimated median and quantiles of an outcome. Let's explore the syntax:

```r
survey_quantile(
  x,
  quantiles,
  na.rm = FALSE,
  vartype = c("se", "ci", "var", "cv"),
  level = 0.95,
  interval_type = c("mean", "beta", "xlogit", "asin", "score", "quantile"),
  qrule = c("math", "school", "shahvaish", "hf1", "hf2", "hf3", "hf4", "hf5", "hf6",
    "hf7", "hf8", "hf9"),
  df = NULL,
  ...
)

survey_median(
  x,
  na.rm = FALSE,
  vartype = c("se", "ci", "var", "cv"),
  level = 0.95,
  interval_type = c("mean", "beta", "xlogit", "asin", "score", "quantile"),
  qrule = c("math", "school", "shahvaish", "hf1", "hf2", "hf3", "hf4", "hf5", "hf6",
    "hf7", "hf8", "hf9"),
  df = NULL,
  ...
)
```

The arguments are:

* `x`: a variable, expression, or empty
* `quantiles`: A vector of quantiles to calculate
* `na.rm`: an indicator of whether missing values should be dropped, defaults to `FALSE`
* `vartype`: type(s) of variation estimate to calculate, defaults to `se` (standard error)
* `level`: a number or a vector indicating the confidence level, defaults to 0.95
* `interval_type`: method for calculating confidence interval
* `qrule`: rule for defining quantiles. The default is the lower end of the quantile interval ("math"). The midpoint of the quantile interval is the "school" rule. "hf1" to "hf9" are weighted analogues to type=1 to 9 in `quantile()`. "shahvaish" corresponds to a rule proposed by @shahvaish. See `vignette("qrule", package="survey")` for more information.
* `df`: (for `vartype = 'ci'`), a numeric value indicating degrees of freedom for the t-distribution
* `...`: Ignored and not used

As a reminder, the median is a special quantile which is the 50^{th} percentile. Quantiles are useful in learning about the distribution of an outcome. WHile we've shown what average electricity bills are, let's look into the quarantines, specifically, the first quartile (p=0.25), the median (p=0.5) and the third quartile (p=0.75) of electric bills. We also show the median to illustrate it is the same as the quantile where p=0.25.

```{r}
#| label: desc-quantile-oa
recs_des %>%
  summarize(
    elec_bill = survey_quantile(DOLLAREL, quantiles=c(0.25, .5, 0.75)),
    elec_bill_med = survey_median(DOLLAREL))
```

```{r}
#| label: desc-quantile-oa-save
#| echo: FALSE
.elbill_quant <- recs_des %>%
  summarize(
    elec_bill = survey_quantile(DOLLAREL, quantiles=c(0.25, .5, 0.75)),
    elec_bill_med = survey_median(DOLLAREL)) %>%
  mutate(
    across(c(starts_with("elec_bill")), \(x) str_c("$", prettyNum(round(x, 0), big.mark=",")))
  )
```

In the output above, we see the 3 quartiles, their respective standard errors, the median, and its standard error. Note that the 50^{th} percentile and the median are the same, as expected. The average electric bill for households was `r pull(.elbill_mn, elec_bill)` but the estimated median electric bill is `r pull(.elbill_quant, elec_bill_q50)`. We can also estimate the quantiles of electric bills by region as shown below:

```{r}
#| label: desc-quantile-reg
recs_des %>%
  group_by(Region) %>%
  summarize(
    elec_bill = survey_quantile(DOLLAREL, quantiles=c(0.25, .5, 0.75)))
```

While we can specify quantiles of 0 and 1 which represent the minimum and maximum, this is not recommended. It only returns the minimum and maximum of the respondents and cannot be extrapolated to the population as there is no valid definition of standard error.

```{r}
#| label: desc-quantile-minmax
recs_des %>%
  summarize(
    elec_bill = survey_quantile(DOLLAREL, quantiles=c(0, 1)))
```

### Standard deviation and variance

### Ratios

### Correlations

## Advanced topics

### Variance types {#Variance-types}

### Design effects

### Creating summary rows 

using cascade

### Conditional versus joint proportions

### Calculating estimates for many outcomes

Using map and across

## TOREMOVE Descriptive analysis using the {srvyr} package

### TOREMOVE Print total overall numbers in our output   

If we want to see the total overall numbers from our `survey_mean()` function, we can use `cascade`. `cascade` is similar to `summarize` but calculates summary statistics for the total of a group in addition to each group.

```{r}
recs_des %>%
  group_by(ACUsed) %>%
  cascade(ElBill = survey_mean(DOLLAREL,
                               na.rm = TRUE))
```

Note that the overall average electricity cost appears as `NA`. The average electricity cost for those who do not use AC is $972. For those who do use AC, it is $1435. Overall, it is $1375. <!--TODO: Add calculations-->

### TOREMOVE Removing `NA` for calculating results

If we run the example below, we get an error:

```{r survey_mean_ex2_sol}
#| error: true
recs_des %>%
  summarize(TD_mean = survey_mean(x = SummerTempDay))
```

Because of the `NA` in `SummerTempDay`, `survey_mean()` cannot calculate the average temperature. We can fix this with the argument `na.rm = TRUE`:

```{r}
recs_des %>%
  summarize(TD_mean = survey_mean(x = SummerTempDay,
                                  na.rm = TRUE))
```

The mean temperature set in a summer day in 72.4 degrees. <!--TODO: Calculate-->

### TOREMOVE Calculate proportions with confidence intervals

We calculate confidence intervals by setting the `vartype` to `ci` within `summarize` when using `survey_mean()` or `survey_mean()`. The confidence intervals gives us an upper and lower column for each method.

```{r survey_p_ci}
recs_des %>%
  group_by(Urbanicity) %>%
  summarize(pd = survey_prop(vartype = "ci") %>% 
              round(4))
```

69.6% of the responses are from people in urban areas, with a lower confidence interval bound of 65.2% and an upper confidence interval bound of 73.62%. <!--TODO: Add calculations-->

We can change the proportion method by adding `prop_method`. The available options are `"logit"`, `"likelihood"`, `"asin"`, `"beta"`, and `"mean"`.

As noted above, `svy_prop()` defaults to `proportion = TRUE`. Here, we rerun the previous function using the logit proportion method and with `proportion = FALSE`.

```{r}
recs_des %>%
  group_by(Urbanicity) %>%
  summarize(pl = survey_prop(
    proportion = FALSE,
    prop_method = "xlogit",
    vartype = "ci"
  ) %>% round(4))
```

Our results have changed slightly: 69.6% of the responses are from people in urban areas, with a lower confidence interval bound of 65.3% and an upper confidence interval bound of 73.8%. <!--TODO: Add calculations-->

### TOREMOVE Other functions that use survey methods

The {srvyr} package includes other functions for summarizing datasets, as mentioned in the section on types of descriptive analysis.

* Center: `survey_mean()`, `survey_median()`
* Count: `survey_count()`, `survey_total()`
* Distribution: `survey_ratio()`, `survey_prop()`
* Range: `survey_quantile()`
* Variance: `survey_var()`, `survey_sd()`

We will not cover each one in depth; however, the principles that we covered above apply.

### TOREMOVE Calculate conditional proportions with more than one group

Specifying more than one group calculates conditional proportions. Say we wanted to know the proportion of respondents who live in rural regions in the Northeast. After the `tbl_svy` object, we specify the two variables we want to calculate proportions for:

```{r survey_p_cond, tidy=FALSE}
recs_des %>%
  group_by(Region, Urbanicity) %>%
  summarize(
    p = survey_mean(),
    N = survey_total(),
    n = unweighted(n()),
    .groups = "drop"
  )
```

From the table, we see that the weighted proportion is 15.5%. Note that column `p` is the proportion of **respondents in rural areas by region**. That is, it is the weighted number of people in rural areas in the Northeast (3,257,375) divided by the weighted number of respondents in the Northeast (15,595,476 + 2,153,686 + 3,257,375).

### TOREMOVE Calculate joint proportions with more than one group

When we want to calculate proportions for multiple variables together as if they were a single variable, we use {srvyr}'s `interact`. We use `interact` within `group_by()` to calculate the  joint proportions of two or more variables.

For example, if we have a survey dataset with variables such as age, gender, and income, we could use `interact` to create summary statistics for each combination of age and gender or for each combination of income and gender. We can examine how these variables are related to each other and whether there are any differences or similarities between different groups.

In the example below, we calculate Region and Urbanicity together:

```{r survey_p_joint}
recs_des %>%
  group_by(interact(Region, Urbanicity)) %>%
  summarize(p = survey_mean(),
            N = survey_total(),
            .groups = "drop")
```

Running `survey_mean()` with `interact`, we see that 13.2% of the dataset is from the Northeast Urban Area, whereas 0.182% is from the Northeast Urban Cluster.

Since `interact` groups by multiple variables as if they were a single variable, the proportions in column `p` sum to 100% across more than a single grouping variable.

```{r}
recs_des %>%
  group_by(interact(Region, Urbanicity)) %>%
  summarize(p = survey_mean(),
            N = survey_total(),
            .groups = "drop") %>% 
  summarize(p_sum = sum(p))
```

### TOREMOVE Calculate proportions with design effects

Note above that functions `survey_total()`, `survey_mean()`, and `survey_prop()` have the argument `deff`. `deff` stands for Design Effect, the ratio of two variances. Use `deff = TRUE` argument to specify whether to return the design effect.

Calculating proportions with design effects is important when analyzing survey data that has been collected using a complex sampling design. Since a complex sampling design means that the probability of selecting each individual in the sample is different, this can lead to the observations in the sample being correlated with each other.

Design effects account for this correlation and adjust the standard errors of estimates, which can affect the significance of test statistics and the accuracy of confidence intervals. Calculating proportions with design effects is important because it helps to produce accurate estimates of population proportions that account for the complex nature of the survey data. 

Deff compares the variance of the current sampling, including its design elements, to the variance of a hypothetical simple random sample (SRS) of the same size. A Deff value less than 1 indicates that the sample design is more efficient than an SRS of the same size.

```{r survey_p_deff}
recs_des %>%
  group_by(interact(Region, Urbanicity)) %>%
  summarize(p = survey_mean(deff = TRUE),
            N = survey_total(),
            .groups = "drop")
```

Rerunning `survey_mean()` shows that `p_deff` is greater than 1 for the proportions. It is common for Deff to be greater than 1 when using complex sampling designs (such as in the case of RECS). A high Deff can occur due to various factors, such as stratification, clustering, or unequal selection probabilities, which are often used to improve the precision of estimates or to reduce sampling costs. These design features can increase the complexity of the sample design and lead to a higher Deff, but they can also improve the accuracy and representativeness of the survey estimates. 

## Exercises

We've created our survey object for the ANES 2020:

```{r}
#| label: desc-load-anes
#| cache: TRUE
library(osfr)
library(srvyr)
source("helper-fun/helper-functions.R")

anes <-
  read_rds_tsr("anes_2020.rds")

anes_des <- anes %>%
  as_survey_design(
    weights = Weight,
    strata = Stratum,
    ids = VarUnit,
    nest = TRUE
  )
```

1. How many females have a graduate degree? Hint: the variables `Gender` and `Education` will be useful.

2. What percentage of people identify as "Strong Democrat"? Hint: The variable `PartyID` indicates what party people identify with.

3. What percentage of people who voted in the 2020 election identify as "Strong Republican"? Hint: The variable `VotedPres2020` indicates whether someone voted in 2020.

4. What percentage of people voted in both the 2016 election and in the 2020 election?  Include the logit confidence interval. Hint: The variable `VotedPres2016` indicates whether someone voted in 2016.

5. What is the design effect for the proportion of people who voted early? Hint: The variable `EarlyVote2020` indicates whether someone voted early in 2020.

6. Is there a relationship between PartyID and whether people voted early?

7. Is there a relationship between PartyID and trust in the government? Hints: `TrustGovernment` indicates how strongly people trust the government. Use Wald as the `statistic` option.
