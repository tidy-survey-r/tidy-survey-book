# (PART) Analysis {-}

# Getting started {#c04-set-up}

```{r}
#| echo: false
knitr::opts_chunk$set(tidy = 'styler')
```

## Introduction

This chapter provides an overview of the packages, data, and design objects we use throughout this book. For a streamlined learning experience, we recommend taking the time to walk through the code provided and making sure everything is installed. As mentioned in Chapter \@ref(c02-overview-surveys), understanding how a survey was conducted helps us make sense of the results and interpret findings. Therefore, we provide background on the datasets used in examples and exercises and we walk through how to create the survey design objects necessary to begin analysis. Finally, we provide an overview of the {srvyr} package and the steps needed for analysis. If you have questions or face issues while going through the book, please report them in the book's GitHub repository: [https://github.com/tidy-survey-r/tidy-survey-book](https://github.com/tidy-survey-r/tidy-survey-book).

## Setup



### Packages

We use several packages throughout the book, but let's install and load specific ones for this chapter. Many functions in the examples and exercises are from three packages: {tidyverse}, {survey}, and {srvyr}. If they are not already installed, use the code below. The {tidyverse} and {survey} package can both be installed from the Comprehensive R Archive Network (CRAN). We use the GitHub development version of {srvyr} because of its additional functionality compared to the one on CRAN. Install the package directly from GitHub using the {remotes} package:

```{r}
#| label: setup-install-core1
#| eval: FALSE
install.packages(c("tidyverse", "survey"))
remotes::install_github("https://github.com/gergness/srvyr")
```

We bundled the datasets used in the book in an R package, {srvyrexploR}. Install it directly from GitHub using the {remotes} package:

```{r}
#| label: setup-install-core2
#| eval: FALSE
#| warning: FALSE
remotes::install_github("https://github.com/tidy-survey-r/srvyrexploR")
```

After installing these packages, load them using the `library()` function:

```{r}
#| label: setup-pkgs-core
#| error: FALSE
#| warning: FALSE
#| message: FALSE
library(tidyverse)
library(survey)
library(srvyr)
library(srvyrexploR)
```

The packages {broom}, {gt}, and {gtsummary} play a role in displaying output and creating formatted tables. Install them with the provided code^[Note: {broom} s already included in the tidyverse, so no separate installation is required]:

```{r}
#| label: setup-install-extra
#| eval: FALSE
install.packages(c("gt", "gtsummary"))
```

After installing these packages, load them using the `library()` function:

```{r}
#| label: setup-pkgs-extra
#| error: FALSE
#| warning: FALSE
#| message: FALSE
library(broom)
library(gt)
library(gtsummary)
```

Install and load the {censusapi} package to access the Current Population Survey (CPS), which we use to ensure accurate weighting of a key dataset in the book. Run the code below to install {censusapi}:

```{r}
#| label: setup-install-census
#| eval: FALSE
install.packages("censusapi")
```

After installing this package, load it using the `library()` function:

```{r}
#| label: setup-pkgs-census
#| error: FALSE
#| warning: FALSE
#| message: FALSE
library(censusapi)
```

Note that the {censusapi} package requires a Census API key, available for free from the U.S. Census Bureau website (refer to the package documentation for more information). It's recommended to include the Census API key in our R environment instead of directly in the code. After obtaining the API key, save it in your R environment by running `Sys.setenv()`:

```{r}
#| label: setup-census-api-setup
#| eval: FALSE
Sys.setenv(CENSUS_KEY="YOUR_API_KEY_HERE")
```

Then, restart the R session. Once the Census API key is stored, we can retrieve it in our R code with `Sys.getenv("CENSUS_KEY")`.

There are other packages used throughout the book. We list them in the Prerequisite boxes at the beginning of each chapter. As we work through the book, make sure to check the Prerequisite box and install any missing packages before proceeding.

### Data

As mentioned above, the {srvyrexploR} package contains the datasets used in the book. Once installed and loaded, explore the documentation using the `help()` function. Read the descriptions of the datasets to understand what they contain:

```{r}
#| label: setup-datapkg-help
#| eval: FALSE
help(package = "srvyrexploR")
```

This book uses two main datasets: the American National Election Studies [ANES -- @debell] and the Residential Energy Consumption Survey [RECS -- @recs-2020-tech]. We can load these datasets individually with the `data()` function by specifying the dataset name as an argument. In the code below, we load the `anes_2020` and `recs_2020` datasets into objects with their respective names:

```{r}
#| label: setup-data-readin
#| error: FALSE
#| warning: FALSE
#| message: FALSE
#| cache: TRUE
data(anes_2020)
data(recs_2020)
```

#### American National Election Studies (ANES) Data {-}

The ANES is a study that collects data from election surveys dating back to 1948. These surveys contain information on public opinion and voting behavior in U.S. presidential elections. They cover topics such as party affiliation, voting choice, and level of trust in the government. The 2020 survey, the data we use in the book, was fielded online, through live video interviews, or via computer-assisted telephone interviews (CATI). 

When working with new survey data, analysts should review the survey documentation (see Chapter \@ref(c03-understanding-survey-data-documentation)) to understand the data collection methods. The original ANES data contains variables starting with `V20` [@debell], so to assist with our analysis throughout the book, we created descriptive variable names. For example, the respondent's age is now in a variable called `Age`, and gender is in a variable called `Gender`. These descriptive variables are included in the {srvyrexploR} package, and Table \@ref(tab:anes-view-tab) displays the list of these renamed variables. A complete overview of all variables can be found in `r if (!knitr:::is_html_output()) 'the online Appendix ('`Appendix \@ref(anes-cb)`r if (!knitr:::is_html_output()) ')'`.

(ref:anes-view-tab) List of created variables in the ANES Data

```{r}
#| label: setup-anes-variables
#| echo: FALSE
#| warning: FALSE

anes_view <- anes_2020 %>%
  select(-matches("^V\\d")) %>%
  colnames() %>%
  as_tibble() %>%
  rename(`Variable Name` = value) %>%
  gt()
```

```{r}
#| label: anes-view-tab
#| echo: FALSE
anes_view %>%
  print_gt_book(knitr::opts_current$get()[["label"]])
```

Before beginning an analysis, it is useful to view the data to understand the available variables. The `dplyr::glimpse()` function produces a list of all variables, their types (e.g., function, double), and a few example values. Below, we remove variables containing numbers with `select(-matches("^V\\d"))` before using `glimpse()` to get a quick overview of the data with descriptive variable names:

```{r}
#| label: setup-anes-glimpse
anes_2020 %>%
  select(-matches("^V\\d")) %>%
  glimpse()
```

From the output, we can see there are `r nrow(anes_2020 %>% select(-matches("^V\\d"))) %>% formatC(big.mark = ",")` rows and `r ncol(anes_2020 %>% select(-matches("^V\\d"))) %>% formatC(big.mark = ",")` variables in the ANES data. This output also indicates that most of the variables are factors (e.g., `InterviewMode`), while a few variables are in double (numeric) format (e.g., `Age`).

#### Residential Energy Consumption Survey (RECS) Data {-}

RECS is a study that measures energy consumption and expenditure in American households. Funded by the Energy Information Administration, the RECS data are collected through interviews with household members and energy suppliers. These interviews take place in person, over the phone, via mail, and on the web. The survey has been fielded 14 times between 1950 and 2020. It includes questions about appliances, electronics, heating, air conditioning (A/C), temperatures, water heating, lighting, energy bills, respondent demographics, and energy assistance. 

As mentioned above, analysts should read the survey documentation (see Chapter \@ref(c03-understanding-survey-data-documentation)) to understand how the data was collected and implemented. Table \@ref(tab:recs-view-tab) displays the list of variables in the RECS data (not including the weights, which start with `NWEIGHT` and will be described in more detail in Chapter \@ref(c10-specifying-sample-designs)). An overview of all variables can be found in `r if (!knitr:::is_html_output()) 'the online Appendix ('`Appendix \@ref(recs-cb)`r if (!knitr:::is_html_output()) ')'`. 

(ref:recs-view-tab) List of Variables in the RECS Data

```{r}
#| label: setup-recs-variables
#| echo: FALSE
#| warning: FALSE

recs_view <- recs_2020 %>%
  select(-matches("^NWEIGHT")) %>%
  colnames() %>%
  as_tibble() %>%
  rename(`Variable Name` = value)  %>%
  gt()
```


```{r}
#| label: recs-view-tab
#| echo: FALSE
recs_view %>%
  print_gt_book("recs-view-tab")
```

Before starting an analysis, we recommend viewing the data to understand the types of data and variables that are included. The `dplyr::glimpse()` function produces a list of all variables, the type of the variable (e.g., function, double), and a few example values. Below, we remove the weight variables with `select(-matches("^NWEIGHT"))` before using `glimpse()` to get a quick overview of the data:

```{r}
#| label: setup-recs-glimpse
recs_2020 %>% 
  select(-matches("^NWEIGHT")) %>% 
  glimpse()
```

From the output, we can see that there are `r nrow(recs_2020 %>% select(-matches("^NWEIGHT"))) %>% formatC(big.mark = ",")` rows and `r ncol(recs_2020 %>% select(-matches("^NWEIGHT"))) %>% formatC(big.mark = ",")` non-weight variables in the RECS data. This output also indicates that most of the variables are in double (numeric) format (e.g., `TOTSQFT_EN`), with some factor (e.g., `Region`), Boolean (e.g., `ACUsed`), character (e.g., `REGIONC`), and ordinal (e.g., `YearMade`) variables.

### Design objects {#setup-des-obj}

The design object is the backbone for survey analysis. It is where we specify the sampling design, weights, and other necessary information to ensure we account for errors in the data. Before creating the design object, analysts should carefully review the survey documentation to understand how to create the design object for accurate analysis.

In this chapter, we provide details on how to code the design object for the ANES and RECS data used in the book. However, we only provide a high-level overview to get readers started. For a deeper understanding of creating these design objects for a variety of sampling designs, see Chapter \@ref(c10-specifying-sample-designs).

While we recommend conducting exploratory data analysis on the original data before diving into complex survey analysis (see Chapter \@ref(c12-pitfalls)), the actual analysis and inference should be performed with the survey design objects instead of the original survey data. This ensures that we appropriately apply the details of the survey design to our calculations. For example, the ANES data is called `anes_2020`. If we create a survey design object called `anes_des`, our analyses should begin with `anes_des` and not `anes_2020`.

#### American National Election Studies (ANES) Design Object {-}

The ANES documentation [@debell] details the sampling and weighting implications for analyzing the survey data. From this documentation and as noted in Chapter \@ref(c03-understanding-survey-data-documentation), the 2020 ANES data is weighted to the sample, not the population. To make generalizations for the population, we need to weigh the data against the full population count.The ANES methodology recommends using the Current Population Survey (CPS) to determine the number of the non-institutional U.S. citizens aged 18 or older living in the 50 U.S. states or D.C. in March of 2020.

We can use the {censusapi} package to obtain the information needed for the survey design object. The `getCensus()` function allows us to retrieve the CPS data for March (`cps/basic/mar`) in 2020 (`vintage = 2020`). Additionally, we extract several variables from the CPS:

- month (`HRMONTH`) and year (`HRYEAR4`) of the interview: to confirm the correct time period
- age (`PRTAGE`) of the respondent: to narrow the population to 18 and older (eligible age to vote) 
- citizenship status (`PRCITSHP`) of the respondent: to narrow the population to only those eligible to vote
- final person-level weight (`PWSSWGT`)

Detailed information for these variables can be found in the CPS data dictionary^[https://www2.census.gov/programs-surveys/cps/datasets/2020/basic/2020_Basic_CPS_Public_Use_Record_Layout_plus_IO_Code_list.txt].

```{r}
#| label: setup-anes-cps-get
#| message: false
#| cache: TRUE

cps_state_in <- getCensus(name = "cps/basic/mar",
                          vintage = 2020,
                          region = "state",
                          vars = c("HRMONTH", "HRYEAR4", 
                                   "PRTAGE", "PRCITSHP", "PWSSWGT"), 
                          key = Sys.getenv("CENSUS_KEY"))

cps_state <- cps_state_in %>%
  as_tibble() %>%
  mutate(across(.cols = everything(),
                .fns = as.numeric))
```

In the code above, we include `region = "state"`. The default region type for the CPS data is at the state level. While it's not required to include this, it can be helpful for understanding the geographical context of the data.

In `getCensus()`, we filtered the dataset by specifying the month (`HRMONTH == 3`) and year (`HRYEAR4 == 2020`) of our request. Therefore, we expect that all interviews within our output were conducted during that particular month and year. We can confirm that the data is from March of 2020 by running the code below:

```{r}
#| label: setup-anes-cps-date
cps_state %>%
  distinct(HRMONTH, HRYEAR4)
```

We can narrow down the dataset using the age and citizenship variables to include only individuals who are 18 years or older (`PRTAGE >= 18`) and have U.S. citizenship (`PRCITSHIP %in% c(1:4)`):

```{r}
#| label: setup-anes-cps-narrowresp
cps_narrow_resp <- cps_state %>%
  filter(PRTAGE >= 18,
         PRCITSHP %in% c(1:4))
```

To calculate the U.S. population from the filtered data, we sum the person weights (`PWSSWGT`):

```{r}
#| label: setup-anes-cps-targetpop
targetpop <- cps_narrow_resp %>%
  pull(PWSSWGT) %>%
  sum()
```

```{r}
#| label: setup-anes-cps-targetpop-display
#| eval: false
targetpop
```

```{r}
#| label: setup-anes-cps-targetpop-print
#| echo: false
scales::comma(targetpop)
```

The target population in 2020 is `r scales::comma(targetpop)`. This result gives us what we need to create the survey design object for estimating population statistics. Using the `anes_2020` data, we adjust the weighting variable (`V200010b`) using the target population we just calculated (`targetpop`). We determine the proportion of the total weight for each individual weights (`V200010b / sum(V200010b)`) and then multiply that proportion by the calculated target population.

```{r}
#| label: setup-anes-adjust
anes_adjwgt <- anes_2020 %>%
  mutate(Weight = V200010b / sum(V200010b) * targetpop) 
```

Once we have the adjusted weights, we can refer to the rest of the documentation to create the survey design. The documentation indicates that the study uses a stratified cluster sampling design. This means that we need to specify variables for `strata` and `ids` (cluster) and fill in the `nest` argument. The documentation provides guidance on which strata and cluster variables to use depending on whether we are analyzing pre- or post-election data. In this book, we analyze post-election data, so we need to use the post-election weight `V200010b`, strata variable `V200010d`, and PSU/cluster variable `V200010c`. Additionally, we set `nest=TRUE` to ensure the clusters are nested within the strata.

```{r}
#| label: setup-anes-des
anes_des <- anes_adjwgt %>%
  as_survey_design(weights = Weight,
                   strata = V200010d,
                   ids = V200010c,
                   nest = TRUE)

anes_des
```

We can examine this new object to learn more about the survey design, such that the ANES is a "Stratified 1 - level Cluster Sampling design (with replacement) With (101) clusters". Additionally, the output displays the sampling variables and then lists the remaning variables in the dataset. This design object will be used throughout this book to conduct survey analysis.

#### Residential Energy Consumption Survey (RECS) Design Object {-}

The RECS documentation [@recs-2020-tech] provides information on the survey's sampling and weighting implications for analysis. The documentation shows the 2020 RECS uses Jackknife weights, where the main analytic weight is `NWEIGHT`, and the Jackknife weights are `NWEIGHT1`-`NWEIGHT60`. In the survey design object code, we can specify these in the `weights` and `repweights` arguments, respectively. 

With Jackknife weights, additional information is required: `type`, `scale`, and `mse`.  Chapter \@ref(c10-specifying-sample-designs) goes into depth about each of these arguments, but to quickly get started, the documentation lets us know that `type=JK1`, `scale=59/60`, and `mse = TRUE`. We can use the following code to create the survey design object: 

```{r}
#| label: setup-recs-des

recs_des <- recs_2020 %>%
  as_survey_rep(
    weights = NWEIGHT,
    repweights = NWEIGHT1:NWEIGHT60,
    type = "JK1",
    scale = 59 / 60,
    mse = TRUE
  )

recs_des
```

Viewing this new object provides information about the survey design, such that the RECS is an "unstratified cluster jacknife (JK1) with 60 replicates and MSE variances".  Additionally, the output shows the sampling variables (`NWEIGHT1`-`NWEIGHT50`) and then lists the remaining variables in the dataset. This design object will be used throughout this book to conduct survey analysis.

This section walked through the installation and loading of several packages, introduced the survey data available in the {srvyrexploR} package, and provided context on creating survey design objects for the ANES and RECS datasets. With this foundational knowledge, we can follow the instructions listed in the Prerequisite boxes at the start of each chapter.


## Survey analysis process

The general process for estimation in the {srvyr} package is to:

1. Create a `tbl_svy` object (a survey object) using: `as_survey_design()` or `as_survey_rep()`

2. Subset data (if needed) using `filter()` (subpopulations)

3. Specify domains of analysis using `group_by()` 

4. Within `summarize()`, specify variables to calculate, including means, totals, proportions, quantiles, and more

In Section \@ref(setup-des-obj), we create the survey design objects for the ANES and RECS data that we use through this book. More details on how to create design objects is located in \@ref(c10-specifying-sample-designs).  Then, once we have the design object, we can then filter the data to any subpopulation of interest (if needed). It is important to only filter the data **after** creating the design object.  This ensures that we are accurately accounting for the survey design. Then we can use `group_by()`, `summarize()`, and other functions from the {survey} and {srvyr} packages to analyze the survey data.

## Similarities between {dplyr} and {srvyr} functions

One of the major advantages of using {srvyr} is that it applies {dplyr}-like syntax to the {survey} package. We can use pipes to specify a tbl_svy object, apply a function, and then feed that output into the next function's first argument. Functions follow the 'tidy' convention of snake_case function names. 

To help explain the similarities between {dplyr} functions and {srvyr} functions, we will use the `mtcars` and `iris` datasets that are built-in to R and `apistrat` data that comes in the {survey} package:

```{r}
#| label: setup-api-surveydata
data(mtcars)
data(iris)
data(api)

dstrata <- apistrat %>%
  as_survey_design(strata = stype, weights = pw)
```

The example below calculates the mean and median for the variable `mpg` (miles per gallon) in the `mtcars` dataset.

```{r}
#| label: setup-dplyr-examp
mtcars %>%
  summarize(mpg_mean = mean(mpg),
            mpg_median = median(mpg))
```

Similarly, in the next example, the variance and standard deviation of the variable `api00` are calculated for the tbl_svy object `dstrata`. Note the similarity in the syntax. When we dig into the functions later, we will show that the results output are similar in that one row is output for each group (if there are groups), but there will be more columns output. Specifically, by default, the standard error of the statistic is calculated in addition to the statistic.

```{r}
#| label: setup-srvyr-examp
dstrata %>%
  summarize(api00_mean = survey_mean(api00),
            api00_med = survey_median(api00))
```

The functions in {srvyr} also play nicely with other tidyverse functions. If we wanted to select columns that have something in common, we use {tidyselect} functions such as `starts_with()`, `num_range()`, etc. In the examples below, a combination of `across()` and `starts_with()` to calculate the mean of variables starting with "Sepal" in the `iris` data frame and then starting with `api` in the `dstrata` survey object.

```{r}
#| label: setup-dplyr-select
iris %>%
  summarize(across(starts_with("Sepal"), mean))
```

```{r}
#| label: setup-srvyr-select
dstrata %>%
  summarize(across(starts_with("api"), survey_mean))
```

We can use {dplyr} verbs such as `mutate()`, `filter()`, etc., on our survey object.

```{r}
#| label: setup-srvyr-mutate
dstrata_mod <- dstrata %>%
  mutate(api_diff = api00 - api99) %>%
  filter(stype == "E") %>%
  select(stype, api99, api00, api_diff, api_students = api.stu)

dstrata_mod

dstrata
```

Instead of data frames or tibbles, {srvyr} functions are meant for `tbl_svy` objects. Attempting to run data manipulation on non-`tbl_svy` objects will result in an error, as shown in the example below when using the mtcars data frame (which is not `tbl_svy` object).

```{r}
#| label: setup-nsobj-error
#| error: true
mtcars %>%
  summarize(mpg_mean = survey_mean(mpg))
```

A few functions in {srvyr} parallel functions in {dplyr}, such as `srvyr::summarize()` and `srvyr::group_by()`. Unlike {srvyr}-specific verbs, the package recognizes these parallel functions on a non-survey object. It will not error and instead give the equivalent output from {dplyr}:

```{r}
#| label: setup-nsobj-noerr
mtcars %>%
  srvyr::summarize(mpg_mean = mean(mpg))
```

Because this book focuses on survey analysis, most of our pipes will stem from a survey object. We will not include the namespace for each function (e.g., `srvyr::summarize()`).

Several functions in {srvyr} must be called within `srvyr::summarize()` with the exception of `srvyr::survey_count()` and `srvyr::survey_tally()` much like `dplyr::count()` and `dplyr::tally()` are not called within `dplyr::summarize()`. These verbs can be used in conjunction with `group_by()` or `by/.by`, applying the functions on a group-by-group basis to create grouped summaries.

```{r}
#| label: setup-dplyr-groupby
mtcars %>%
  group_by(cyl) %>%
  dplyr::summarize(mpg_mean = mean(mpg))
```

We use a similar setup to summarize data in {srvyr}.

```{r}
#| label: setup-srvyr-groupby
dstrata %>%
  group_by(stype) %>%
  summarize(api00_mean = survey_mean(api00),
            api00_median = survey_median(api00))
```
