# Specifying sample designs and replicate weights in {srvyr} {#c03-specifying-sample-designs}

::: {.prereqbox-header}
`r if (knitr:::is_html_output()) '### Prerequisites {- #prereq3}'`
:::

::: {.prereqbox data-latex="{Prerequisites}"}
For this chapter, here are the libraries and helper functions we will need:
```{r}
#| label: samp-setup-libraries
#| error: FALSE
#| warning: FALSE
#| message: FALSE
library(tidyverse)
library(survey)
library(srvyr)
library(tidycensus)
library(osfr)
source("helper-fun/helper-functions.R")
```

To help explain the different types of sample designs, this chapter will use the `api` and `scd` data that comes in the {survey} package:
```{r}
#| label: samp-setup-surveydata
data(api)
data(scd)
```

Additionally, we have created multiple analytic datasets for use in this book on a directory on OSF^[https://osf.io/gzbkn/?view_only=8ca80573293b4e12b7f934a0f742b957]. To load any data used in the book that is not included in existing packages, we have created a helper function `read_osf()`. This chapter uses data from the Residential Energy Consumption Survey (RECS), so we will use the following code to load the RECS data to use later in this chapter:
```{r}
#| label: samp-setup-recs
#| eval: FALSE
recs_in <- read_osf("recs_2015.rds")
```
:::

## Introduction

The primary reason for using packages like {survey} and {srvyr} is to incorporate the sampling design or replicate weights into estimates. By incorporating the sampling design or replicate weights, precision estimates (e.g., standard errors and confidence intervals) are appropriately calculated.

In this chapter, we will introduce common sampling designs and common types of replicate weights, the mathematical methods for calculating estimates and standard errors for a given sampling design, and the R syntax to specify the sampling design or replicate weights. While we will show the math behind the estimates, the functions in these packages will do the calculation. To deeply understand the math and the derivation, refer to @sarndal2003model, @wolter2007introduction, or @fuller2011sampling. 

The general process for estimation in the {srvyr} package is to:

1. Create a `tbl_svy` object (a survey object) using: `as_survey_design()` or `as_survey_rep()`

2. Subset data (if needed) using `filter()` (subpopulations)

3. Specify domains of analysis using `group_by()` 

4. Within `summarize()`, specify variables to calculate, including means, totals, proportions, quantiles, and more

This chapter includes details on the first step - creating the survey object. The other steps are detailed in the next several chapters.

## Common sampling designs

A sampling design is the method used to draw a sample. Both logistical and statistical elements are considered when developing a sampling design. When specifying a sampling design in R, the levels of sampling are specified along with the weights. Each record of a weight is constructed so that the particular record represents that many units in the population. For example, in a survey of 6th-grade students in the United States, the weight associated with each responding student reflects how many students that record represents. Generally, the sum of the weights corresponds to the total population size, although some studies may have the sum of the weights equal to the number of respondent records.

Some common terminology across the designs are:

  - **sample size**, generally denoted as $n$, is the number of units selected to be sampled
  - **population size**, generally denoted as $N$, is the number of units in the target population
  - **sampling frame**, the list of units from which the sample is drawn

### Simple random sample without replacement

The simple random sample (SRS) without replacement is a sampling design where a fixed sample size is selected from a sampling frame, and every possible subsample has an equal probability of selection.

  - **Requirements**: The sampling frame must include the entire population.
  - **Advantages**: SRS requires no information about the units apart from contact information.
  - **Disadvantages**: The sampling frame may not be available for the entire population. This design is not generally feasible for in-person data collection.
  - **Example**: Randomly select students in a university from a roster provided by the registrar's office. 

#### The math {-}

The estimate for the population mean of variable $y$ is: 

$$\bar{y}=\frac{1}{n}\sum_{i=1}^n y_i$$
where $\bar{y}$ represents the sample mean, $n$ is the total number of respondents (or observations), and $y_i$ is each individual value of $y$.

The estimate of the standard error of the mean is:

$$se(\bar{y})=\sqrt{\frac{s^2}{n}\left( 1-\frac{n}{N} \right)}$$ where

$$s^2=\frac{1}{n-1}\sum_{i=1}^n\left(y_i-\bar{y}\right)^2.$$

and $N$ is the population total. This standard error estimate might look very similar to equations in other applications except for the part on the right side of the equation: $1-\frac{n}{N}$. This is called the finite population correction factor (FPC), and if the size of the frame, $N$, is very large, the FPC is negligible, so it is often ignored.  

To estimate proportions, we define $x_i$ as the indicator if the outcome is observed. That is, $x_i=1$ if the outcome is observed, and $x_i=0$ if the outcome is not observed. Then the estimated proportion from an SRS design is:

$$\hat{p}=\frac{1}{n}\sum_{i=1}^n x_i $$
and the estimated standard error of the proportion is:

$$se(\hat{p})=\sqrt{\frac{\hat{p}(1-\hat{p})}{n-1}\left(1-\frac{n}{N}\right)} $$

#### The syntax {-} 

If a sample was drawn through SRS and had no nonresponse or other weighting adjustments, in R, specify this design as:

```r
srs1_des <- dat %>%
 as_survey_design(fpc = fpcvar)
```

where `dat` is a tibble or data.frame with the survey data, and `fpcvar` is a variable on the tibble indicating the sampling frame's size. If the frame is very large, sometimes the frame size is not provided. In that case, the FPC is not needed, and specify the design as:

```r
srs2_des <- dat %>%
 as_survey_design()
```

If some post-survey adjustments were implemented and the weights are not all equal, specify the design as:

```r
srs3_des <- dat %>%
 as_survey_design(weights = wtvar, fpc = fpcvar)
```

where `wtvar` is the variable for the weight on the data. Again, the FPC can be omitted if it is unnecessary because the frame is large.

#### Example {-} 

The {survey} package in R provides some example datasets that we will use throughout this chapter. The documentation provides detailed information about the variables. One of the example datasets we will use is from the Academic Performance Index (API). The API was a program administered by the California Department of Education, and the {survey} package includes a population file (sample frame) of all schools with at least 100 students and several different samples pulled from that data using different sampling methods. For this first example, we will use the `apisrs` dataset, which contains an SRS of 200 schools. For printing purposes, we create a new dataset called `apisrs_slim`, which sorts the data by the school district and school ID and subsets the data to only a few columns. The SRS sample data is illustrated below: 

```{r}
#| label: samp-des-apisrs-display
#| message: false
apisrs_slim <-
 apisrs %>%
 as_tibble() %>%
 arrange(dnum, snum) %>%
 select(cds, dnum, snum, dname, sname, fpc, pw)

apisrs_slim
```

Table \@ref(tab:apidata) provides details on all the variables in this dataset.

Table: (\#tab:apidata) Overview of Variables in `api` Data

Variable Name | Description
-- | --------
`cds` | Unique identifier for each school
`dnum` | School district identifier within county
`snum` | School identifier within district
`dname` | District Name
`sname` | School Name
`fpc` | Finite population correction factor (FPC)
`pw` | Weight

To create the `tbl_survey` object for this SRS data, the design should be specified as follows:

```{r}
#| label: samp-des-apisrs-des
apisrs_des <- apisrs_slim %>%
 as_survey_design(weights = pw, fpc = fpc)

apisrs_des
```

In the printed design object above, the design is described as an "Independent Sampling design," which is another term for SRS. The ids are specified as `1`, which means there is no clustering (a topic described later in this chapter), the FPC variable is indicated, and the weights are indicated. We can also look at the summary of the design object, and see the distribution of the probabilities (inverse of the weights) along with the population size and a list of the variables in the dataset. 

```{r}
#| label: samp-des-apisrs-summary
summary(apisrs_des)
```

### Simple random sample with replacement

Similar to the SRS design, the simple random sample with replacement (SRSWR) design randomly selects the sample from the entire sampling frame.  However, while SRS removes sampled units before selecting again, the SRSWR instead replaces each sampled unit before drawing again, so units can be selected more than once.

  - **Requirements**: The sampling frame must include the entire population.
  - **Advantages**: SRSWR requires no information about the units apart from contact information.
  - **Disadvantages**: The sampling frame may not be available for the entire population. This design is not generally feasible for in-person data collection. Units can be selected more than once, resulting in a smaller realized sample size as receiving the duplicate information from a single respondent does not provide additional information. For small populations, SRSWR has larger standard errors than SRS designs.
  - **Example**: A professor puts all students' names on paper slips and selects them randomly to ask students questions, but the professor replaces the paper after calling on the student so they can be selected again at any time.


#### The math {-}

The estimate for the population mean of variable $y$ is:

$$\bar{y}=\frac{1}{n}\sum_{i=1}^n y_i$$

and the estimate of the standard error of mean is:

$$se(\bar{y})=\sqrt{\frac{s^2}{n}}$$ where

$$s^2=\frac{1}{n-1}\sum_{i=1}^n\left(y_i-\bar{y}\right)^2.$$
To calculate the estimated proportion, we define $x_i$ as the indicator that the outcome is observed (as we did with SRS):

$$\hat{p}=\frac{1}{n}\sum_{i=1}^n x_i $$
and the estimated standard error of the proportion is:

$$se(\hat{p})=\sqrt{\frac{\hat{p}(1-\hat{p})}{n}} $$

#### The syntax {-} 

If you had a sample that was drawn through SRSWR and had no nonresponse or other weighting adjustments, in R, you should specify this design as:  

```r
srswr1_des <- dat %>%
 as_survey_design()
```

where `dat` is a tibble or data.frame containing your survey data.  This syntax is the same as a SRS design without an FPC.  Therefore, with large enough samples that do not have an FPC, the underlying formulas for SRS and SRSWR designs are the same.

If some post-survey adjustments were implemented and the weights are not all equal, specify the design as:

```r
srswr2_des <- dat %>%
 as_survey_design(weights = wtvar)
```

where `wtvar` is the variable for the weight on the data.

#### Example {-} 

The {survey} package does not include an example of SRSWR, so to illustrate this design we create an example from the population data provided. We call this new dataset `apisrswr`.

```{r}
#| label: samp-des-apisrs-wr-display
set.seed(409963)

apisrswr <- apipop %>%
 as_tibble() %>%
 slice_sample(n = 200, replace = TRUE) %>%
 select(cds, dnum, snum, dname, sname) %>%
 mutate(
  weight = nrow(apipop)/200
 )

head(apisrswr)

```

Because this is a SRS design *with replacement*, there will be duplicates in the data. It is important to keep the duplicates in the data for proper estimation, but for reference we can view the duplicates in the example data we just created.

```{r}
#| label: samp-des-apisrs-wr-duplicates

apisrswr %>%
 group_by(cds) %>%
 filter(n()>1) %>%
 arrange(cds)
```


We created a weight variable in this example data, which is the inverse of the probability of selection. To specify the sampling design for `apisrswr`, the following syntax should be used:

```{r}
#| label: samp-des-apisrswr-des
apisrswr_des <- apisrswr %>%
 as_survey_design(weights = weight)

apisrswr_des
summary(apisrswr_des)
```

In the chunk above, the design object is printed, and the object summary is shown. Both note that the sampling is done "with replacement" because no FPC was specified. The probabilities, which are derived from the weights, are summarized in the summary.

### Stratified sampling

A population is divided into mutually exclusive subpopulations (strata), and then samples are selected independently within each stratum.

  - **Requirements**: The sampling frame must include the information to divide the population into groups for every unit.
  - **Advantages**: This design ensures sample representation in all subpopulations. If the strata are correlated with survey outcomes, a stratified sample has smaller standard errors compared to a SRS sample of the same size.  Thus is a more efficient design.
  - **Disadvantages**: Auxiliary data may not exist to divide the sampling frame into groups, or the data may be outdated.
  - **Examples**: 
    - **Example 1**: A population of North Carolina residents could be separated into urban and rural areas, and then a SRS of residents from both rural and urban areas is selected independently. This ensures there are residents from both areas in the sample.
    - **Example 2**: There are three primary general-purpose law enforcement agencies in the US: local police, sheriff's departments, and state police. In a survey of law enforcement agencies, the agency type could be used to form strata. 

#### The math {-} 

Let $\bar{y}_h$ be the sample mean for stratum $h$, $N_h$ be the population size of stratum $h$, and $n_h$ be the sample size of stratum $h$. Then the estimate for the population mean under stratified SRS sampling is:

$$\bar{y}=\frac{1}{N}\sum_{h=1}^H N_h\bar{y}_h$$ 
and the estimate of the standard error of $\bar{y}$ is:

$$se(\bar{y})=\sqrt{\frac{1}{N^2} \sum_{h=1}^H N_h^2 s_h^2\left(1-\frac{n_h}{N_h}\right)} $$ 

where 
$$s_h^2=\frac{1}{n_h-1}\sum_{i=1}^{n_h}\left(y_{i,h}-\bar{y}_h\right)^2.$$

For estimates of proportions, let $\hat{p}_h$ be the estimated proportion in stratum $h$. Then the population proportion estimate is:

$$\hat{p}= \frac{1}{N}\sum_{h=1}^H N_h \hat{p}_h$$

where $H$ is the total number of clusters. The standard error of the proportion is:

$$se(\hat{p}) = \frac{1}{N} \sqrt{ \sum_{h=1}^H N_h^2 \frac{\hat{p}_h(1-\hat{p}_h)}{n_h-1} \left(1-\frac{n_h}{N_h}\right)}$$

#### The syntax {-} 

To specify a stratified SRS design in {srvyr} when using the FPC, that is, where the population sizes of the strata are not too large and are known, that is, you are using the FPC, specify the design as:

```r
stsrs1_des <- dat %>%
 as_survey_design(fpc = fpcvar, strata = stratvar)
```

where `fpcvar` is a variable on your data that indicates $N_h$ for each row, and `stratavar` is a variable indicating the stratum for each row. You can omit the FPC if it is not applicable. Additionally, you can indicate the weight variable if it is present where `wtvar` is a variable on your data with a numeric weight.

```r
stsrs2_des <- dat %>%
 as_survey_design(weights = wtvar, strata = stratvar)
```

#### Example {-} 

In the example API data, `apistrat` is a stratified random sample, stratified by school type (`stype`). As with the SRS example above, we sort and select specific variables for use in printing. The data are illustrated below, including a count of the number of cases per stratum:

```{r}
#| label: samp-des-apistrat-dis
apistrat_slim <-
 apistrat %>%
 as_tibble() %>%
 arrange(dnum, snum) %>%
 select(cds, dnum, snum, dname, sname, stype, fpc, pw)

apistrat_slim %>%
 count(stype, fpc)
```

The FPC is the same within each stratum, and 100 elementary schools were sampled, while 50 schools were sampled from both the middle and high school levels. This design should be specified as follows:

```{r}
#| label: samp-des-apistrat-des
apistrat_des <- apistrat_slim %>%
  as_survey_design(strata = stype,
                   weights = pw,
                   fpc = fpc)

apistrat_des
summary(apistrat_des)
```

When printing the object, it is specified as a "Stratified Independent Sampling design," also known as a stratified SRS, and the strata variable is included. Printing the summary we see a distribution of probabilities, as we saw with SRS, but we also see the sample and populations sizes by stratum.

### Clustered sampling

A population is divided into mutually exclusive subgroups called clusters or primary sampling units (PSUs). A random selection of PSUs is sampled, and then another level of sampling is done within these clusters. There can be multiple levels of this selection. Clustered sampling is often used when a list of the entire population is not available, or data collection involves interviewers needing direct contact with respondents.

  - **Requirements**: There must be a way to divide the population into clusters. Clusters are commonly structural such as institutions (e.g., schools, prisons) or geography (e.g., states, counties). 
  - **Advantages**: Clustered sampling is advantageous when data collection is done in person, so interviewers are sent to specific sampled areas rather than completely at random across a country. With cluster sampling, a list of the entire population is not necessary. For example, if sampling students, you do not need a list of all students but only a list of all schools. Once the schools are sampled, lists of students can be obtained within the sampled schools.
  - **Disadvantages**: Compared to a simple random sample for the same sample size, clustered samples generally have larger standard errors of estimates.
  - **Examples**: 
    - **Example 1**: Consider a study needing a sample of 6th-grade students in the United States, no list likely exists of all these students. However, it is more likely to obtain a list of schools that have 6th graders, so a study design could select a random sample of schools that have 6th graders. The selected schools can then provide a list of students to do a second stage of sampling where 6th-grade students are randomly sampled within each of the sampled schools. This is a one-stage sample design and will be the type of design we will discuss in the formulas below.
    - **Example 2**: Consider a study sending interviewers to households for a survey. This is a more complicated example that requires two levels of selection to efficiently use interviewers in geographic clusters. First, in the U.S., counties could be selected as the PSU, then Census block groups within counties could be selected as the secondary sampling unit (SSU). Households could then be randomly sampled within the block groups. This type of design is popular for in-person surveys as it reduces the travel necessary for interviewers.

#### The math {-}

Consider a population where there are $N$ clusters and $n$ clusters are sampled via SRS. Units within each sampled cluster are sampled via SRS as well. Let $M_i$ be the number of units in cluster $i$ and $\bar{y}_i$ be the sample mean of cluster $i$. Then, a ratio estimator of the population mean is:

$$\bar{y}=\frac{\sum_{i=1}^n M_i \bar{y}_i}{ \sum_{i=1}^n M_i}$$
Note this is a consistent but biased estimator. Often the population size is not known, so this is a method to estimate a mean without knowing the population size. The estimated standard error of the mean is:

$$se(\bar{y})=\frac{1}{\hat{N}_{pop} } \sqrt{\frac{N^2 (1-\frac{n}{N})}{n}\frac{1}{n-1} \sum_{i=1}^n (M_i\bar{y}_i -\hat{t}/N)^2 + \frac{N}{n} \sum_{i=1}^n \frac{M_i^2}{m_i}\left(1-\frac{m_i}{M_i}\right)s^2_i }$$
where $\hat{N}_{pop}$ is the estimated population size, $\hat{t}$ is the estimated total, and $s_i^2$ is the sample variance of cluster $i$.

For estimates of proportions, the estimated proportion is:

$$\hat{p}=\frac{\sum_{i=1}^n M_i \hat{p}_i}{ \sum_{i=1}^n M_i}$$

and the associated standard error estimate is:

$$se(\hat{p})=\frac{1}{\hat{N}_{pop} } \sqrt{\frac{N^2 (1-\frac{n}{N})}{n}\frac{1}{n-1} \sum_{i=1}^n (M_i\hat{p}_i -\hat{t}/N)^2 + \frac{N}{n} \sum_{i=1}^n \frac{M_i^2}{m_i}\left(1-\frac{m_i}{M_i}\right)s^2_i }$$

where $s^2_i$ is defined as:

$$s^2_i = \frac{m_hp_h(1-p_h)}{m_h-1}$$.

#### The syntax {-} 

To specify a two-stage clustered design without replacement, use the following syntax:

```r
clus2_des <- dat %>%
 as_survey_design(weights = wtvar, ids = c(PSU, SSU), fpc = c(N, M))
```

where `PSU` and `SSU` are the variables indicating the PSU and SSU identifiers, and `N` and `M` are the variables indicating the population sizes for each level (i.e., `N` is the number of clusters, and `M` is the number of units within each cluster). Note that `N` will be the same for all records (within a strata), and `M` will be the same for all records within the same cluster.

If clusters were sampled with replacement or from a very large population, a FPC is unnecessary. Additionally, only the first stage of selection is necessary regardless of whether the units were selected with replacement at any stage. The subsequent stages of selection are ignored in computation as their contribution to the variance is overpowered by the first stage (see @sarndal2003model or @wolter2007introduction for a more in-depth discussion). Therefore, the syntax below will yield the same estimates in the end:

```r
clus2wra_des <- dat %>%
 as_survey_design(weights = wtvar, ids = c(PSU, SSU))

clus2wrb_des <- dat %>%
 as_survey_design(weights = wtvar, ids = PSU)

```

#### Example {-} 

The `survey` package includes a two-stage cluster sample data, `apiclus2`, in which school districts were sampled, and then a random sample of five schools was selected within each district. For districts with fewer than five schools, all schools were sampled. School districts are identified by `dnum`, and schools are identified by `snum`. The variable `fpc1` indicates how many districts there are in California (`N`), and `fpc2` indicates how many schools were in a given district with at least 100 students (`M`). The data has a row for each school. In the data printed below, there are 757 school districts, as indicated by `fpc1`, and there are nine schools in District 731, one school in District 742, two schools in District 768, and so on as indicated by `fpc2`. For illustration purposes, the object `apiclus2_slim` has been created from `apiclus2`, which subsets the data to only the necessary columns and sorts data.

```{r}
#| label: samp-des-api2clus-dis
apiclus2_slim <-
  apiclus2 %>%
  as_tibble() %>%
  arrange(desc(dnum), snum) %>%
  select(cds, dnum, snum, fpc1, fpc2, pw)

apiclus2_slim
```

To specify this design in R, the following syntax should be used:

```{r}
#| label: samp-des-api2clus-des
apiclus2_des <- apiclus2_slim %>%
  as_survey_design(
    ids = c(dnum, snum),
    fpc = c(fpc1, fpc2),
    weights = pw
  )

apiclus2_des
summary(apiclus2_des)
```

The design objects are described as "2 - level Cluster Sampling design" and include the ids (cluster), FPC, and weight variables. The summary notes that the sample includes 40 first-level clusters (PSUs), which are school districts, and 126 second-level clusters (SSUs), which are schools. Additionally, the summary includes a numeric summary of the probabilities and the population size (number of PSUs) as 757.

## Replicate weights

Replicate weights are often included on analysis files instead of, or in addition to, the design variables (strata and PSUs). Replicate weights are used as another method to estimate variability and are often used specifically so that design variables are not published as a measure to limit disclosure risk. There are several types of replicate weights, including balanced repeated replication (BRR), Fay's BRR, jackknife, and bootstrap methods. An overview of the process for using replicate weights is as follows:

1. Divide the sample into subsample **replicates** that mirror the design of the sample
2. Calculate weights for each **replicate** using the same procedures for the full-sample weight (i.e., nonresponse and post-stratification)
3. Calculate estimates for each **replicate** using the same method as the full-sample estimate
4. Calculate the estimated variance, which will be proportional to the variance of the replicate estimates

The different types of replicate weights largely differ in step 1 - how the sample is divided into subsamples, and step 4 - which multiplication factors (scales) are used to multiply the variance.

### Balanced Repeated Replication (BRR) Method

The BRR method requires a stratified sample design with two PSUs in each stratum. Each replicate is constructed by deleting one PSU per stratum using a Hadamard matrix. For the PSU that is included, the weight is generally multiplied by two but may have other adjustments, such as post-stratification. A Hadamard matrix is a special square matrix with entries of +1 or -1 with mutually orthogonal rows. Hadamard matrices must have one row, two rows, or a multiple of four rows. To size of the Hadamard matrix is determined by the first multiple of 4 greater than or equal to the number of strata.  For example, if a survey had 7 strata, the Hadamard matrix would be an $8\times8$ matrix. Additionally, a survey with 8 strata would also have an $8\times8$ Hadamard matrix. An example of a $4\times4$ Hadamard matrix is below: 

$$ \begin{array}{rrrr} +1 &+1 &+1 &+1\\ +1&-1&+1&-1\\ +1&+1&-1&-1\\ +1 &-1&-1&+1 \end{array} $$
The columns specify the strata and the rows the replicate. In the first replicate, all the values are +1, so in each stratum, the first PSU would be used in the estimate. In the second replicate, the first PSU would be used in stratum 1 and 3, while the second PSU would be used in stratum 2 and 4. In the third replicate, the first PSU would be used in stratum 1 and 2, while the second PSU would be used in strata 3 and 4. Finally, in the fourth replicate, the first PSU would be used in strata 1 and 4, while the second PSU would be used in strata 2 and 3.

#### The math {-}

A weighted estimate for the full sample is calculated as $\hat{\theta}$, and then a weighted estimate for each replicate is calculated as $\hat{\theta}_r$ for $R$ replicates. The standard error of the estimate is calculated as follows:

$$se(\hat{\theta})=\sqrt{\frac{1}{R} \sum_{r=1}^R \left( \hat{\theta}_r-\hat{\theta}\right)^2}$$
Specifying replicate weights in R requires specifying the type of replicate weights, the main weight variable, the replicate weight variables, and other options. One of the key options is for `mse`. If `mse=TRUE`, variances are computed around the point estimate $(\hat{\theta})$, whereas if `mse=FALSE`, variances are computed around the mean of the replicates $(\bar{\theta})$ instead which looks like this: 

$$se(\hat{\theta})=\sqrt{\frac{1}{R} \sum_{r=1}^R \left( \hat{\theta}_r-\bar{\theta}\right)^2}$$ where $$\bar{\theta}=\frac{1}{R}\sum_{r=1}^R \hat{\theta}_r$$

The default option for `mse` is to use the global option of "survey.replicates.mse" which is set to `FALSE` initially unless a user changes it. To determine if `mse` should be set to `TRUE` or `FALSE`, read the survey documentation.  If there is no indication in the survey documentation, for BRR, set `mse` to `TRUE`.

#### The syntax {-} 

Replicate weights generally come in groups and are sequentially numbered, such as PWGTP1, PWGTP2, ..., PWGTP80 for the person weights in the American Community Survey (ACS) [@acs-pums-2021] or BRRWT1, BRRWT2, ..., BRRWT96 in the 2015 Residential Energy Consumption Survey (RECS) [@recs-2015-micro]. This makes it easy to use some of the tidy selection^[dplyr documentation on tidy-select: https://dplyr.tidyverse.org/reference/dplyr_tidy_select.html] functions in R. For example, if a dataset had WT0 for the main weight and had 20 BRR weights indicated WT1, WT2, ..., WT20, we can use the following syntax (both are equivalent):

```r
brr_des <- dat %>%
  as_survey_rep(
    weights = WT0,
    repweights = all_of(str_c("WT", 1:20)), 
    type = "BRR",
    mse = TRUE
  )

brr_des <- dat %>%
  as_survey_rep(
    weights = WT0,
    repweights = num_range("WT", 1:20),
    type = "BRR",
    mse = TRUE
  )
```

If a dataset had WT for the main weight and had 20 BRR weights indicated REPWT1, REPWT2, ..., REPWT20, the following syntax could be used (both are equivalent):

```r
brr_des <- dat %>%
  as_survey_rep(
    weights = WT,
    repweights = all_of(str_c("REPWT", 1:20)),
    type = "BRR",
    mse = TRUE
  )

brr_des <- dat %>%
  as_survey_rep(
    weights = WT,
    repweights = starts_with("REPWT"),
    type = "BRR",
    mse = TRUE
  )
```

If the replicate weight variables are in the file consecutively, the following syntax can also be used:

```r
brr_des <- dat %>%
  as_survey_rep(
    weights = WT,
    repweights = REPWT1:REPWT20,
    type = "BRR",
    mse = TRUE
  )
```

Typically, the replicate weights sum to a value similar to the main weight, as they are both supposed to provide population estimates. Rarely an alternative method will be used where the replicate weights have values of 0 or 2 in the case of BRR weights. This would be indicated in the documentation, and Section \@ref(und-surv-doc) and Chapter \@ref(c04-understanding-survey-data-documentation) discuss how to understand documentation. In this case, the replicate weights are not combined, and the option `combined_weights = FALSE` should be indicated, as the default value for this argument is TRUE. This specific syntax is shown below:

```r
brr_des <- dat %>%
  as_survey_rep(
    weights = WT,
    repweights = starts_with("REPWT"),
    type = "BRR",
    combined_weights = FALSE,
    mse = TRUE
  )
```

#### Example {-} 

The {survey} package includes a data example from Section 12.2 of @levy2013sampling. In this fictional data, two out of five ambulance stations were sampled from each of three emergency service areas (ESAs), thus BRR weights are appropriate with 2 PSUs (stations) sampled in each stratum (ESA). In the code below, BRR weights are created as was done by @levy2013sampling.

```{r}
#| label: samp-des-brr-display
scdbrr <- scd %>%
  as_tibble() %>%
  mutate(
    wt = 5 / 2,
    rep1 = 2 * c(1, 0, 1, 0, 1, 0),
    rep2 = 2 * c(1, 0, 0, 1, 0, 1),
    rep3 = 2 * c(0, 1, 1, 0, 0, 1),
    rep4 = 2 * c(0, 1, 0, 1, 1, 0)
  )

scdbrr
```

To specify the BRR weights, the following syntax is used:

```{r}
#| label: samp-scdbrr-des
scdbrr_des <- scdbrr %>%
  as_survey_rep(
    type = "BRR",
    repweights = starts_with("rep"),
    combined_weights = FALSE,
    weight = wt
  )

scdbrr_des

summary(scdbrr_des)
```

Note that `combined_weights` was specified as `FALSE` because these weights are simply specified as 0 and 2 and do not incorporate the overall weight. When printing the object, the type of replication is noted as Balanced Repeated Replicates, and the replicate weights and the weight variable are specified. Additionally, the summary lists the variables included.

### Fay's BRR Method

Fay's BRR method for replicate weights is similar to the BRR method in that it uses a Hadamard matrix to construct replicate weights. However, rather than deleting PSUs for each replicate, with Fay's BRR half of the PSUs have a replicate weight which is the main weight multiplied by $\rho$, and the other half have the main weight multiplied by $(2-\rho)$ where $0 \le \rho < 1$. Note that when $\rho=0$, this is equivalent to the standard BRR weights, and as $\rho$ becomes closer to 1, this method is more similar to jackknife discussed in the next section. To obtain the value of $\rho$, it is necessary to read the documentation as discussed in Section \@ref(und-surv-doc) and Chapter \@ref(c04-understanding-survey-data-documentation).

#### The math {-}

The standard error estimate for $\hat{\theta}$ is slightly different than the BRR, due to the addtion of the multipler of \rho, and is calculated as:

$$se(\hat{\theta})=\sqrt{\frac{1}{R (1-\rho)^2} \sum_{r=1}^R \left( \hat{\theta}_r-\hat{\theta}\right)^2}$$

#### The syntax {-} 

The syntax is very similar for BRR and Fay's BRR. If a dataset had WT0 for the main weight and had 20 BRR weights indicated as WT1, WT2, ..., WT20, and Fay's multiplier is 0.5, use the following syntax:

```r
fay_des <- dat %>%
  as_survey_rep(
    weights = WT0,
    repweights = num_range("WT", 1:20),
    type = "Fay",
    mse = TRUE,
    rho = 0.5
  )
```

#### Example {-} 

The 2015 RECS [@recs-2015-micro] uses Fay's BRR weights with the final weight as NWEIGHT and replicate weights as BRRWT1 - BRRWT96 with $\rho=0.5$. On the file, DOEID is a unique identifier for each respondent, TOTALDOL is the total cost of energy, TOTSQFT_EN is the total square footage of the residence, and REGOINC is the Census region. We have already read in the RECS data and created a dataset called `recs_in` above in the prerequisites.

To specify this design, use the following syntax:

```{r}
#| label: samp-des-recs-des
#| eval: TRUE
recs_des <- recs_in %>%
  as_survey_rep(
    weights = NWEIGHT,
    repweights = BRRWT1:BRRWT96,
    type = "Fay",
    rho = 0.5,
    mse = TRUE,
    variables = c(DOEID, TOTALDOL, TOTSQFT_EN, REGIONC)
  )

recs_des 

summary(recs_des) 
```

```{r}
#| label: samp-des-recs-des-full
#| echo: FALSE
# This is just for later use in book
recs_des <- recs_in %>%
  as_survey_rep(
    weights = NWEIGHT,
    repweights = BRRWT1:BRRWT96,
    type = "Fay",
    rho = 0.5,
    mse = TRUE
  )
```

In specifying the design, the `variables` option was also used to include which variables might be used in analyses. This is optional but can make your object smaller. When printing the design object or looking at the summary, the replicate weight type is re-iterated as `Fay's variance method (rho= 0.5) with 96 replicates and MSE variances`, and the variables are included. No weight or probability summary is included in this output as we have seen in some other design objects.

### Jackknife method

There are three jackknife estimators implemented in {srvyr} - Jackknife 1 (JK1), Jackknife n (JKn), and Jackknife 2 (JK2). The JK1 method can be used for unstratified designs, and replicates are created by removing one PSU at a time so the number of replicates is the same as the number of PSUs. If there is no clustering, then the PSU is the ultimate sampling unit (e.g., unit). 

The JKn method is used for stratified designs and requires two or more PSUs per stratum. In this case, each replicate is created by deleting one PSU from one stratum, so the number of replicates is the number of total PSUs across all strata. The JK2 method is a special case of JKn when there are exactly 2 PSUs sampled per stratum. For variance estimation, scaling constants must also be specified. 

#### The math {-}

For the JK1 method, the standard error estimate for $\hat{\theta}$ is calculated as:

$$se(\hat{\theta})=\sqrt{\frac{R-1}{R} \sum_{r=1}^R \left( \hat{\theta}_r-\hat{\theta}\right)^2}$$
The JKn method is a bit more complex, but the coefficients are generally provided with restricted and public-use files. For each replicate, one stratum has a PSU removed, and the weights are adjusted by $n_h/(n_h-1)$ where $n_h$ is the number of PSUs in the stratum. The coefficients in other strata are set to 1. Denote the coefficient that results from this process for replicate $r$ as $\alpha_r$, then the standard error estimate for $\hat{\theta}$ is calculated as:

$$se(\hat{\theta})=\sqrt{\sum_{r=1}^R \left(\alpha_r \hat{\theta}_r-\hat{\theta}\right)^2}$$

#### The syntax {-}

To specify the Jackknife method, the type would be `JK1`, `JKn`, or `JK2`. Additionally, the overall multiplier for JK1 is specified with the scale argument, whereas the replicate-specific multiplier ($\alpha_r$) is specified with the scales argument. 

Consider a case for the JK1 method where the multiplier, $(R-1)/R=19/20=0.95$ and the dataset had WT0 for the main weight and had 20 JK1 weights indicated WT1, WT2, ..., WT20, then the syntax would be

```r
jk1_des <- dat %>%
 as_survey_rep(weights = WT0, repweights= num_range("WT", 1:20),
        type="JK1", mse=TRUE, scale=0.95)
```

Consider a case for the JKn method where $\alpha_r=0.1$ for all replicates and the dataset had WT0 for the main weight and had 20 JK1 weights indicated as WT1, WT2, ..., WT20, then the syntax would be:

```r
jkn_des <- dat %>%
 as_survey_rep(weights = WT0, repweights= num_range("WT", 1:20),
        type="JKN", mse=TRUE, rscales=rep(0.1, 20))
```

#### Example {-}

The American Community Survey releases public use microdata with JK1 weights at the person and household level. This example includes data at the household level where the replicate weights are specified as WGTP1, ..., WGTP80, and the main weight is WGTP [@acs-5yr-doc]. Using the {tidycensus} package^[tidycensus package: https://walker-data.com/tidycensus/], data is downloaded from the Census API. For example, the code below has a request to obtain data for each person in each household in two Public Use Microdata Areas (PUMAs) in Durham County, NC^[Public Use Microdata Areas in North Carolina: https://www.census.gov/geographies/reference-maps/2010/geo/2010-pumas/north-carolina.html]. The variables requested are NP (number of persons in the household), BDSP (number of bedrooms), HINCP (household income), and TYPEHUGQ (type of household). By default, several other variables will come along, including SERIALNO (a unique identifier for each household), SPORDER (a unique identifier for each person within each household), PUMA, ST (state), person weight (PWGTP), and the household weights (WGTP, WGTP1, ..., WGTP80). Filtering to records where SPORDER=1 yields only one record per household and TYPEHUGQ=1 filters to only households and not group quarters. 

```{r}
#| label: samp-des-acsexamp
#| cache: TRUE
#| results: 'hide'
#| warning: false
pums_in <- get_pums(
  variables = c("NP", "BDSP", "HINCP"),
  state = "37", 
  puma = c("01301", "01302"), 
  rep_weights = "housing",
  year = 2021,
  survey = "acs5",
  variables_filter = list(SPORDER = 1, TYPEHUGQ = 1)
)
```

```{r}
#| label: samp-des-acsexampcont
#| cache: TRUE
#| dependson: 'acsexamp'
pums_in

acs_des <- pums_in %>%
  as_survey_rep(
    weights = WGTP,
    repweights = num_range("WGTP", 1:80),
    type = "JK1",
    mse = TRUE,
    scale = 4 / 80
  )

acs_des 

summary(acs_des) 
```

When printing the design object or looking at the summary, the replicate weight type is re-iterated as `Unstratified cluster jacknife (JK1) with 80 replicates and MSE variances`, and the variables are included. No weight or probability summary is included.

### Bootstrap Method

In bootstrap resampling, replicates are created by selecting random samples of the PSUs with replacement (SRSWR). If there are $M$ PSUs in the sample, then each replicate will be created by selecting a random sample of $M$ PSUs with replacement. Each replicate is created independently, and the weights for each replicate are adjusted to reflect the population, generally using the same method as how the analysis weight was adjusted.  

#### The math {-}

A weighted estimate for the full sample is calculated as $\hat{\theta}$, and then a weighted estimate for each replicate is calculated as $\hat{\theta}_r$ for $R$ replicates. Then the standard error of the estimate is calculated as follows:

$$se(\hat{\theta})=\sqrt{\alpha \sum_{r=1}^R \left( \hat{\theta}_r-\hat{\theta}\right)^2}$$ 

where $\alpha$ is the scaling constant.

#### The syntax {-}

If a dataset had WT0 for the main weight, 20 bootstrap weights indicated WT1, WT2, ..., WT20, and $\alpha=.02$, use the following syntax:

```r
bs_des <- dat %>%
 as_survey_rep(weights = WT0, repweights= num_range("WT", 1:20),
        type="bootstrap", mse=TRUE, scale=.02)

```

Note that the scale ($\alpha$) is usually provided in the documentation and is a constant, so it is not provided as a variable in the tibble.

#### Example {-}

Returning to the api example, we are going to create a dataset with bootstrap weights to use as an example. In this example, we construct a one-cluster design with fifty replicate weights.

```{r}
#| label: samp-des-genbs
apiclus1_slim <-
  apiclus1 %>%
  as_tibble() %>%
  arrange(dnum) %>%
  select(cds, dnum, fpc, pw)

set.seed(662152)
apibw <-
  bootweights(
    psu = apiclus1_slim$dnum,
    strata = rep(1, nrow(apiclus1_slim)),
    fpc = apiclus1_slim$fpc,
    replicates = 50
  )

bwmata <-
  apibw$repweights$weights[apibw$repweights$index,] * apiclus1_slim$pw

apiclus1_slim <- bwmata %>%
  as.data.frame() %>%
  set_names(str_c("pw", 1:50)) %>%
  cbind(apiclus1_slim) %>%
  as_tibble() %>%
  select(cds, dnum, fpc, pw, everything())

apiclus1_slim
```

The output of `apiclus1_slim` includes the same variables we have seen in other api examples (see Table \@ref(tab:apidata)), but now additionally includes bootstrap weights `pw1`, ..., `pw50`.  When creating the survey design object, we use the bootstrap weights as the replicate weights. Additionally, with replicate weights we need to include the scale ($\alpha$).  For this example we created, $\alpha$ is $15/(14*49)=0.02186589$.
<!-- Stephanie, I think it would be good if we could provide the original formula for bootstrap alpha.  Where do the 15, 14, and 49 come from?-->

```{r}
#| label: samp-des-bsexamp
api1_bs_des <- apiclus1_slim %>%
  as_survey_rep(
    weights = pw,
    repweights = pw1:pw50,
    type = "bootstrap",
    scale = 0.02186589,
    mse = TRUE
  )

api1_bs_des 

summary(api1_bs_des) 
```

As with other replicate design objects, when printing the object or looking at the summary, the replicate weights are provided along with the data variables.

## Understanding survey design documentation {#und-surv-doc}

SRS, stratified, and clustered designs are the backbone of sampling designs, and the features are often combined in one design. Additionally, rather than using SRS for selection, other sampling mechanisms are commonly used, such as probability proportional to size (PPS), systematic sampling, or selection with unequal probabilities, which are briefly described here. In PPS sampling, a size measure is constructed for each unit (e.g., the population of the PSU or the number of occupied housing units) and then units with larger size measures are more likely to be sampled. Systematic sampling is commonly used to ensure representation across a population. Units are sorted by a feature and then every $k$ units are selected from a random start point so the sample is spread across the population. In addition to PPS, other unequal probabilities of selection may be used. For example, in a study of establishments (e.g., businesses or public institutions) that conducts a survey every year, an establishment that recently participated (e.g., participated last year) may have a reduced chance of selection in a subsequent round to reduce the burden on the establishment. To learn more about sampling designs, refer to @valliant2013practical, @cox2011business, @cochran1977sampling, and @deming1991sample.

A common method of sampling is to stratify PSUs, select PSUs within the stratum using PPS selection, and then select units within the PSUs either with SRS or PPS. Reading survey documentation is an important first step in survey analysis to understand the design of the survey you are using and variables necessary to specify the design. Good documentation will highlight the variables necessary to specify the design. This is often found in User's Guides, methodology, analysis guides, or technical documentation (see Chapter \@ref(c04-understanding-survey-data-documentation) for more details).

#### Example {-}

For example, the 2017-2019 National Survey of Family Growth (NSFG)^[2017-2019 National Survey of Family Growth (NSFG): Sample Design Documentation - https://www.cdc.gov/nchs/data/nsfg/NSFG-2017-2019-Sample-Design-Documentation-508.pdf] had a stratified multi-stage area probability sample. In the first stage, PSUs are counties or collections of counties and are stratified by Census region/division, size (population), and MSA status. Within each stratum, PSUs were selected via PPS. In the second stage, neighborhoods were selected within the sampled PSUs using PPS selection. In the third stage, housing units were selected within the sampled neighborhoods. In the fourth stage, a person was randomly chosen within the selected housing units among eligible persons using unequal probabilities based on the person's age and sex. The public use file does not include all these levels of selection and instead has pseudo-strata and pseudo-clusters, which are the variables used in R to specify the design. As specified on page 4 of the documentation, the stratum variable is `SEST`, the cluster variable is `SECU`, and the weight variable is `WGT2017_2019`. Thus, to specify this design in R, use the following syntax:

```r
nsfg_des <- nsfgdata %>%
  as_survey_design(ids = SECU,
                   strata = SEST,
                   weights = WGT2017_2019)
```

## Exercises

<!-- For this chapter, the exercises entail reading public documentation to determine how to specify the survey design. While reading the documentation, be on the lookout for description of the weights and the survey design variables or replicate weights. -->

1. The American National Election Studies (ANES) collect data before and after elections approximately every four years around the presidential election cycle. Each year with the data release, a user's guide is also released^[ANES 2020 User's Guide: https://electionstudies.org/wp-content/uploads/2022/02/anes_timeseries_2020_userguidecodebook_20220210.pdf]. What is the syntax for specifying the analysis of the full sample post-election data?

```r
anes_des <- anes_data %>%
  as_survey_design(weight)
```

2. The General Social Survey is a survey that has been administered since 1972 on social, behavioral, and attitudinal topics. The 2016-2020 GSS Panel codebook^[2016-2020 GSS Panel Codebook Release 1a: https://gss.norc.org/Documents/codebook/2016-2020%20GSS%20Panel%20Codebook%20-%20R1a.pdf] provides examples of setting up syntax in SAS and Stata but not R. How would you specify the design in R?

```r
gss_des <- gss_data %>%
  as_survey_design(ids = VPSU_2,
                   strata = VSTRAT_2,
                   weights = WTSSNR_2)
```
