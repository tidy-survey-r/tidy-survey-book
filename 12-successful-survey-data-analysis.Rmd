# Recommendations for successful survey data analysis {#c12-recommendations}

```{r}
#| label: recommendations-styler
#| include: false
knitr::opts_chunk$set(tidy = 'styler')
```

::: {.prereqbox-header}
`r if (knitr:::is_html_output()) '### Prerequisites {- #prereq12}'`
:::

::: {.prereqbox data-latex="{Prerequisites}"}
For this chapter, load the following packages:
```{r}
#| label: recommendations-setup
#| error: FALSE
#| warning: FALSE
#| message: FALSE
library(tidyverse)
library(survey)
library(srvyr)
library(srvyrexploR)
```

To illustrate the importance of data visualization, we will discuss Anscombe's Quartet. The dataset can be replicated by running the code below:

```{r}
#| label: recommendations-anscombe-setup
anscombe_tidy <- anscombe %>%
  mutate(observation = row_number()) %>%
  pivot_longer(-observation, names_to = "key", values_to = "value") %>%
  separate(key, c("variable", "set"), 1, convert = TRUE) %>%
  mutate(set = c("I", "II", "III", "IV")[set]) %>%
  pivot_wider(names_from = variable, values_from = value)
```

We create an example survey dataset to explain potential pitfalls and how to overcome them in survey analysis. To recreate the dataset, run the code below:

```{r}
#| label: recommendations-example-dat
example_srvy <- tribble(
  ~id, ~region, ~q_d1,                 ~q_d2_1, ~gender, ~weight,
   1L,   1L,    1L,      "Somewhat interested", "female",  1740,
   2L,   1L,    1L,      "Not much interested", "female",  1428,
   3L,   2L,    NA,      "Somewhat interested", "female",   496,
   4L,   2L,    1L,      "Not much interested", "female",   550,
   5L,   3L,    1L,      "Somewhat interested", "female",  1762,
   6L,   4L,    NA,     "Very much interested", "female",  1004,
   7L,   4L,    NA,      "Somewhat interested", "female",   522,
   8L,   3L,    2L,      "Not much interested", "female",  1099,
   9L,   4L,    2L,      "Somewhat interested", "female",  1295,
   10L,  2L,    2L,      "Somewhat interested",   "male",   983
)

example_des <-
  example_srvy %>%
  as_survey_design(weights = weight)
```
:::

## Introduction

The previous chapters in this book aimed to provide the technical skills and knowledge required to run survey analyses. This chapter builds upon the best practices previously mentioned to present a curated set of recommendations aimed at running a *successful* survey analysis. We hope this list equips you with practical insights that assist in producing meaningful and reliable results.

## Applying the survey design appropriately

Understanding complex design factors such as clustering, stratification, and weighting is foundational to complex survey analysis. Each of these techniques impacts standard errors and variance, and we cannot treat complex surveys as unweighted simple random samples if we want to produce unbiased estimates.

Throughout the book, we highlight the importance of running functions like `filter()` after creating the survey design. This is another way to ensure we appropriately apply the survey design to our data.

## Beginning analysis with descriptive data analysis

When receiving a fresh batch of data, it's tempting to jump right into running models to find significant results. However, a successful data analyst begins by exploring the dataset. This involves running descriptive analysis on the dataset as a whole, as well as individual variables and combinations of variables. As described in Chapter \@ref(c05-descriptive-analysis), descriptive analyses should always precede statistical analysis to avoid avoidable (and potentially embarrassing) mistakes.

Even before applying weights, consider running cross-tabulations on the raw data. Do any results jump out?

Letâ€™s explore the example survey dataset introduced in the Prerequisites box, `example_srvy`. We run the code below on the unweighted data to inspect the `gender` variable:

```{r}
#| label: recommendations-example-desc
example_srvy %>% 
  group_by(gender) %>% 
  summarise(n = n())
```

The data shows that males make up 1 out of 10, or 10%, of the sample. Generally, we assume around a 50/50 split between male and female respondents in a population. The large female proportion could indicate either a unique sample or a potential error in the data. If we review the survey documentation and see this was a deliberate part of the design, we can continue our analysis using the appropriate methods. If this was not an intentional choice by the researchers, the results alert us that something may be incorrect in the data or our code, and we can verify if there's an issue by comparing the results with the weighted means.

Tables provide a quick check of our assumptions, but there is no substitute for graphs and plots to visualize the distribution of data. We might miss outliers or nuances if we scan only summary statistics. Anscombe's Quartet demonstrates the importance of visualization in analysis. Let's say we have a dataset with x- and y- variables in an object called `anscombe_tidy`. Let's take a look at how the dataset is structured:

```{r}
#| label: recommendations-anscombe-head
head(anscombe_tidy)
```

We can begin by checking one set of variables. For Set I, the x-variables have an average of 9 with a standard deviation of 3.3; for y, we have an average of 7.5 with a standard deviation of 2.03. The two variables have a correlation of 0.81.

```{r}
#| label: recommendations-anscombe-calc
anscombe_tidy %>% 
  filter(set == "I") %>% 
  summarize(
    x_mean = mean(x),
    x_sd = sd(x),
    y_mean = mean(y),
    y_sd = sd(y),
    correlation = cor(x, y)
  )
```

These are useful statistics. We can note that the data doesn't have high variability and the two variables are strongly correlated.

Now, let's check all of our variables. Notice anything interesting?

```{r}
#| label: recommendations-anscombe-calc-2
anscombe_tidy %>% 
  group_by(set) %>%
  summarize(
    x_mean = mean(x),
    x_sd = sd(x, na.rm = TRUE),
    y_mean = mean(y),
    y_sd = sd(y, na.rm = TRUE),
    correlation = cor(x, y)
  )
```

The summary results for these four variables are nearly identical! We might assume that the distribution for each of them is similar. A data visualization can help confirm our assumptions.

```{r}
#| label: recommendations-anscombe-plot
ggplot(anscombe_tidy, aes(x, y)) +
  geom_point() +
  facet_wrap( ~ set) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal()
```

When reviewing the plots, it becomes apparent that the distributions are not the same at all. Each set of points results in different shapes and distributions. Imagine sharing each plot with a shareholder, how one would describe the data, and how different the interpretations will be.

With survey data, we may not always have continuous data that we can plot like Anscombe's Quartet. However, if the dataset does contain continuous data or other types of data which would benefit from a visual representation, we recommend taking the time to graph distributions and correlations.

## Using the appropriate variable types

When we pull the data from surveys into R, the data may be listed as character, factor, numeric, or logical/Boolean. Let's revisit the `example_srvy` data. Taking a `glimpse()` of the data gives us insight into what it contains:

```{r}
#| label: recommendations-example-dat-glimpse
example_srvy %>%
  glimpse()
```

While the output shows that `q_d2_1` is a character, R does not clearly indicate that it is an ordinal variable (Very interested / somewhat interested / Not interested). We will watch to keep an eye out on any ordinal variables to make sure we can make meaningful comparisons in our analyses.

We may also notice that there is a column called `region`, which is imported as a number. This is a good hint to use the questionnaire and codebook along with the data to find out if the values actually reflect a number or are perhaps a coded categorical variable (see Chapter \@ref(c03-understanding-survey-data-documentation) for more details). Otherwise, without carefully reviewing the documentation, we may accidentally calculate the mean across all numeric variables:

```{r}
#| label: recommendations-example-dat-num-calc
example_des %>%
  select(-weight) %>%
  summarize(across(where(is.numeric), ~ survey_mean(.x, na.rm = TRUE)))
```

R will calculate the mean even if it is not appropriate, leading to the common mistake of applying an average to categorical values instead of a proportion function. If the variable name is difficult to interpret, we might accidentally report an average region of `r round(example_des %>% summarize(across(where(is.numeric), ~ survey_mean(.x, na.rm = TRUE))) %>% pull(region), 2)` to our stakeholders. Checking that our variables are of the appropriate type will avoid this pitfall and ensure the measures and models are suitable for the type of variable.

## Improving your debugging skills

It is common for analysts working in R to come across warning or error messages. It's important to improve our debugging skills - our ability to find and fix issues - to ensure we can proceed with our work and avoid mistakes.

We've discussed a few examples in this book. For example, if we calculate an average with `survey_mean()` and we get `NA` instead of a number, it may be because there are missing values in our column.

```{r}
#| label: recommendations-missing-dat
example_des %>%
  summarize(mean = survey_mean(q_d1))
```

Including the `na.rm = TRUE` would resolve the issue:

```{r}
#| label: recommendations--missing-dat-fix
example_des %>%
  summarize(mean = survey_mean(q_d1, na.rm = TRUE))
```

Often, debugging involves interpreting the message from R. For example, if our code results in this error:

```
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
  contrasts can be applied only to factors with 2 or more levels
```

We can see that the error has to do with a function requiring a factor with two or more levels, and that it has been applied to something else. This ties back to our section on using appropriate variable types. We can check the variable of interest to examine whether it's the correct type.

The internet also offers many resources for debugging. Searching for a specific error message can often lead us to a solution. In addition, we can post on community forums like Posit Community, [https://community.rstudio.com/](https://community.rstudio.com/), for direct help from others.

## Drawing significant conclusions appropriately

As mentioned in Chapter \@ref(c02-overview-surveys), determining the study design is a lengthy and intensive process. Careful consideration is taken to reduce the sampling error in hopes that our results are not solely due to how the sample was chosen. This allows us to say something is "statistically significant," meaning that our result can be attributed to an effect, a relationship between variables, or a difference between groups rather than purely to chance.

As mentioned above, we should account for the survey design before we draw significance from our results. We also want to carefully consider how we manage missing data, as described in Chapter \@ref(c11-missing-data). Finally, we want to avoid model overfitting by using too many variables in our formulas. Our model may be too tailored to generalize to new data.

It's important to note that even significant results do not mean that it is meaningful or important. A large enough sample can produce statistically significant results. Therefore, we want to look at our results in context, such as comparing them with results from other studies or analyzing them in conjunction with confidence intervals and other measures. As analysts, we also need to curate what we report, including the many significant results that we find.