\mainmatter

# Introduction {#c01}

```{r}
#| label: globaloptions
#| include: FALSE
options(width=72)
```

Surveys of random samples are collected to gather information and provide inference to populations. Initially statisticians argued to obtain purposefully representative samples but over time the field of probability samples grew. This book discusses the last part of the survey process, the analysis. We assume that you have survey data that has already been collected and weighted, with the most common scenario being that you are using a public use microdata file. In this book, we will discuss descriptive analysis, statistical testing, and modeling as well as some best practices in coding and how to present results. We use real data and provide realistic examples. We wanted a text available for people who are new to survey analysis but might already have some statistics and R background 

Most survey microdata distributed publicly includes analysis weights and design variables. These variables are included with the data to correctly calculate estimates. Without using these weights, results will likely be biased. Accounting for the sampling design is also necessary to calculate correct variance estimates and test statistics. However, as will be discussed in Chapter \@ref(c05), these calculations can be complex. Several general purpose statistical software have functions to correctly account for these features in analysis including SAS, Stata, SUDAAN, and R. This book will use R and a combination of both the {survey} and {srvyr} packages and is meant for people who already have experience in R, namely in using the tidyverse.

In 2003, the {survey} package was released on CRAN and has been continuously developed over time^[https://cran.r-project.org/src/contrib/Archive/survey/]. This package, primarily developed by Thomas Lumley, is extensive and includes the following features:

- Estimates of point estimates and their associated variances including means, totals, ratios, quantiles, and proportions
- Estimation of regression models including generalized linear models, log linear models, and survival curves
- Variances by Taylor linearization or by replicate weights (BRR, jackknife, bootstrap, multistage bootstrap, or user-supplied)
- Hypothesis testing for means, proportions, and more

The {srvyr} package in R builds on the {survey} package and provides wrappers for functions that align with the tidyverse philosophy which is our motivation for using and recommending this package. We believe it is easy to use for R users who already use {tidyverse} packages. For example, variables to many functions in the {survey} package are passed as formulas but in the {srvyr} package, variable names are passed using tidy select^[https://dplyr.tidyverse.org/reference/dplyr_tidy_select.html].  The {srvyr} package is written to easily use piping of functions which leads to analyses which are easy to follow. Several common functions from {dplyr} can be applied to survey objects including `filter()`, `mutate()`, and `summarize()`. 

The modeling functionality of the {survey} package are not ported over to tidy versions in the {srvyr} package so this book will use the {survey} package when discussing modeling and hypothesis testing.

What to expect in this book:

- Chapter \@ref(c02): An overview of surveys and the process of designing surveys. This is only an overview, and we include many references to get more in-depth knowledge
- Chapter \@ref(c05): Specifying sampling designs. Descriptions of common sampling designs, when they are used, the math behind the mean and standard error estimates, how to specify the designs in R, and examples using real data.
- Chapter \@ref(understanding-survey-data-documentation): Understanding survey documentation. How to read the various components of survey documentation, working with missing data, and how to find the documentation.
- Chapter \@ref(c06): Descriptive analyses. Calculating point estimates along with their standard errors, confidence intervals, and design effects.
- Chapter \@ref(c07): Statistical testing. Testing for differences between groups including comparisons of means and proportions as well as goodness of fit tests, tests of independence, and tests of homogeneity.
- Chapter \@ref(c08): Modeling. Linear regression, ANOVA, and logistic regression.
- Chapter \@ref(c09): Communicating results. Developing analysis plans, describing results, reproducibility, making publishable tables and graphs, and helpful functions.
- Chapter \@ref(c10-ncvs-vignette): National Crime Victimization Survey Vignette. A vignette on how to analyze data from the NCVS, a survey in the US which collects information on crimes and their characteristics. This illustrates an analysis which requires multiple files to calculate victimization rates.
- Chapter \@ref(c11-ambarom-vignette): AmericasBarometer Vignette. A vignette on how to analyze data from the AmericasBarometer, a survey of attitudes, evaluations, experiences, and behavior in countries in the Western Hemisphere. This includes how to make choropleth maps with survey estimates.

What not to expect in this book:

- Survey methodology - we only provide a primer on methodology
- Statistical theory - we only provide a bit of formulas throughout
- Weighting - we assume you are using a analysis-ready data file with weights