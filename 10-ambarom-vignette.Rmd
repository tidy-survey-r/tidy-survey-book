# AmericasBarometer Vignette {#c10-ambarom-vignette}

<!-- author review -->

The AmericasBarometer surveys are conducted by the LAPOP Lab, and they aim to understand public opinions about democracy across the Americas. The study launched in 2004/2005 with 11 countries, with the participating countries growing and fluctuating over time. The key aspect of these surveys is that they use a consistent methodology across multiple countries. In 2021, the study included 22 countries ranging from Canada in the north to Chile and Argentina in the south^[https://www.vanderbilt.edu/lapop/about-americasbarometer.php].

Historically, the surveys were administered through face-to-face household interviews. However, due to the COVID-19 pandemic, the study had to adapt significantly. They expanded the use of random-digit dialing (RDD) for mobile phones in all countries except the United States and Canada. ^[https://www.vanderbilt.edu/lapop/ab2021/AB2021-Technical-Report-v1.0-FINAL-eng-030722.pdf]. In Canada, LAPOP collaborated with the Environics Institute to collect data from a panel of Canadians using a web survey^[http://datasets.americasbarometer.org/database/files/ABCAN2021-Technical-Report-v1.0-FINAL-eng-110921.pdf]. In the United States, YouGov conducted the survey on behalf of LAPOP through a web survey among their panelists^[http://datasets.americasbarometer.org/database/files/ABUSA2021-Technical-Report-v1.0-FINAL-eng-110921.pdf].

The AmericasBarometer survey includes a core set of questions that are asked across the countries, but not all questions are asked everywhere. Additionally, some questions are only asked to half of the respondents within a country, presumably to reduce the burden as different sections are randomized to different respondents.^[https://www.vanderbilt.edu/lapop/ab2021/AB2021-Core-Questionnaire-v17.5-Eng-210514-W-v2.pdf] 

## Data Structure

Each country and each year has its own files. In this vignette, we will be using data from 2021, namely version v1.2. These are not available on the book's repository, but one can download the raw files directly from the LAPOP website^[http://datasets.americasbarometer.org/database/index.php] (@lapopdat). To read the survey files into R and ignore the Stata labels, we recommend the following code (replacing the file path accordingly):

```r
library(haven)
library(purrr)

stata_files <-
  list.files(here::here("RawData", "LAPOP_2021"), "*.dta")

read_stata_unlabeled <- function(file) {
  read_stata(file) %>%
    zap_labels() %>%
    zap_label()
}

lapop_in <- here::here("RawData", "LAPOP_2021", stata_files) %>%
  map_df(read_stata_unlabeled)
```

The code above reads all files with the extension `.dta` in and stacks them into one tibble. After doing this, we selected a subset of variables for this vignette.

The core questionnaire is a valuable resource for understanding variables that are used across different countries.^[https://www.vanderbilt.edu/lapop/ab2021/AB2021-Core-Questionnaire-v17.5-Eng-210514-W-v2.pdf] 

## Preparing files

In the dataset, some variables are represented as numeric codes without intuitive names, which may make them hard to interpret. The next step involves creating derived variables and preparing the data for analysis.  We create derived variables with relevant factors and informative names using the core questionnaire as a codebook. This will facilitate the following analysis steps.

```{r}
#| label: ambarom-setup
#| warning: false
library(tidyverse)
library(srvyr)
library(sf)
library(rnaturalearth) # Getting world maps 
library(rnaturalearthdata)
library(gt)
library(ggpattern)
```

```{r}
#| label: ambarom-read
#| message: false
#| cache: TRUE
library(osfr)
source("helper-fun/helper-functions.R")

ambarom_in <- read_rds_tsr("lapop_2021.rds") 
```

```{r}
#| label: ambarom-derive
ambarom <- ambarom_in %>%
  mutate(
    Country = factor(
      case_match(
        pais,
        1 ~ "Mexico",
        2 ~ "Guatemala",
        3 ~ "El Salvador",
        4 ~ "Honduras",
        5 ~ "Nicaragua",
        6 ~ "Costa Rica",
        7 ~ "Panama",
        8 ~ "Colombia",
        9 ~ "Ecuador",
        10 ~ "Bolivia",
        11 ~ "Peru",
        12 ~ "Paraguay",
        13 ~ "Chile",
        14 ~ "Uruguay",
        15 ~ "Brazil",
        17 ~ "Argentina",
        21 ~ "Dominican Republic",
        22 ~ "Haiti",
        23 ~ "Jamaica",
        24 ~ "Guyana",
        40 ~ "United States",
        41 ~ "Canada"
      )
    ),
    Gender = fct_reorder(
      case_match(q1tb,
                 1 ~ "Male",
                 2 ~ "Female",
                 3 ~ "Other"),
      q1tb,
      .na_rm = FALSE
    ),
    CovidWorry = fct_reorder(
      case_match(
        covid2at,
        1 ~ "Very worried",
        2 ~ "Somewhat worried",
        3 ~ "A little worried",
        4 ~ "Not worried at all"
      ),
      covid2at,
      .na_rm = FALSE
    ),
    EconSituation = fct_reorder(
      case_match(idio2,
                 1 ~ "Better",
                 2 ~ "Same",
                 3 ~ "Worse"),
      idio2,
      .na_rm = FALSE
    ),
    EconSituationWorse_Reason = fct_reorder(
      case_match(idio2cov,
                 1 ~ "Coronavirus",
                 2 ~ "Another reason"),
      idio2cov,
      .na_rm = FALSE
    ),
    CommunityTrustworthy = fct_reorder(
      case_match(
        it1,
        1 ~ "Very trustworthy",
        2 ~ "Somewhat trustworthy",
        3 ~ "Not very trustworthy",
        4 ~ "Untrustworthy"
      ),
      it1,
      .na_rm = FALSE
    ),
    CoupCorruption = fct_reorder(
      case_match(jc13,
                 1 ~ "Justified",
                 2 ~ "Not justified"),
      jc13,
      .na_rm = FALSE
    ),
    LeaderApproval = fct_reorder(
      case_match(
        m1,
        1 ~ "Very good",
        2 ~ "Good",
        3 ~ "Neither good nor bad (fair)",
        4 ~ "Bad",
        5 ~ "Very bad"
      ),
      m1,
      .na_rm = FALSE
    ),
    Employment = fct_reorder(
      case_match(
        ocup4a,
        c(1, 2) ~ "Working",
        3 ~ "Looking for a job",
        4 ~ "Student",
        5 ~ "Homemaker",
        6 ~ "Retired or disabled",
        7 ~ "Not working, not looking for job"
      ),
      ocup4a,
      .na_rm = FALSE
    ),
    IntentionMigrate = fct_reorder(
      case_match(q14,
                 1 ~ "Yes",
                 2 ~ "No"), q14, .na_rm = FALSE
      ),
    NewsFrequency = fct_reorder(
      case_match(
        gi0n,
        1 ~ "Daily",
        2 ~ "Few times a week",
        3 ~ "Few times a month",
        4 ~ "Few times a year",
        5 ~ "Never"
      ),
      gi0n,
      .na_rm = FALSE
    )
  ) %>%
  rename(
    Educ_NotInSchool = covidedu1_1,
    Educ_NormalSchool = covidedu1_2,
    Educ_VirtualSchool = covidedu1_3,
    Educ_Hybrid = covidedu1_4,
    Educ_NoSchool = covidedu1_5,
    Age = q2,
    HHSize = q12c,
    HHChildren = q12bn,
    ComputerTablet = r15,
    BroadbandInternet = r18n,
    Internet = r18
  )


ambarom %>% count(Country, pais) %>% print(n = 22)
ambarom %>% count(Gender, q1tb)
ambarom %>% count(EconSituation, idio2)
ambarom %>% count(EconSituationWorse_Reason, idio2cov)
ambarom %>% count(CommunityTrustworthy, it1)
ambarom %>% count(CoupCorruption, jc13)
ambarom %>% count(LeaderApproval, m1)
ambarom %>% count(Employment, ocup4a)
ambarom %>% count(IntentionMigrate, q14)
ambarom %>% count(NewsFrequency, gi0n)
```

## Survey design objects

The technical report is the best source to understand how to specify the sampling design in R^[https://www.vanderbilt.edu/lapop/ab2021/AB2021-Technical-Report-v1.0-FINAL-eng-030722.pdf]. The data includes two weight variables: `wt` and `weight1500`. The first weight variable `wt` is country-specific and sums to the sample size but is calibrated to reflect each country's demographics. The second weight variable `weight1500` sums to 1500 for each country and is indicated as the weight for multi-country analyses. While the documentation does not directly state this, the example Stata syntax `svyset upm [pw=weight1500], strata(strata)` indicates the variable `upm` is the PSU clustering variable, and `strata` is the strata variable. We set up the design object as follows: 

```{r}
#| label: ambarom-design
ambarom_des <- ambarom %>%
  as_survey_design(ids = upm,
                   strata = strata,
                   weight = weight1500)
```

One interesting thing to note is that while these weights allow us to compare countries, they do not account for the different sizes of countries to estimate multi-country statistics. For example, Canada has approximately 10% of the population of the United States, but an estimate that uses records from both countries would weigh them equally. Multi-country estimates may not accurately reflect the true proportions of each country's contribution to the combined analysis.

## Calculating estimates and making tables

This survey was administered in 2021 between March and August, with the specific timeframe varying by country^[For country-specific dates, refer to Table 2 in  https://www.vanderbilt.edu/lapop/ab2021/AB2021-Technical-Report-v1.0-FINAL-eng-030722.pdf]. Given the state of the pandemic at that time,  the survey included several questions related to COVID-19. The first of these questions asked respondents if they were worried about the possibility of either themselves or someone in their household getting sick from the coronavirus within the next three months. Our analysis will focus on calculating the percentage of people in each country who reported being either 'very worried' or 'somewhat worried' about the possibility. 

The following code calculates the estimates and then creates a table using the {gt} package to display the results.

```{r}
#| label: ambarom-est1
covid_worry_country_ests <-
  ambarom_des %>%
  mutate(CovidWorry_bin = fct_collapse(
    CovidWorry,
    WorriedHi = c("Very worried", "Somewhat worried"),
    WorriedLo = c("A little worried", "Not worried at all")
  )) %>%
  group_by(Country) %>%
  summarize(p = survey_mean(CovidWorry_bin == "WorriedHi", na.rm = TRUE) *
              100)

covid_worry_country_ests %>%
  gt(rowname_col = "Country") %>%
  cols_label(p = "Percent",
             p_se = "SE") %>%
  tab_header(title = "Proportion worried about the possibility that they or someone in their household will get sick from coronavirus in the next 3 months") %>%
  fmt_number(decimals = 1)
```

Another question focused on how education was affected by the pandemic. This question was asked specifically among households with children under the age of 13. Respondents were allowed to select multiple options to describe how education was affected. The available options were:

> Did any of these children have their school education affected due to the pandemic?
> 
>    - No, because they are not yet school age or because they do not attend school for another reason
>    - No, their classes continued normally
>    - Yes, they went to virtual or remote classes
>    - Yes, they switched to a combination of virtual and in-person classes
>    - Yes, they cut all ties with the school

Multiple-choice questions are interesting. To analyze how education was impacted specifically among those attending school, we need to filter the relevant responses. These responses include those who answered 'no' to the first part of the question.

Below, we include an unweighted cross-tabulation of the responses, revealing a wide range of impacts on education. Many combinations of effects on education are possible.

```{r}
#| label: ambarom-covid-ed-skip
ambarom %>% filter(Educ_NotInSchool == 0) %>%
  count(Educ_NormalSchool,
        Educ_VirtualSchool,
        Educ_Hybrid) %>%
  print(n = 50)
```

We can create multiple outcomes for a table as follows:

  - An indicator for schools that continued with regular, in-person classes without any virtual or hybrid options
  - An indicator for schools that transitioned to a different education medium, either virtual or hybrid

By creating these variables, we can make national estimates and generate a summary table to examine the distribution of these outcomes across different countries.

```{r}
#| label: ambarom-covid-ed-der
ambarom_des_educ <- ambarom_des %>%
  filter(Educ_NotInSchool == 0) %>%
  mutate(
    Educ_OnlyNormal = Educ_NormalSchool == 1 &
      Educ_VirtualSchool == 0 & Educ_Hybrid == 0,
    Educ_MediumChange = Educ_VirtualSchool == 1 | Educ_Hybrid == 1,
  )

covid_educ_ests <-
  ambarom_des_educ %>%
  group_by(Country) %>%
  summarize(
    p_onlynormal = survey_mean(Educ_OnlyNormal, na.rm = TRUE) * 100,
    p_mediumchange = survey_mean(Educ_MediumChange, na.rm = TRUE) * 100,
    p_noschool = survey_mean(Educ_NoSchool, na.rm = TRUE) * 100,
  ) 

covid_educ_ests %>%
  gt(rowname_col = "Country") %>%
  cols_label(
    p_onlynormal = "%",
    p_onlynormal_se = "SE",
    p_mediumchange = "%",
    p_mediumchange_se = "SE",
    p_noschool = "%",
    p_noschool_se = "SE"
  ) %>%
  tab_spanner(label = "Normal school only",
              columns = c("p_onlynormal", "p_onlynormal_se")) %>%
  tab_spanner(label = "Medium change",
              columns = c("p_mediumchange", "p_mediumchange_se")) %>%
  tab_spanner(label = "Cut ties with school",
              columns = c("p_noschool", "p_noschool_se")) %>%
  fmt_number(decimals = 1)
```

Among the countries that participated in this survey, a significant number of households experienced a change in their children's education medium, except for Haiti. In Haiti, only 7.2% of households with students reported transitioning to virtual or hybrid learning.

## Mapping survey data

While the table effectively presents the data, an alternative visualization could be achieved using a map. We can use the package {rnaturalearth} to obtain maps of the countries, subsetting North and South America using the function `ne_countries()`. This function returns a Simple Features (sf) object, which represents spatial data and includes information about the geometry of spatial features (such as points, lines, or polygons) and their associated attributes. The returned sf object contains several columns, including `soverignt` (sovereignty), `geounit` (country or territory), and `geometry` (the shape). The United States, Puerto Rico, and the US Virgin Islands are separate units with the same sovereignty.

We plot a map without data first. The initial map appears excessively wide because the Aleutian islands in Alaska extend into the Eastern Hemisphere. To address this issue, we crop the shape file to include only the Western Hemisphere, thus removing some of the trailing islands of Alaska.

```{r}
#| label: ambarom-americas-map
#| fig.cap: "Map of North and South America"
country_shape <-
  ne_countries(
    scale = "medium",
    returnclass = "sf",
    continent = c("North America", "South America")
  )

country_shape %>%
  ggplot() +
  geom_sf()
```

```{r}
#| label: ambarom-americas-map-crop
#| fig.cap: "Map of North and South America, cropped to the Western Hemisphere"
country_shape %>%
  st_crop(c(
    xmin = -180,
    xmax = 0,
    ymin = -90,
    ymax = 90
  )) %>%
  ggplot() +
  geom_sf()
```

Then, we use the `anti_join()` function to check if all countries in the survey data are present in the map data. As revealed below, the United States is referred to as "United States" in the survey data but "United States of America" in the map data. We need to match the country names in both datasets.

```{r}
#| label: ambarom-map-merge-check
survey_country_list <- ambarom %>% distinct(Country)

survey_country_list %>% anti_join(country_shape, by = c("Country" = "geounit"))

country_shape %>% as_tibble() %>% select(geounit, sovereignt) %>%
  anti_join(survey_country_list, by = c("geounit" = "Country")) %>%
  arrange(geounit) %>%
  print(n = 30)
```

There are several ways to reconcile the name discrepancy to enable a successful merge. The most straightforward fix involves renaming the shape object's data before performing the merge. We can then proceed to plot the survey estimates.

```{r}
#| label: ambarom-update-map-usa
country_shape_upd <- country_shape %>%
  mutate(geounit = if_else(geounit == "United States of America",
                           "United States",
                           geounit)) %>%
  st_crop(c(
    xmin = -180,
    xmax = 0,
    ymin = -90,
    ymax = 90
  )) 
```

We combine the map file with the estimates data to make the map. After merging them, we create the map using the same outcomes as in the tables above.

```{r}
#| label: ambarom-make-maps-covid
#| fig.cap: "Percent of people worried someone in their household will get COVID-19 in the next three months by country"
covid_sf <- country_shape_upd %>%
  full_join(covid_worry_country_ests, by = c("geounit" = "Country")) %>%
  full_join(covid_educ_ests, by = c("geounit" = "Country"))

ggplot() +
  geom_sf(data = covid_sf, aes(fill = p, geometry = geometry)) +
  scale_fill_gradientn(
    guide = "colorbar",
    name = "Percent",
    labels = scales::comma,
    colors = c("#BFD7EA", "#087E8B", "#0B3954"),
    na.value = NA
  ) +
  geom_sf_pattern(
    data = filter(covid_sf, is.na(p)),
    pattern = "crosshatch",
    pattern_fill = "black",
    fill = NA
  )
```

```{r}
#| label: ambarom-make-maps-covid-ed
#| fig.cap: "Percent of students who participated in virtual or hybrid learning"
ggplot() +
  geom_sf(data = covid_sf, aes(fill = p_mediumchange, geometry = geometry)) +
  scale_fill_gradientn(
    guide = "colorbar",
    name = "Percent",
    labels = scales::comma,
    colors = c("#BFD7EA", "#087E8B", "#0B3954"),
    na.value = NA
  ) +
  geom_sf_pattern(
    data = filter(covid_sf, is.na(p_mediumchange)),
    pattern = "crosshatch",
    pattern_fill = "black",
    fill = NA
  )
```

Canada, Mexico, and the United States did not include this question, so we remove North America from the map to focus on Central and South America.

```{r}
#| label: ambarom-make-maps-covid-ed-c-s
#| fig.cap: "Percent of students who participated in virtual or hybrid learning, Central and South America"

covid_c_s <- covid_sf %>%
  filter(region_wb == "Latin America & Caribbean")

ggplot() +
  geom_sf(data = covid_c_s, aes(fill = p_mediumchange, geometry = geometry)) +
  scale_fill_gradientn(
    guide = "colorbar",
    name = "Percent",
    labels = scales::comma,
    colors = c("#BFD7EA", "#087E8B", "#0B3954"),
    na.value = NA
  ) +
  geom_sf_pattern(
    data = filter(covid_c_s, is.na(p_mediumchange)),
    pattern = "crosshatch",
    pattern_fill = "black",
    fill = NA
  )
```

## Exercises

1. Calculate the percentage of households with broadband internet and those with any internet at home, including from a phone or tablet. Hint: if you see countries with 0% Internet usage, you may want to filter by something first.

```{r}
#| label: ambarom-int-prev
int_ests <-
  ambarom_des %>%
  filter(!is.na(Internet) | !is.na(BroadbandInternet)) %>%
  group_by(Country) %>%
  summarize(
    p_broadband = survey_mean(BroadbandInternet, na.rm = TRUE) * 100,
    p_internet = survey_mean(Internet, na.rm = TRUE) * 100
  ) 

int_ests %>%
  print(n = 30)
```

2. Make a faceted map showing both broadband internet and any internet usage.

```{r}
#| label: ambarom-facet-map
internet_sf <- country_shape_upd %>%
  full_join(select(int_ests, p = p_internet, geounit = Country), by = "geounit") %>%
  mutate(Type = "Internet")
broadband_sf <- country_shape_upd %>%
  full_join(select(int_ests, p = p_broadband, geounit = Country), by = "geounit") %>%
  mutate(Type = "Broadband")
b_int_sf <- internet_sf %>%
  bind_rows(broadband_sf) %>%
  filter(region_wb == "Latin America & Caribbean")

b_int_sf %>%
  ggplot(aes(fill = p)) +
  geom_sf() +
  facet_wrap( ~ Type) +
  scale_fill_gradientn(
    guide = "colorbar",
    name = "Percent",
    labels = scales::comma,
    colors = c("#BFD7EA", "#087E8B", "#0B3954"),
    na.value = NA
  ) +
  geom_sf_pattern(
    data = filter(b_int_sf, is.na(p)),
    pattern = "crosshatch",
    pattern_fill = "black",
    fill = NA
  )
```