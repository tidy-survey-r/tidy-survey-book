# Modeling {#c08}

Modeling survey data cannot be directly done in {srvyr} but can be done in the {survey} package as was true in Chapter \@ref(c07). In this chapter, we will first review concepts of modeling in R and how to specify formulas. Then, we will introduce linear modeling including ANOVA and linear regression, logistic regression, nonlinear models, and  survival analysis. 

In all models in R, you need to specify the structure of the model using a formula. The left side of the formula is the response/dependent variable and the right side of the formula has the predictor/independent variable(s). There are many symbols used in R to specify the formula. 

For example, a linear formula mathematically specified as 

$$Y_i=\beta_0+\beta X_i+\epsilon_i$$ 
would be specified in R as `y~x` where the intercept is not explicitly included. To fit a model with no intercept, that is, 

$$Y_i=\beta_0+\beta X_i+\epsilon_i$$ 

it can be specified as `y~x-1`. Formula notation details in R can be found in the help file for formula^[Use `help(formula)` in R or find the documentation online at https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html]. A quick overview of the common formula notation is in the following table:

Symbol | Example | Meaning
-|-|-
+|`+X`|include this variable
-|`-X`|delete this variable
:|`X:Z`|include the interaction between these variables
* |`X*Z`|include these variables and the interactions between them
^n |`(X+Z+Y)^3`|include these variables and all interactions up to n way
I |`I(X-Z)`| as-as: include a new variable which is the difference of these variables

There are often multiple ways to specify the same formula. For example, consider the following equation using the mtcars data

$$mpg_i=\beta_0+\beta_1cyl_{i}+\beta_2disp_{i}+\beta_3hp_{i}+\beta_4cyl_{i}disp_{i}+\beta_5cyl_{i}hp_{i}+\beta_6disp_{i}hp_{i}+\epsilon_i$$

This could be specified as any of the following:

- `mpg~(cyl+disp+hp)^2`
- `mpg~cyl+disp+hp+cyl:disp+cyl:hp+disp:hp` 
- `mpg~cyl*disp+cyl*hp+disp*hp`

Note that the following two specifications are not the same:

- `mpg~cyl:disp:hp` this only has the interactions and not the main effect
- `mpg~cyl*disp*hp` this also has the 3-way interaction in addition to the main effects and 2-way interactions


## Chapter Set-Up

For this chapter, we will be using the same data as we did in \@ref(c06): ANES and RECS. As a reminder, we will need to create survey design objects to work with. These design objects ensure that the variance estimation is calculated accurately, and thus we can accurately determine statistical significance.

First, make sure you have installed and loaded the following packages:

```{r c07_setup}
#| error: FALSE
#| warning: FALSE
#| message: FALSE
library(tidyverse)
library(survey) # for survey analysis
library(srvyr) # for tidy survey analysis
library(here)
library(broom) # for tidy regression output
```

Second, we need to read in the data and create the design objects.

Here is how you create the design object for the ANES data, remember that we need to adjust the weight so it sums to the population instead of the sample. We do that by multiplying the weights (see the ANES methodology documentation for more information).
```{r anes_des_c07}
anes <- read_rds(here("AnalysisData", "anes_2020.rds")) %>%
   mutate(Weight=Weight/sum(Weight)*231592693) 
anes_des <- anes %>%
   as_survey_design(weights = Weight,
                    strata = Stratum,
                    ids = VarUnit,
                    nest = TRUE)
```

Here is how you create the design object for the RECS data:
```{r recs_des_c07}
recs <-read_rds(here("AnalysisData", "recs_2015.rds"))
recs_des <- recs %>%
  as_survey_rep(weights = NWEIGHT,
                repweights = starts_with("BRRWT"),
                type = "Fay",
                rho = 0.5,
                mse = TRUE)
```


## Linear modeling

In this section, we will discuss linear models. Many common models and tests are linear models including analysis of variance (ANOVA) and linear regression. Jonas Kristoffer LindelÃ¸v has an interesting [discussion](https://lindeloev.github.io/tests-as-linear/) of many statistical tests and models being equivalent to a linear model. As an example, a one-way ANOVA is a linear model with one categorical independent variable and a two-sample t-test is an ANOVA where the independent variable has exactly 2 levels.


### ANOVA

In ANOVA, we are testing whether the mean of an outcome is the same across two or more groups. Statistically, we set up this as:

- $H_0: \mu_1 = \mu_2= \dots = \mu_k$ where $\mu_i$ is the is the mean outcome for group $i$
- $H_A: \text{At least one mean is different}$

To perform this type of test in R, the general syntax is as follows:

```
des_obj %>%
  svyglm(design=.,
         outcomevar~groupvar,
         na.action=na.exclude,
         df.resid=degf(.))
```

where `des_obj` is a design object, `outcomevar` is the outcome variable, `groupvar` is the group variable, and `na.action=na.exclude` is set so that records with missing data in the outcome or group variable are removed for prediction ^[See `help(na.exclude)` for more information on options to use for `na.action`]. The function `svyglm` does not have the design as the first argument so the `.` notation is used to pass it with a pipe.

Some assumptions when using ANOVA on survey data include:

- Outcome variable is normally distributed within each group
- The variances of the outcome variable between each group are approximately equal
- We do NOT assume independence between the groups as with general ANOVA. The covariance is accounted for in the survey design

Looking at an example will help us discuss the output and how to interpret the results. In RECS, respondents are asked what temperature they set their thermostat to during the day and evening when using the air-conditioning during the summer which is encoded in the variable `SummerTempNight`. A descriptive analysis is displayed below of the temperature set by region and the sample sizes. Note that the temperature setting is set to NA when the household does not use air-conditioning.

```{r}
#| label: anova_prep
recs_des %>%
  filter(ACUsed) %>%
  group_by(Region) %>%
  summarise(
    SMN=survey_mean(SummerTempNight, na.rm=TRUE),
    n=unweighted(n()),
    n_na=unweighted(sum(is.na(SummerTempNight)))
  )
```

In the following code, we test whether this temperature varies by region by first using `svyglm` to run the test and then using `broom::tidy` to display the output. 

```{r}
#| label: anova_ex
anova_out <- recs_des %>%
   svyglm(design=.,
          formula=SummerTempNight~Region,
          na.action=na.omit)

tidy(anova_out)
```

In the output above, we can see the estimated coefficients (`estimate`), estimated standard errors of the coefficients (`std.error`), the t-statistic (`statistic`), and the p-value for each coefficient. In this output, the intercept represents the reference value which is the Northeast region. The other coefficients indicate the difference in temperature relative to the Northeast region. For example, in the Midwest, temperatures are set, on average, `r tidy(anova_out) %>% filter(term=="RegionMidwest") %>% pull(estimate) %>% round(3)` degrees higher than in the Northeast during summer nights.

### Linear regression

Linear regression is a more generalized method than ANOVA. In linear regression, we are fitting a model of a continuous outcome with any number of predictors which are categorical or continuous. We form these models as follows:

$$y_i=\beta_0 +\sum_{i=1}^n \beta_i x_i + \epsilon_i$$

where $y_i$ is the outcome, $\beta_0$ is an intercept, $x_1, \cdots, x_n$ are the predictors with $\beta_1, \cdots, \beta_n$ as the associated coefficients, and $\epsilon_i$ is the error. It is assumed that the residuals ($\epsilon_i$) are normally distributed but there is not an assumption of independence and the correlation structure is captured in the survey design object. The syntax for linear regression is nearly identical to ANOVA as follows:

```
des_obj %>%
  svyglm(design=.,
         outcomevar~x1+x2+x3,
         na.action=na.exclude,
         df.resid=degf(.))
```

As discussed in the beginning of the chapter, the formula on the right-hand side can be specified many ways whether interactions are desired or not, for example. On RECS, information on the square footage of homes and the electric bills are obtained. We assume that square footage is related to the amount of money spent on electricity and examine a model for this. Before any modeling, we first plot the data.

```{r}
#| label: plot_sf_elbill
#| fig.cap: "Relationship between square footage and dollars spent on electricity, RECS 2015"
#| echo: FALSE
#| warning: FALSE

recs %>%
  ggplot(aes(x=TOTSQFT_EN, y=DOLLAREL, weight=NWEIGHT)) +
  geom_bin2d() + 
  scale_fill_gradientn(guide="colourbar",name="Count of Housing Units", labels=scales::comma, 
                       colours=c("#0B3954", "#087E8B", "#BFD7EA", "#FF8484", "#8D6B94")) +
  xlab("Total square footage") + ylab("Amount spent on electricity") +
  scale_y_continuous(labels=scales::dollar_format()) +
  scale_x_continuous(labels=scales::comma_format()) + 
  theme_bw() 
```

The model is fit below with electricity expenditure as the outcome. Some textbooks use the term simple linear regression when a linear model has one continuous independent variable.

```{r}
#| label: slr_examp
m_electric_sqft <- recs_des %>%
   svyglm(design=.,
          formula=DOLLAREL~TOTSQFT_EN,
          na.action=na.exclude)
tidy(m_electric_sqft)
```

In the output above, we can see the estimated coefficients (`estimate`), estimated standard errors of the coefficients (`std.error`), the t-statistic (`statistic`), and the p-value for each coefficient. In these results, we can say that, on average, for every additional square foot of house size, the electricity bill increases by `r (tidy(m_electric_sqft) %>% filter(term=="TOTSQFT_EN") %>% pull(estimate) %>% round(3))*100` cents and that square footage is significantly associated with electricity expenditure. This is a very simple model and there are likely many more factors in electricity expenditure including the type of cooling, number of appliances, location, and more. 


In the following example, a model is fit predicting electricity expenditure including Census region (categorical), Urbanicity, square footage, and whether air-conditioning is used with all two-way interactions are also included.

```{r}
#| label: lmr_examp

m_electric_multi <- recs_des %>%
   svyglm(design=.,
          formula=DOLLAREL~(Region+Urbanicity+TOTSQFT_EN+ACUsed)^2-1,
          na.action=na.exclude)
tidy(m_electric_multi) %>% print(n=50)
```

To examine the predictions, residuals and more from the model, the function `augment` from {broom}. The `augment` function will return a tibble with the independent and dependent variables and other fit statistics. The fitted value and standard error are contained in one column and need to be split after using augment as illustrated below.

These results can then be used in a variety of ways including examining residual plots as is illustrated below:


```{r}
#| label: aug_examp
#| fig.cap: "Residual plot"

fitstats <-
  augment(m_electric_multi) %>%
  mutate(
    .se.fit=sqrt(attr(.fitted, "var")), # extract the variance of the fitted value
    .fitted=as.numeric(.fitted) 
    )

fitstats

fitstats %>%
  ggplot(aes(x=.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept =0, colour="red") +
  theme_bw()

```

