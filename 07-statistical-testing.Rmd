# Statistical testing {#c07}

When analyzing results from a survey, the point estimates described in Chapter \@ref(c06) are helpful for understanding the data at a high level, but researchers and the public often want to make comparisons between different groups. These comparisons are calculated through statistical testing where we compare the point estimates and the variance estimates of each statistic to see if there are statistically significant differences. The general idea of statistical testing is the same for data obtained through surveys and data obtained through other methods, but the importance lies in ensuring the variance is calculated correctly. Functions in the {survey} packages allow for the correct estimation of the variances. This chapter will cover the following statistical tests with survey data and functions:

-  Comparison of proportions `svyttest()`
-  Comparison of means `svyttest()`
-  Goodness of fit tests `svygofchisq()`
-  Tests of independence `svychisq()`
-  Tests of homogeneity `svychisq()`

Up to this point, the functions that we've provided have used the wrappers from the {srvyr} package. This means that the functions work with tidyverse syntax. However, the functions in this chapter do not have wrappers from the {srvyr} package and are instead pulled directly from the {survey} package. This means that the design object is *not* the first argument and that to use these functions with the magrittr pipe `%>%` and tidyverse syntax we will need to use dot (`.`) notation. Functions that work with the magrittr pipe `%>%` have the first argument as data. When data is run, it automatically places anything to the left of the pipe into the first argument of the function to the right of the pipe. For example, if we wanted to take the `mtcars` data and filter to only cars with 6 cylinders we can write the code in one of three ways:

1. `filter(mtcars, cyl == 6)`
2. `mtcars %>% filter(cyl == 6)`
3. `mtcars %>% filter(., cyl == 6)`

Each of these lines of code will produce the same output since the argument that takes the data is in the first spot in `filter()`. Those who have worked with the tidyverse, the first two are probably familiar. The third option functions the same way as the second one, but is explicit about where the data is going. Here we're telling R to take what's on the left side of the pipe `mtcars` and pipe it into the spot with the dot (`.`)---the first argument.

In functions that are not part of the tidyverse, the data argument may be in a different spot in the functions. For example, in `svyttest()` the data argument is in the second spot, which means we need to place the dot (`.`) in the second spot and not the first. For example:

```{r stattest-dotex}
#| eval: FALSE

svydata_des %>% 
  svyttest(x~y,.)
```


Placing the dot (`.`) in the second argument spot, indicates that the survey design object `svydata_svy` should be used in the second argument and not the first (which is the default). 


## Chapter Set-Up {#stattest-setup}

For this chapter, we will be using the same data as we did in \@ref(c06): ANES and RECS. As a reminder, we will need to create survey design objects to work with. These design objects ensure that the variance estimation is calculated accurately, and thus we can accurately determine statistical significance.

First, make sure install and load the following packages:

```{r stattest-pkgs}
#| error: FALSE
#| warning: FALSE
#| message: FALSE

library(tidyverse)
library(survey) # for survey analysis
library(srvyr) # for tidy survey analysis
library(readr)
library(here)
```

Second, we need to read in the data and create the design objects.

Here is how to create the design object for the ANES data, remember that we need to adjust the weight so it sums to the population instead of the sample. We do that by multiplying the weights (see the ANES methodology documentation for more information).
```{r stattest-anesdes}
anes <- read_rds(here("data", "anes_2020.rds")) %>%
  mutate(Weight=Weight/sum(Weight)*231592693) 

anes_des <- anes %>%
  as_survey_design(weights = Weight,
          strata = Stratum,
          ids = VarUnit,
          nest = TRUE)
```

Here is how to create the design object for the RECS data:
```{r stattest-recsdes}
recs <-read_rds(here("data", "recs.rds"))

recs_des <- recs %>%
 as_survey_rep(weights = NWEIGHT,
        repweights = starts_with("BRRWT"),
        type = "Fay",
        rho = 0.5,
        mse = TRUE)
```

## Comparison of Proportions and Means {#stattest-ttest}

To compare two proportions or means, we use t-tests. This allows us to determine if one proportion or mean is statistically different from the other. T-tests are commonly used to determine if a single estimate is different from a known value (e.g., 0 or 50%) or to compare two group means (e.g., males vs females). For comparing a single estimate to a known value, this is called a *one sample t-test* and we can set up the hypothesis test as:

- $H_0: \mu = 0$ where $\mu$ is the is the mean outcome and $0$ is the value we are comparing it to
- $H_A: \mu \neq 0$

For comparing two estimates, this is called a *two sample t-test* and we can set up the hypothesis test as:

- $H_0: \mu_1 = \mu_2$ where $\mu_i$ is the is the mean outcome for group $i$
- $H_A: \mu_1 \neq \mu_2$

Two sample t-tests can also be *paired* or *unpaired*. If the data come from two different populations (e.g., males vs females), then the t-test run will be an *unpaired* or *independent samples* t-test. *Paired* t-tests occur when the data come from the same population. This is commonly seen with data taken from the same population in two different time periods (e.g., before and after an intervention). 

The difference between using t-tests with non-survey data and with survey data is based on the underlying variance estimation difference. Chapter \@ref(c05) provides the detailed overview of the math behind the mean and sampling error calculations for various sample designs. The functions in the {survey} package will account for these nuances provided the design object is correctly defined.  

### Syntax {#stattest-ttest-syntax}

When we do not have survey data, we may be able to use the `t.test()` function. This function does not allow for weights or the variance structure to be accounted for with survey data. Therefore, when using survey data, we need to use the `svyttest()` function. Many of the arguments are the same between the two functions, but there are a two key differences:

- We need to use the survey design object, instead of data
- We can only use a formula and not separate x and y data

Here is the syntax for the `svyttest()` function:

``` r
svyttest(formula, 
         design, 
         na.rm=FALSE,
         level=0.95,
         ...)
```

Notice that the first argument here is the `formula` and not the `design`. This means that we must use the dot `(.)` if we pipe in the survey design object (as described at the beginning of this chapter). 

The `formula` argument can take on a couple of different forms depending on what it is that we are measuring.  Here are a few common scenarios:

1. **One-sided t-test:** 
    a. **Comparison to 0:** $var \sim 0$, where $var$ is the measure of interest and $0$ is the value we are comparing it to. For example, we could test if the percent of the population that has blue eyes is different from $0$.
    b. **Comparison to a different value:** $I(var - value) \sim 0$, where $var$ is the measure of interest and $value$ is what we are comparing to. We need to use the `I()` function, to tell the program to calculate the difference between the variable and the comparison value prior to testing. For example, we could test if the percent of the population that has blue eyes is different from $25%$.
2. **Two-sided t-test:**
    a. **Unpaired:**
        - **2 level grouping variable:** $var \sim groupVar$, where $var$ is the measure of interest and $groupVar$ is a variable with two categories.  For example, we could test if the perfect of the popualtion that has blue eyes is different for men and women. 
        - **3+ level grouping variable:** $var \sim I(groupVar == level)$, where $var$ is the measure of interest, $groupVar$ is the categorical variable, and $level$ is the category level to isolate. Again we need to use the `I()` function to tell the program to isolate the category before doing the comparison across groups.  For example, we could test if the test scores in one classroom differed from all other classrooms.
    b. **Paired:** $I(var_1 - var_2) \sim 0$, where $var_1$ is the first variable of interest and $var_2$ is the second variable of interest. We again will have to use the `I()` function to have the program calculate the difference between the two variables before comparing it against $0$.  For example, we could test if test scores on a subject differed between the start and the end of a course.

Additionally, the `na.rm` argument defaults to `FALSE`, which means if any data is missing the t-test will not compute. Throughout this chapter we will always set `na.rm=TRUE`, but before analyzing the survey data, make sure to review the notes provided in Chapter \@ref(c03) to better understand how to handle missing data.  Finally, the `level` argument is $1-\alpha$, or the amount of type 1 error.  The default is $0.95$.

### Examples {#stattest-ttest-examples}
Let's walk through a few examples using the ANES and RECS data.  See \@ref(stattest-setup) to set up the design objects.

#### Example 1: One-sided t-test {.unnumbered #stattest-ttest-ex1}

ANES asked respondents if they voted early in the 2020 election.  In our data, we've called this variable `EarlyVote2020`.  If we want to see if the percent of the U.S. voting eligble population that early voted is greater than 0%, we could set up the hypothesis as follows:

- $H_0: p = 0$ where $p$ is the percent of U.S. voting eligible population that voted early
- $H_A: p \neq 0$

To conduct this in R, we would then use the `svyttest()` function:
```{r stattest-ex1}
ex1<-anes_des %>%
   svyttest(formula=I(EarlyVote2020=="Yes")~0,
            design=.,
            na.rm=TRUE)

ex1
```
Note that because `EarlyVote202` is a factor, we need to specify which level we are interested in.  In this case we want to isolate those that did vot early in 2020.  The results indicate that on average `r round(ex1$estimate*100,1)`% of the U.S. voting eligible population voted early in the 2020 election.  We also see that the t-statistic is `r ex1$statistic` and the p-value is `r ex1$p.value`, indicating that the average is statistically different from 0 at an $\alpha$ level of $0.05$.

<!--Add in callout box about how to use the $ notation to help call out the different values?  Maybe indicate how this will be covered more in the reporting chapter?-->
<!--What about a callout box about tidy()?-->

#### Example 2: One-sided t-test {.unnumbered #stattest-ttest-ex2}

RECS asks respondents to indicate what temperature they set their house to during the summer at night.  In our dataset, we've called this variable `SummerTempNight`.  If we want to see if the U.S. household sets their temperature at a value different from 68$^\circ$F, we could set up the hypothesis as follows:

- $H_0: \mu = 68$ where $\mu$ is the is average temperature U.S. Households set their thermostat to in the summer at night
- $H_A: \mu \neq 68$

To conduct this in R, we would then use the `svyttest()` function, and the `I()` function in the formula:
```{r stattest-ex2}
ex2<-recs_des %>%
   svyttest(formula=I(SummerTempNight-68)~0,
            design=.,
            na.rm=TRUE)

ex2
```

The estimate in this case differs from example one in that the estimate is not displaying $\mu$ but rather $\mu - 68$.  If we wanted the average we could do one of the following:
```{r stattest-ex2-svymean}
recs_des %>% summarize(mu=survey_mean(SummerTempNight,na.rm=TRUE))
```

Or, we could take our t-test estimate (`ex2$estimate`) and add it to 68: 
```{r stattest-ex2-add}
ex2$estimate + 68
```

The result is the same in both methods, so we see that the average temperature U.S. Households set their thermostat to in the summer at night is `r round(ex2$estimate + 68,1)`.  Looking at the output from the` svyttest()`, the t-statistic is `r ex2$statistic` and the p-value is `r ex2$p.value`, indicating that the average is statistically different from 68$^\circ$F at an $\alpha$ level of $0.05$.


#### Example 3: Unpaired two-sided t-test {.unnumbered #stattest-ttest-ex3}

Two additional variables we have on the RECS data are the electric bill cost (`DOLLAREL`) and whether the house used AC or not (`ACUsed`).  If we want to know if the U.S. households that used AC had high electrical bills than those that did not, we could set up the hypothesis as follows:

- $H_0: \mu_{AC} = \mu_{noAC}$ where $\mu_{AC}$ is the electrical bill cost for U.S. households that used AC and $\mu_{noAC}$ is the electrical bill cost for U.S. household that did not use AC
- $H_A: \mu_{AC} \neq \mu_{noAC}$
 
Let's take a quick look at the data to see the format the data are in:
```{r stattest-ex3-desc}
recs_des %>% 
  group_by(ACUsed) %>% 
  summarize(mean=survey_mean(DOLLAREL,na.rm=TRUE))
```

To conduct this in R, we would then use `svyttest()`:
```{r stattest-ex3}
ex3<-recs_des %>%
   svyttest(formula=DOLLAREL~ACUsed,
            design=.,
            na.rm=TRUE)

ex3
```
The results indicate that the difference in electrical bill for those that used AC and those that did not is on average \$`r round(ex3$estimate,2)`. The difference does appear to be statistically significant as the t-statistic is `r ex3$statistic` and the p-value is `r ex3$p.value`.

#### Example 4: Paired two-sided t-test {.unnumbered #stattest-ttest-ex4}

To conduct a paired t-test that looks at differences at two timepoints, we use the same `I()` notatation we've been using.  For example, let's say we want to test whether the temperature that U.S. households set their thermostat to differs depending on the season (comparing summer temperature and winter temperature).  We could set up the hypothesis as follows:

- $H_0: \mu_{summer} = \mu_{winter}$ where $\mu_{summer}$ is the temperature that U.S. households set their thermostat to during summer nights, and $\mu_{winter}$ is the etemperature that U.S. households set their thermostat to during winter nights
- $H_A: \mu_{summer} \neq \mu_{winter}$

To conduct this in R, we would then use `svyttest()` and `I()`:
```{r stattest-ex4}
ex4<-recs_des %>%
   svyttest(design=.,
            formula=I(SummerTempNight-WinterTempNight)~0,
            na.rm=TRUE)

ex4
```

U.S. households set their thermostat on average `r round(ex4$estimate,1)`$^\circ$F warmer in summer nights than winter nights, and it is statistically significant (t=`r ex4$statistic`, p-value=`r ex4$p.value`).

### Exercises {#stattest-ttest-exercises}

Here are some exercises for practicing conducting t-tests using `svyttest()`:

1. Using the RECS data, do more than 50% of U.S. household use AC (`ACUsed`)?
```{r stattest-solution1}
solution1<-recs_des %>%
   svyttest(design=.,
            formula=I((ACUsed==TRUE)-0.5)~0,
            na.rm=TRUE)

solution1
```
2. Using the RECS data, does the average temperature that U.S. households set their thermostats to differ between the day and night in the winter (`WinterTempDay` and `WinterTempNight`)?
```{r stattest-solution2}
solution2<-recs_des %>% 
  svyttest(design=.,
           formula=I(WinterTempDay-WinterTempNight)~0,
           na.rm=TRUE)

solution2
```

3. Using the ANES data, does the average age (`Age`) of those who voted for Biden in 2020 (`VotedPres2020_selection`) differ from those that voted for another candidate?
```{r stattest-solution3}
solution3<-anes_des %>%
   svyttest(design=.,
            formula=Age~I(VotedPres2020_selection=="Biden"),
            na.rm=TRUE)

solution3
```

## Chi-Square Tests {#stattest-chi}

Chi-square tests ($\chi^2$) allow us to examine multiple proportions using goodness-of-fit test, test of independence, or test of homogeneity. All three of these tests the same $\chi^2$ distributions but with slightly different underlying assumptions.

First, **goodness-of-fit** tests are used when comparing *observed* data to *expected* data. For example, this could be used to determine if respondent demographics (the observed data) match known population information (the expected data). In this case, we can set up the hypothesis test as:

- $H_0: p_1 = \pi_1, ~ p_2 = \pi_2, ~ ..., ~ p_k = \pi_k$ where $p_i$ is the observed proportion for category $i$, $\pi_i$ is expected proportion for category $i$, and $k$ is the number of categories
- $H_A:$ at least one level of $p_i$ does not match $\pi_i$

Second, **tests of independence** are used when comparing two types of *observed* data to see if there is a relationship. For example, this could be used to determine if the proportion of respondents who voted for each political party in the Presidential election matches the proportion of respondents who voted for each political party in a local election. In this case, we can set up the hypothesis test as:

- $H_0:$ The two variables/factors are independent
- $H_A:$ The two variables/factors are *not* independent 

Third, **tests of homogeneity** are used to compare two distributions to see if they match. For example, this could be used to determine if the highest education achieved is the same for both men and women.  In this case, we can set up the hypothesis test as:

- $H_0: p_{1a} = p_{1b}, ~ p_{2a} = p_{2b}, ~ ..., ~ p_{ka} = p_{kb}$ where $p_{ia}$ is the observed proportion of category $i$ for subgroup $a$, $p_{ib}$ is the observed proportion of category $i$ for subgropu $a$, and $k$ is the number of categories
- $H_A:$ at least one category of $p_{ia}$ does not match $p_{ib}$

The difference between using $\chi^2$ tests with non-survey data and with survey data is based on the underlying variance estimation difference. The functions in the {survey} package will account for these nuances provided the design object is correctly defined.  

<!--Chapter 5 provides se for individual mean/proportion estimates, but does it provide the details for doing these?  Do we want to include the details here?  -->

### Syntax {#stattest-chi-syntax}

As with t-tests, when we do not have survey data, we may be able to use the `chisq.test()` function.  However, this function does not allow for weights or the variance structure to be accounted for with survey data. Therefore, when using survey data, we need to use one of two functions:

-  `svygofchisq()`: For goodness of fit tests
-  `svychisq()`: For tests of independence and homogeneity

This non-survey data function requires either a single set of counts and given proportions (for goodness of fit tests), or two sets of counts for tests of independence and homogeneity.  The survey versions of this function require formulas instead of counts.

First, the function for the goodness of fit tests is `svygofchisq()`:

``` r
svygofchisq(formula,
            p,
            design, 
            na.rm=TRUE,
            ...)
```

In this function, you'll notice that the first argument is the `formula`, the second argument is `p` which are the expected proportions, and the third argument is the `design`.  Therefore, we again must use the dot `(.)` notation if we pipe in the survey design object (as described at the beginning of this chapter).  For the goodness of fit tests, the formula will be a single variable `formula=~VARIABLE` as we are comparing the observed data from this variable to expected data.  The expected data are then presented in `p`, and needs to be a vector of the same length as the number of categories in the variable.  For example, if we want to know if the proportion of males and females match a distribution of 30/70, then the sex variable (with 2 categories) would be used in the formula `formula=~SEX` and the proportions would be included as `p=c(.3,.7)`.  The examples below provide more detail and tips on how to make sure the levels are matching up correctly.
<!--Check to see if the variable needs to be a factor.  Would be good to mention that here.-->

The function for tests of independence and homogeneity (`svychisq()`) is similar to the goodness of fit function in that the `formula` argument is first.  However, instead of an argument for the expected proportions, the `svychisq()` function has an argument to select the statistic used for the test:

``` r
svychisq(formula,
         design, 
         statistic = c("F",  "Chisq", "Wald", "adjWald", 
                       "lincom", "saddlepoint"),
         na.rm=TRUE,
         ...)
```

Each statistic is used for different purposes: `F` and `Chisq` are used primarily for tests of homogeneity, while `Wald` and `adjWald` are recommended for tests of independence.<!--How much detail do we want to go into for this?-->The formula argument will always be one sided unlike the `svyttest()` function. The two variables of interest should be included with a plus sign: `formula=~VAR1+VAR2`.

Additionally, as with the t-test function, both `svygofchisq()` and `svychisq()` have the `na.rm` argument.  This argument defaults to `FALSE`, which means if any data is missing the $\chi^2$ test will not compute. Throughout this chapter we will always set `na.rm=TRUE`, but before analyzing the survey data, make sure to review the notes provided in Chapter \@ref(c03) to better understand how to handle missing data.


### Examples {#stattest-chi-examples}

### Exercises {#stattest-chi-exercises}




