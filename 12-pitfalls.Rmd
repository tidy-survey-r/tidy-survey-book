# Recommendations for Successful Survey Data Analysis {#c12-pitfalls}

This book pertains to the analysis of complex surveys, which require extra considerations compared to non-random ones. Running analysis carefully and accurately, while avoiding pitfalls, is crucial for success. We've included our recommendations for successful survey data analysis throughout the book; however, this chapter summarizes a few key considerations while taking the steps shown in previous chapters. Note, this is not meant to be a comprehensive list of best practices for survey analysis but instead a curated list for survey analysts.

```{r}
#| include: false
anscombe_tidy <- anscombe %>%
  mutate(observation = seq_len(n())) %>%
  gather(key, value,-observation) %>%
  separate(key, c("variable", "set"), 1, convert = TRUE) %>%
  mutate(set = c("I", "II", "III", "IV")[set]) %>%
  spread(variable, value)
```

## Begin your analysis with descriptive data analysis

When receiving a fresh batch of data, it's tempting to jump right into developing models to find significant results. However, a successful data analyst begins by exploring the dataset. This involves running descriptive analysis on the dataset as a whole, as well as individual variables and combinations of variables. As described in Chapter \@ref(c05-descriptive-analysis), descriptive analyses should always precede statistical analysis to prevent avoidable (and embarrassing) mistakes.

Even before applying weights, consider running cross-tabulations on the raw data. Do any results jump out?

Let’s say that we run `svy_des %>% group_by(group) %>% summarize(p = mean())` and see the data shows that males make up 10% of the sample.

```r
## # A tibble: 2 × 2
##   group    	p
##   <fct> 	<dbl>
## 1 female  	0.9
## 2 male    	0.1
```

We would generally assume around a 50/50 split between male and female respondents in a population. The large female proportion could indicate either a unique sample or a potential error in the data. If we review the survey documentation and see this was an intentional part of the design, we can continue our analysis using the appropriate methods. If this was not an intentional choice by the researchers, the results alert us that something may be incorrect in the data or our code, and we can verify if there's an issue by comparing the results with the weighted means.

Tables provide a quick check of our assumptions, but there is no substitute for graphs and plots to visualize the distribution of data. We might miss outliers or nuances if we scan only summary statistics. Anscombe's Quartet demonstrates the importance of visualization in analysis. Let's say we have a dataset with x and y variables. Let's take a look at how the dataset is structured:

```{r}
head(anscombe_tidy)
```

We can begin by checking one set of variables. For Set I, the x-variables have an average of 9 with a standard deviation of 3.3; for y, we have an average of 7.5 with a standard deviation of 2.03. The two variables have a correlation of 0.81.

```{r}
anscombe_tidy %>% 
  filter(set == "I") %>% 
  summarize(
    x_mean = mean(x),
    x_sd = sd(x),
    y_mean = mean(y),
    y_sd = sd(y),
    correlation = cor(x, y)
  )
```

These are useful statistics - we can note that the data doesn't have high variability; the two variables are strongly correlated.

Now, let's check all of our variables. Notice anything interesting?

```{r}
anscombe_tidy %>% 
  group_by(set) %>%
  summarize(
    x_mean = mean(x),
    x_sd = sd(x, na.rm = TRUE),
    y_mean = mean(y),
    y_sd = sd(y, na.rm = TRUE),
    correlation = cor(x, y)
  )
```

The summary results for these four variables are nearly identical! We might assume that the distribution for each of them is similar. A data visualization can help confirm our assumptions.

```{r}
ggplot(anscombe_tidy, aes(x, y)) +
  geom_point() +
  facet_wrap( ~ set) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal()
```

When creating the plots, we clearly see that the distributions are very dissimilar. Each set of points results in different shapes and distributions. Imagine sharing each individual plot with a shareholder and how you would describe the data, and how different the interpretations will be.

With survey data, we might not always have continuous data that we can plot like Anscombe's Quartet. However, if the dataset does contain continuous data, or other types of data which would benefit from a visual representation, we recommend taking the time to graph distributions and correlations.

## Improve your debugging skills



